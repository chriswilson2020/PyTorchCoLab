{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSWK608Gj8z19TGy2m+aHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chriswilson2020/PyTorchCoLab/blob/main/01_PyTorch_Workflow_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Workflow\n",
        "\n",
        "Let's explore an example PyTorch end-to-end workflow.\n",
        "\n",
        "Resources:\n",
        "\n",
        "* Ground truth notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
        "* Book version of the notebook - https://www.learnpytorch.io/01_pytorch_workflow/"
      ],
      "metadata": {
        "id": "8wGbpP-qF97S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering = {1: \"date (prepare and load\",\n",
        "                      2: \"build model\",\n",
        "                      3: \"fitting the model to data (training)\",\n",
        "                      4: \"making predictions and evaluating a model (inference)\",\n",
        "                      5: \"saving and loading a model\",\n",
        "                      6: \"putting it all together\"}\n",
        "what_were_covering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plIrD3woHQW2",
        "outputId": "b7cb822a-64c2-44da-d08b-2beab4c8ca23"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'date (prepare and load',\n",
              " 2: 'build model',\n",
              " 3: 'fitting the model to data (training)',\n",
              " 4: 'making predictions and evaluating a model (inference)',\n",
              " 5: 'saving and loading a model',\n",
              " 6: 'putting it all together'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn #nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OVKahKp2IByI",
        "outputId": "41d919fe-bee9-4f56-ccd8-c70072b83e27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data (preparing and loading)\n",
        "\n",
        "Data can be almost anything... in machine learning. \n",
        "\n",
        "* Excel spreadsheet\n",
        "* Images of any kind\n",
        "* Videos (YouTube has lots of data...)\n",
        "* Audio like songs or podcasts\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "1. Get data into a numerical representation. \n",
        "2. Build a model to learn patterns in that numerical representation.\n",
        "\n",
        "To showcase this, let's create some *known* data using the linear regression formula.\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with known **parameters**.\n",
        "\n"
      ],
      "metadata": {
        "id": "VmaBZ60fMgD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1) # Add an extra dimension to give the right dimensionality\n",
        "y = weight * X + bias\n",
        "\n",
        "print(f\"X is: {X[:10]}\\n\")\n",
        "print(f\"y is: {y[:10]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMR8g0psJTFf",
        "outputId": "922d6553-27f4-46eb-de00-7f411b79d4a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X is: tensor([[0.0000],\n",
            "        [0.0200],\n",
            "        [0.0400],\n",
            "        [0.0600],\n",
            "        [0.0800],\n",
            "        [0.1000],\n",
            "        [0.1200],\n",
            "        [0.1400],\n",
            "        [0.1600],\n",
            "        [0.1800]])\n",
            "\n",
            "y is: tensor([[0.3000],\n",
            "        [0.3140],\n",
            "        [0.3280],\n",
            "        [0.3420],\n",
            "        [0.3560],\n",
            "        [0.3700],\n",
            "        [0.3840],\n",
            "        [0.3980],\n",
            "        [0.4120],\n",
            "        [0.4260]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets (one of the most important concepts in machine learning in general)\n",
        "\n",
        "Let's create a training and test set with our data."
      ],
      "metadata": {
        "id": "fkQAgPhAPy3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train/test split\n",
        "train_split = int(0.8 * len(X))\n",
        "print(f\"The data for the training set consists of: {train_split} samples \\n\")\n",
        "\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "print(f\"The training data consists of:    {len(X_train)} X and {len(y_train)} y pairs\")\n",
        "print(f\"The test data consists of:        {len(X_test)} X and {len(y_test)} y pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOT3VxGmQo3f",
        "outputId": "19459928-6e5d-4dd1-9284-9e0d12952bf7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data for the training set consists of: 40 samples \n",
            "\n",
            "The training data consists of:    40 X and 40 y pairs\n",
            "The test data consists of:        10 X and 10 y pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  # Plot training data in blue.\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\" )\n",
        "\n",
        "  #Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  #Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "  \n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ],
      "metadata": {
        "id": "6OnUrdAIRiV6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "EWLjWzvVUnCC",
        "outputId": "c4c16fb4-f729-4119-c048-1098917ed7b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build model\n",
        "\n",
        "Out first PyTorch model. \n",
        "\n",
        "Let's get to coding!!!\n",
        "\n",
        "\n",
        "Because we are going to be building classes throughout the course here is a good resource for learning OOP or object oriented programming.\n",
        "\n",
        "Resources for Python Classes - https://realpython.com/python3-object-oriented-programming/\n",
        "\n",
        "What our model does:\n",
        "* Start with random values (weight & bias)\n",
        "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)\n",
        "\n",
        "How does it do so?\n",
        "\n",
        "Through two main algorithms:\n",
        "1. Gradient descent - https://youtu.be/IHZwWFHWa-w\n",
        "2. Backpropagation - https://youtu.be/Ilg3gGewQ5U"
      ],
      "metadata": {
        "id": "yP6j4CRPUrJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# Create a linear regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherits from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Initialize model parameters - Note: you don't have to initialize with random parameters you can also include them explicitly\n",
        "    self.weights = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight\n",
        "                                            requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
        "                                            dtype=torch.float32)) # <- PyTorch loves the data type torch.float32\n",
        "    \n",
        "    self.bias = nn.Parameter(torch.randn(1, # <- start with a random bias and try to adjust it to the ideal bias\n",
        "                                         requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
        "                                         dtype=torch.float)) # <- PyTorch loves the data type torch.float32\n",
        "    \n",
        "  # Forward method to define the computation model\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
        "    return self.weights * x + self.bias # this is the linear regression formula\n",
        "\n"
      ],
      "metadata": {
        "id": "h1LltunvVcwt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
        "* torch.nn.Parameter - What parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us\n",
        "* torch.nn.Module - The base class of all neural network modules, if you subclass it, you should overwrite forward\n",
        "* torch.optim - This is where the optimizers in PyTorch live, they will help with gradient descent\n",
        "* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation\n",
        "\n",
        "See more of these essential modules via the PyTorch cheatsheet - https://pytorch.org/tutorials/beginner/ptcheat.html"
      ],
      "metadata": {
        "id": "-FIen6MxWCx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "Now we have created a model, let's see what's inside...\n",
        "\n",
        "So we can check our model parameters or what's inside our model using `.parameters()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "5y4wWSKba4Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWxfpXaXcA8t",
        "outputId": "d1af22c0-bbb5-49ed-8746-2d0588706f07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True), Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHSFVDv5cRHp",
        "outputId": "94773a29-d5d9-4f22-fcbd-796681394dc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making prediction using `torch.inference_mode()`\n",
        "\n",
        "To check our models predictive power lets see how well it predicts `y_test` based on `X_test`\n",
        "\n",
        "When we pass data through our model its going to run it through the forward method"
      ],
      "metadata": {
        "id": "yt0miUHcc7ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "#with torch.no_grad(): #Older way of doing this before inference mode\n",
        "#  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtJfNvGB2R3x",
        "outputId": "a1e38a57-3872-4b10-e7ae-8bdcf41436e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3982],\n",
              "        [0.4049],\n",
              "        [0.4116],\n",
              "        [0.4184],\n",
              "        [0.4251],\n",
              "        [0.4318],\n",
              "        [0.4386],\n",
              "        [0.4453],\n",
              "        [0.4520],\n",
              "        [0.4588]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See more on inference mode here - https://twitter.com/pytorch/status/1437838231505096708"
      ],
      "metadata": {
        "id": "ENyQuI624ZY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0lY3KgcI2fIC",
        "outputId": "a3b33f7d-6a55-44cc-d713-7f1900a5afc2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train model\n",
        "\n",
        "The whole idea of training is for a model to move from some unknown parameters which may be random to some known parameters.\n",
        "\n",
        "Or in otherwords from a poor representation of the data to a better representation of the data.\n",
        "\n",
        "One way to measure how poor or how wrong your models predictions are is to use a loss function. \n",
        "\n",
        "* Note: Loss function may also be called cost function or criterion in different areas. In our case we are going to refer to it as a loss function.\n",
        "\n",
        "* **Loss function:** A function to measure how wrong your models predictions are to the ideal outputs so lower is better. \n",
        "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameter (e.g. weight & bias) in our case to improve the loss function - https://pytorch.org/docs/stable/optim.html#module-torch.optim\n",
        "\n",
        "  * Inside the optimizer you'll often have to set two parameters\n",
        "    * `params`- the model parameters you'd like to optimise for example `params=model_0.parameters()`\n",
        "    * lr (learning rate) - the learning rate is a hyperparameter that defines how big/small the optimizer changes the parameters with each step (a small `lr` resutls in small changes, a large `lr` results in large changes)\n",
        "\n",
        "And specifically for PyTorch we need: \n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "GDc7BXnU3j8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm-UdCvF7DBX",
        "outputId": "15589abd-9ac0-4f90-cbd6-77ab90dedcb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True), Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's parameters (A parameter is a value that the model sets itself)\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpcZgI767evj",
        "outputId": "b6042a81-394d-438c-e3b7-91cdc176201f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "\n",
        "# Setup an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.00005) # lr = learning rate = possibly the most important hyperparameter you can set"
      ],
      "metadata": {
        "id": "RJs0NBG77iQa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q:** Which loss function  or optimiser should I use?\n",
        "\n",
        "**A:** This will be problem specific. But with experience, you'll get an idea of what works and what doesn't with your particular problem set. \n",
        "\n",
        "For example, for a regression problem (like ours), a loss function of `nn.L1Loss()` and an optimizer like `torch.optim.SGD()` will suffice.\n",
        "\n",
        "But for a classification problem like classifying whether a photo is of a dog or a cat, you'll likely want to use a loss function of `nn.BCELoss()` (binary cross entropy loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "l2771mGi9NkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a training loop (and a testing loop) in PyTorch\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "\n",
        "0. Loop through the data and do...\n",
        "1. Forward pass (this involves data moving through our models forward functions) to make predictions on data - also called forward propagation\n",
        "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gratidents of each of the parameters of our model with respect to the loss (**backpropagation**)\n",
        "5. Optimizer step - use the optimizer to adjust our models parameters to try to improve the loss (**gradient descent**)"
      ],
      "metadata": {
        "id": "eaXD2SG3BJGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch is one loop through the data... (this is a hyperparameter because we've set it ourselves)\n",
        "epochs = 36000\n",
        "\n",
        "#Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "### Training\n",
        "# 0. loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  # print(f\"Loss: {loss}\")\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step() # by default how the optimizer changes will accumulate through the loop so... we have to zero them above in stap 3 for the next itteration of the loop\n",
        "\n",
        "  ### Testing\n",
        "  model_0.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode(): # turns off gradient tracking & a couple of more things behind the scenes\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    # 2. Calculate the test loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    # Print out what's happening\n",
        "    if epoch % 10 == 0:\n",
        "     epoch_count.append(epoch)\n",
        "     loss_values.append(loss)\n",
        "     test_loss_values.append(test_loss)\n",
        "     print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
        "    # Print out model state_dict()\n",
        "     print(model_0.state_dict(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-12AxCtkClT2",
        "outputId": "8a79af88-43b1-45fb-e17a-616b61c969a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "OrderedDict([('weights', tensor([0.5731])), ('bias', tensor([0.3533]))]) \n",
            "\n",
            "Epoch: 19340 | Loss: 0.02549285627901554 | Test loss: 0.059604864567518234\n",
            "OrderedDict([('weights', tensor([0.5732])), ('bias', tensor([0.3533]))]) \n",
            "\n",
            "Epoch: 19350 | Loss: 0.025475705042481422 | Test loss: 0.059567101299762726\n",
            "OrderedDict([('weights', tensor([0.5733])), ('bias', tensor([0.3532]))]) \n",
            "\n",
            "Epoch: 19360 | Loss: 0.02545856311917305 | Test loss: 0.059525877237319946\n",
            "OrderedDict([('weights', tensor([0.5733])), ('bias', tensor([0.3532]))]) \n",
            "\n",
            "Epoch: 19370 | Loss: 0.025441383942961693 | Test loss: 0.059484630823135376\n",
            "OrderedDict([('weights', tensor([0.5734])), ('bias', tensor([0.3532]))]) \n",
            "\n",
            "Epoch: 19380 | Loss: 0.025424232706427574 | Test loss: 0.059446848928928375\n",
            "OrderedDict([('weights', tensor([0.5735])), ('bias', tensor([0.3531]))]) \n",
            "\n",
            "Epoch: 19390 | Loss: 0.0254070945084095 | Test loss: 0.05940563604235649\n",
            "OrderedDict([('weights', tensor([0.5736])), ('bias', tensor([0.3531]))]) \n",
            "\n",
            "Epoch: 19400 | Loss: 0.025389928370714188 | Test loss: 0.05936610698699951\n",
            "OrderedDict([('weights', tensor([0.5737])), ('bias', tensor([0.3530]))]) \n",
            "\n",
            "Epoch: 19410 | Loss: 0.025372758507728577 | Test loss: 0.05932486802339554\n",
            "OrderedDict([('weights', tensor([0.5738])), ('bias', tensor([0.3530]))]) \n",
            "\n",
            "Epoch: 19420 | Loss: 0.025355583056807518 | Test loss: 0.05928710103034973\n",
            "OrderedDict([('weights', tensor([0.5739])), ('bias', tensor([0.3530]))]) \n",
            "\n",
            "Epoch: 19430 | Loss: 0.02533845230937004 | Test loss: 0.059245847165584564\n",
            "OrderedDict([('weights', tensor([0.5739])), ('bias', tensor([0.3529]))]) \n",
            "\n",
            "Epoch: 19440 | Loss: 0.02532128430902958 | Test loss: 0.05920461565256119\n",
            "OrderedDict([('weights', tensor([0.5740])), ('bias', tensor([0.3529]))]) \n",
            "\n",
            "Epoch: 19450 | Loss: 0.025304105132818222 | Test loss: 0.0591634139418602\n",
            "OrderedDict([('weights', tensor([0.5741])), ('bias', tensor([0.3529]))]) \n",
            "\n",
            "Epoch: 19460 | Loss: 0.02528696320950985 | Test loss: 0.059123892337083817\n",
            "OrderedDict([('weights', tensor([0.5742])), ('bias', tensor([0.3528]))]) \n",
            "\n",
            "Epoch: 19470 | Loss: 0.025269800797104836 | Test loss: 0.05908610299229622\n",
            "OrderedDict([('weights', tensor([0.5743])), ('bias', tensor([0.3528]))]) \n",
            "\n",
            "Epoch: 19480 | Loss: 0.02525266632437706 | Test loss: 0.05904487520456314\n",
            "OrderedDict([('weights', tensor([0.5744])), ('bias', tensor([0.3528]))]) \n",
            "\n",
            "Epoch: 19490 | Loss: 0.02523549273610115 | Test loss: 0.05900363251566887\n",
            "OrderedDict([('weights', tensor([0.5745])), ('bias', tensor([0.3527]))]) \n",
            "\n",
            "Epoch: 19500 | Loss: 0.02521831914782524 | Test loss: 0.05896584317088127\n",
            "OrderedDict([('weights', tensor([0.5745])), ('bias', tensor([0.3527]))]) \n",
            "\n",
            "Epoch: 19510 | Loss: 0.025201186537742615 | Test loss: 0.05892461538314819\n",
            "OrderedDict([('weights', tensor([0.5746])), ('bias', tensor([0.3527]))]) \n",
            "\n",
            "Epoch: 19520 | Loss: 0.025184016674757004 | Test loss: 0.058885104954242706\n",
            "OrderedDict([('weights', tensor([0.5747])), ('bias', tensor([0.3526]))]) \n",
            "\n",
            "Epoch: 19530 | Loss: 0.025166859850287437 | Test loss: 0.05884387344121933\n",
            "OrderedDict([('weights', tensor([0.5748])), ('bias', tensor([0.3526]))]) \n",
            "\n",
            "Epoch: 19540 | Loss: 0.02514968439936638 | Test loss: 0.05880265310406685\n",
            "OrderedDict([('weights', tensor([0.5749])), ('bias', tensor([0.3525]))]) \n",
            "\n",
            "Epoch: 19550 | Loss: 0.02513253688812256 | Test loss: 0.058764856308698654\n",
            "OrderedDict([('weights', tensor([0.5750])), ('bias', tensor([0.3525]))]) \n",
            "\n",
            "Epoch: 19560 | Loss: 0.025115394964814186 | Test loss: 0.05872363597154617\n",
            "OrderedDict([('weights', tensor([0.5751])), ('bias', tensor([0.3525]))]) \n",
            "\n",
            "Epoch: 19570 | Loss: 0.02509821020066738 | Test loss: 0.058682382106781006\n",
            "OrderedDict([('weights', tensor([0.5751])), ('bias', tensor([0.3524]))]) \n",
            "\n",
            "Epoch: 19580 | Loss: 0.02508106268942356 | Test loss: 0.05864288657903671\n",
            "OrderedDict([('weights', tensor([0.5752])), ('bias', tensor([0.3524]))]) \n",
            "\n",
            "Epoch: 19590 | Loss: 0.025063883513212204 | Test loss: 0.05860164761543274\n",
            "OrderedDict([('weights', tensor([0.5753])), ('bias', tensor([0.3524]))]) \n",
            "\n",
            "Epoch: 19600 | Loss: 0.025046750903129578 | Test loss: 0.05856386944651604\n",
            "OrderedDict([('weights', tensor([0.5754])), ('bias', tensor([0.3523]))]) \n",
            "\n",
            "Epoch: 19610 | Loss: 0.02502959407866001 | Test loss: 0.05852262303233147\n",
            "OrderedDict([('weights', tensor([0.5755])), ('bias', tensor([0.3523]))]) \n",
            "\n",
            "Epoch: 19620 | Loss: 0.025012413039803505 | Test loss: 0.058481406420469284\n",
            "OrderedDict([('weights', tensor([0.5756])), ('bias', tensor([0.3523]))]) \n",
            "\n",
            "Epoch: 19630 | Loss: 0.02499527484178543 | Test loss: 0.058443617075681686\n",
            "OrderedDict([('weights', tensor([0.5757])), ('bias', tensor([0.3522]))]) \n",
            "\n",
            "Epoch: 19640 | Loss: 0.024978097528219223 | Test loss: 0.05840412899851799\n",
            "OrderedDict([('weights', tensor([0.5757])), ('bias', tensor([0.3522]))]) \n",
            "\n",
            "Epoch: 19650 | Loss: 0.024960970506072044 | Test loss: 0.05836288258433342\n",
            "OrderedDict([('weights', tensor([0.5758])), ('bias', tensor([0.3522]))]) \n",
            "\n",
            "Epoch: 19660 | Loss: 0.024943795055150986 | Test loss: 0.05832163617014885\n",
            "OrderedDict([('weights', tensor([0.5759])), ('bias', tensor([0.3521]))]) \n",
            "\n",
            "Epoch: 19670 | Loss: 0.024926623329520226 | Test loss: 0.05828387290239334\n",
            "OrderedDict([('weights', tensor([0.5760])), ('bias', tensor([0.3521]))]) \n",
            "\n",
            "Epoch: 19680 | Loss: 0.024909498170018196 | Test loss: 0.058242641389369965\n",
            "OrderedDict([('weights', tensor([0.5761])), ('bias', tensor([0.3520]))]) \n",
            "\n",
            "Epoch: 19690 | Loss: 0.02489231899380684 | Test loss: 0.058201391249895096\n",
            "OrderedDict([('weights', tensor([0.5762])), ('bias', tensor([0.3520]))]) \n",
            "\n",
            "Epoch: 19700 | Loss: 0.02487516961991787 | Test loss: 0.0581619031727314\n",
            "OrderedDict([('weights', tensor([0.5763])), ('bias', tensor([0.3520]))]) \n",
            "\n",
            "Epoch: 19710 | Loss: 0.02485799416899681 | Test loss: 0.05812065675854683\n",
            "OrderedDict([('weights', tensor([0.5763])), ('bias', tensor([0.3519]))]) \n",
            "\n",
            "Epoch: 19720 | Loss: 0.024840837344527245 | Test loss: 0.05808286741375923\n",
            "OrderedDict([('weights', tensor([0.5764])), ('bias', tensor([0.3519]))]) \n",
            "\n",
            "Epoch: 19730 | Loss: 0.02482370100915432 | Test loss: 0.058041639626026154\n",
            "OrderedDict([('weights', tensor([0.5765])), ('bias', tensor([0.3519]))]) \n",
            "\n",
            "Epoch: 19740 | Loss: 0.024806519970297813 | Test loss: 0.05800040811300278\n",
            "OrderedDict([('weights', tensor([0.5766])), ('bias', tensor([0.3518]))]) \n",
            "\n",
            "Epoch: 19750 | Loss: 0.024789361283183098 | Test loss: 0.057962626218795776\n",
            "OrderedDict([('weights', tensor([0.5767])), ('bias', tensor([0.3518]))]) \n",
            "\n",
            "Epoch: 19760 | Loss: 0.024772191420197487 | Test loss: 0.05791967362165451\n",
            "OrderedDict([('weights', tensor([0.5768])), ('bias', tensor([0.3518]))]) \n",
            "\n",
            "Epoch: 19770 | Loss: 0.02475505694746971 | Test loss: 0.05788187310099602\n",
            "OrderedDict([('weights', tensor([0.5768])), ('bias', tensor([0.3517]))]) \n",
            "\n",
            "Epoch: 19780 | Loss: 0.024737898260354996 | Test loss: 0.057840634137392044\n",
            "OrderedDict([('weights', tensor([0.5769])), ('bias', tensor([0.3517]))]) \n",
            "\n",
            "Epoch: 19790 | Loss: 0.02472071908414364 | Test loss: 0.057799406349658966\n",
            "OrderedDict([('weights', tensor([0.5770])), ('bias', tensor([0.3517]))]) \n",
            "\n",
            "Epoch: 19800 | Loss: 0.024703573435544968 | Test loss: 0.05776163935661316\n",
            "OrderedDict([('weights', tensor([0.5771])), ('bias', tensor([0.3516]))]) \n",
            "\n",
            "Epoch: 19810 | Loss: 0.024686429649591446 | Test loss: 0.057720400393009186\n",
            "OrderedDict([('weights', tensor([0.5772])), ('bias', tensor([0.3516]))]) \n",
            "\n",
            "Epoch: 19820 | Loss: 0.024669276550412178 | Test loss: 0.0576808862388134\n",
            "OrderedDict([('weights', tensor([0.5773])), ('bias', tensor([0.3515]))]) \n",
            "\n",
            "Epoch: 19830 | Loss: 0.02465209737420082 | Test loss: 0.057639651000499725\n",
            "OrderedDict([('weights', tensor([0.5774])), ('bias', tensor([0.3515]))]) \n",
            "\n",
            "Epoch: 19840 | Loss: 0.02463492378592491 | Test loss: 0.05760188773274422\n",
            "OrderedDict([('weights', tensor([0.5774])), ('bias', tensor([0.3515]))]) \n",
            "\n",
            "Epoch: 19850 | Loss: 0.024617787450551987 | Test loss: 0.05756063386797905\n",
            "OrderedDict([('weights', tensor([0.5775])), ('bias', tensor([0.3514]))]) \n",
            "\n",
            "Epoch: 19860 | Loss: 0.024600625038146973 | Test loss: 0.05751940608024597\n",
            "OrderedDict([('weights', tensor([0.5776])), ('bias', tensor([0.3514]))]) \n",
            "\n",
            "Epoch: 19870 | Loss: 0.024583453312516212 | Test loss: 0.05747989937663078\n",
            "OrderedDict([('weights', tensor([0.5777])), ('bias', tensor([0.3514]))]) \n",
            "\n",
            "Epoch: 19880 | Loss: 0.024566298350691795 | Test loss: 0.05743866041302681\n",
            "OrderedDict([('weights', tensor([0.5778])), ('bias', tensor([0.3513]))]) \n",
            "\n",
            "Epoch: 19890 | Loss: 0.02454913780093193 | Test loss: 0.057400912046432495\n",
            "OrderedDict([('weights', tensor([0.5779])), ('bias', tensor([0.3513]))]) \n",
            "\n",
            "Epoch: 19900 | Loss: 0.024532008916139603 | Test loss: 0.057359665632247925\n",
            "OrderedDict([('weights', tensor([0.5780])), ('bias', tensor([0.3513]))]) \n",
            "\n",
            "Epoch: 19910 | Loss: 0.024514824151992798 | Test loss: 0.05731840059161186\n",
            "OrderedDict([('weights', tensor([0.5780])), ('bias', tensor([0.3512]))]) \n",
            "\n",
            "Epoch: 19920 | Loss: 0.024497661739587784 | Test loss: 0.05728065222501755\n",
            "OrderedDict([('weights', tensor([0.5781])), ('bias', tensor([0.3512]))]) \n",
            "\n",
            "Epoch: 19930 | Loss: 0.02448050118982792 | Test loss: 0.057237666100263596\n",
            "OrderedDict([('weights', tensor([0.5782])), ('bias', tensor([0.3512]))]) \n",
            "\n",
            "Epoch: 19940 | Loss: 0.02446335181593895 | Test loss: 0.05719990283250809\n",
            "OrderedDict([('weights', tensor([0.5783])), ('bias', tensor([0.3511]))]) \n",
            "\n",
            "Epoch: 19950 | Loss: 0.024446208029985428 | Test loss: 0.05715867877006531\n",
            "OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3511]))]) \n",
            "\n",
            "Epoch: 19960 | Loss: 0.02442902885377407 | Test loss: 0.05711743235588074\n",
            "OrderedDict([('weights', tensor([0.5785])), ('bias', tensor([0.3510]))]) \n",
            "\n",
            "Epoch: 19970 | Loss: 0.024411877617239952 | Test loss: 0.05707965046167374\n",
            "OrderedDict([('weights', tensor([0.5786])), ('bias', tensor([0.3510]))]) \n",
            "\n",
            "Epoch: 19980 | Loss: 0.02439473755657673 | Test loss: 0.05703843757510185\n",
            "OrderedDict([('weights', tensor([0.5786])), ('bias', tensor([0.3510]))]) \n",
            "\n",
            "Epoch: 19990 | Loss: 0.024377571418881416 | Test loss: 0.05699890851974487\n",
            "OrderedDict([('weights', tensor([0.5787])), ('bias', tensor([0.3509]))]) \n",
            "\n",
            "Epoch: 20000 | Loss: 0.024360403418540955 | Test loss: 0.0569576695561409\n",
            "OrderedDict([('weights', tensor([0.5788])), ('bias', tensor([0.3509]))]) \n",
            "\n",
            "Epoch: 20010 | Loss: 0.024343229830265045 | Test loss: 0.05691990256309509\n",
            "OrderedDict([('weights', tensor([0.5789])), ('bias', tensor([0.3509]))]) \n",
            "\n",
            "Epoch: 20020 | Loss: 0.02432609722018242 | Test loss: 0.056878648698329926\n",
            "OrderedDict([('weights', tensor([0.5790])), ('bias', tensor([0.3508]))]) \n",
            "\n",
            "Epoch: 20030 | Loss: 0.024308931082487106 | Test loss: 0.05683741718530655\n",
            "OrderedDict([('weights', tensor([0.5791])), ('bias', tensor([0.3508]))]) \n",
            "\n",
            "Epoch: 20040 | Loss: 0.0242917500436306 | Test loss: 0.05679621547460556\n",
            "OrderedDict([('weights', tensor([0.5792])), ('bias', tensor([0.3508]))]) \n",
            "\n",
            "Epoch: 20050 | Loss: 0.024274608120322227 | Test loss: 0.05675669386982918\n",
            "OrderedDict([('weights', tensor([0.5792])), ('bias', tensor([0.3507]))]) \n",
            "\n",
            "Epoch: 20060 | Loss: 0.024257445707917213 | Test loss: 0.05671890452504158\n",
            "OrderedDict([('weights', tensor([0.5793])), ('bias', tensor([0.3507]))]) \n",
            "\n",
            "Epoch: 20070 | Loss: 0.024240314960479736 | Test loss: 0.0566776767373085\n",
            "OrderedDict([('weights', tensor([0.5794])), ('bias', tensor([0.3506]))]) \n",
            "\n",
            "Epoch: 20080 | Loss: 0.02422313578426838 | Test loss: 0.05663643404841423\n",
            "OrderedDict([('weights', tensor([0.5795])), ('bias', tensor([0.3506]))]) \n",
            "\n",
            "Epoch: 20090 | Loss: 0.02420596405863762 | Test loss: 0.05659864470362663\n",
            "OrderedDict([('weights', tensor([0.5796])), ('bias', tensor([0.3506]))]) \n",
            "\n",
            "Epoch: 20100 | Loss: 0.024188831448554993 | Test loss: 0.056557416915893555\n",
            "OrderedDict([('weights', tensor([0.5797])), ('bias', tensor([0.3505]))]) \n",
            "\n",
            "Epoch: 20110 | Loss: 0.02417166158556938 | Test loss: 0.05651790648698807\n",
            "OrderedDict([('weights', tensor([0.5798])), ('bias', tensor([0.3505]))]) \n",
            "\n",
            "Epoch: 20120 | Loss: 0.024154504761099815 | Test loss: 0.05647667497396469\n",
            "OrderedDict([('weights', tensor([0.5798])), ('bias', tensor([0.3505]))]) \n",
            "\n",
            "Epoch: 20130 | Loss: 0.024137329310178757 | Test loss: 0.05643545463681221\n",
            "OrderedDict([('weights', tensor([0.5799])), ('bias', tensor([0.3504]))]) \n",
            "\n",
            "Epoch: 20140 | Loss: 0.024120181798934937 | Test loss: 0.056397657841444016\n",
            "OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3504]))]) \n",
            "\n",
            "Epoch: 20150 | Loss: 0.024103038012981415 | Test loss: 0.056356437504291534\n",
            "OrderedDict([('weights', tensor([0.5801])), ('bias', tensor([0.3504]))]) \n",
            "\n",
            "Epoch: 20160 | Loss: 0.02408585511147976 | Test loss: 0.05631518363952637\n",
            "OrderedDict([('weights', tensor([0.5802])), ('bias', tensor([0.3503]))]) \n",
            "\n",
            "Epoch: 20170 | Loss: 0.02406870760023594 | Test loss: 0.056275688111782074\n",
            "OrderedDict([('weights', tensor([0.5803])), ('bias', tensor([0.3503]))]) \n",
            "\n",
            "Epoch: 20180 | Loss: 0.024051528424024582 | Test loss: 0.0562344491481781\n",
            "OrderedDict([('weights', tensor([0.5803])), ('bias', tensor([0.3503]))]) \n",
            "\n",
            "Epoch: 20190 | Loss: 0.024034395813941956 | Test loss: 0.0561966709792614\n",
            "OrderedDict([('weights', tensor([0.5804])), ('bias', tensor([0.3502]))]) \n",
            "\n",
            "Epoch: 20200 | Loss: 0.02401723898947239 | Test loss: 0.05615542456507683\n",
            "OrderedDict([('weights', tensor([0.5805])), ('bias', tensor([0.3502]))]) \n",
            "\n",
            "Epoch: 20210 | Loss: 0.024000057950615883 | Test loss: 0.056114207953214645\n",
            "OrderedDict([('weights', tensor([0.5806])), ('bias', tensor([0.3501]))]) \n",
            "\n",
            "Epoch: 20220 | Loss: 0.02398291975259781 | Test loss: 0.05607641860842705\n",
            "OrderedDict([('weights', tensor([0.5807])), ('bias', tensor([0.3501]))]) \n",
            "\n",
            "Epoch: 20230 | Loss: 0.0239657424390316 | Test loss: 0.05603693053126335\n",
            "OrderedDict([('weights', tensor([0.5808])), ('bias', tensor([0.3501]))]) \n",
            "\n",
            "Epoch: 20240 | Loss: 0.023948615416884422 | Test loss: 0.05599568411707878\n",
            "OrderedDict([('weights', tensor([0.5809])), ('bias', tensor([0.3500]))]) \n",
            "\n",
            "Epoch: 20250 | Loss: 0.023931439965963364 | Test loss: 0.05595443770289421\n",
            "OrderedDict([('weights', tensor([0.5809])), ('bias', tensor([0.3500]))]) \n",
            "\n",
            "Epoch: 20260 | Loss: 0.023914268240332603 | Test loss: 0.0559166744351387\n",
            "OrderedDict([('weights', tensor([0.5810])), ('bias', tensor([0.3500]))]) \n",
            "\n",
            "Epoch: 20270 | Loss: 0.023897143080830574 | Test loss: 0.055875442922115326\n",
            "OrderedDict([('weights', tensor([0.5811])), ('bias', tensor([0.3499]))]) \n",
            "\n",
            "Epoch: 20280 | Loss: 0.023879963904619217 | Test loss: 0.05583419278264046\n",
            "OrderedDict([('weights', tensor([0.5812])), ('bias', tensor([0.3499]))]) \n",
            "\n",
            "Epoch: 20290 | Loss: 0.023862814530730247 | Test loss: 0.05579470470547676\n",
            "OrderedDict([('weights', tensor([0.5813])), ('bias', tensor([0.3499]))]) \n",
            "\n",
            "Epoch: 20300 | Loss: 0.02384563907980919 | Test loss: 0.05575345829129219\n",
            "OrderedDict([('weights', tensor([0.5814])), ('bias', tensor([0.3498]))]) \n",
            "\n",
            "Epoch: 20310 | Loss: 0.023828482255339622 | Test loss: 0.05571567267179489\n",
            "OrderedDict([('weights', tensor([0.5815])), ('bias', tensor([0.3498]))]) \n",
            "\n",
            "Epoch: 20320 | Loss: 0.023811345919966698 | Test loss: 0.055674441158771515\n",
            "OrderedDict([('weights', tensor([0.5815])), ('bias', tensor([0.3498]))]) \n",
            "\n",
            "Epoch: 20330 | Loss: 0.02379416488111019 | Test loss: 0.05563320964574814\n",
            "OrderedDict([('weights', tensor([0.5816])), ('bias', tensor([0.3497]))]) \n",
            "\n",
            "Epoch: 20340 | Loss: 0.023777004331350327 | Test loss: 0.05559542775154114\n",
            "OrderedDict([('weights', tensor([0.5817])), ('bias', tensor([0.3497]))]) \n",
            "\n",
            "Epoch: 20350 | Loss: 0.023759836331009865 | Test loss: 0.05555248260498047\n",
            "OrderedDict([('weights', tensor([0.5818])), ('bias', tensor([0.3496]))]) \n",
            "\n",
            "Epoch: 20360 | Loss: 0.02374269999563694 | Test loss: 0.05551467463374138\n",
            "OrderedDict([('weights', tensor([0.5819])), ('bias', tensor([0.3496]))]) \n",
            "\n",
            "Epoch: 20370 | Loss: 0.023725543171167374 | Test loss: 0.055473439395427704\n",
            "OrderedDict([('weights', tensor([0.5820])), ('bias', tensor([0.3496]))]) \n",
            "\n",
            "Epoch: 20380 | Loss: 0.023708367720246315 | Test loss: 0.05543220788240433\n",
            "OrderedDict([('weights', tensor([0.5821])), ('bias', tensor([0.3495]))]) \n",
            "\n",
            "Epoch: 20390 | Loss: 0.023691218346357346 | Test loss: 0.05539444088935852\n",
            "OrderedDict([('weights', tensor([0.5821])), ('bias', tensor([0.3495]))]) \n",
            "\n",
            "Epoch: 20400 | Loss: 0.023674074560403824 | Test loss: 0.05535320192575455\n",
            "OrderedDict([('weights', tensor([0.5822])), ('bias', tensor([0.3495]))]) \n",
            "\n",
            "Epoch: 20410 | Loss: 0.023656921461224556 | Test loss: 0.05531368777155876\n",
            "OrderedDict([('weights', tensor([0.5823])), ('bias', tensor([0.3494]))]) \n",
            "\n",
            "Epoch: 20420 | Loss: 0.023639746010303497 | Test loss: 0.05527245253324509\n",
            "OrderedDict([('weights', tensor([0.5824])), ('bias', tensor([0.3494]))]) \n",
            "\n",
            "Epoch: 20430 | Loss: 0.023622572422027588 | Test loss: 0.05523468181490898\n",
            "OrderedDict([('weights', tensor([0.5825])), ('bias', tensor([0.3494]))]) \n",
            "\n",
            "Epoch: 20440 | Loss: 0.023605432361364365 | Test loss: 0.05519343540072441\n",
            "OrderedDict([('weights', tensor([0.5826])), ('bias', tensor([0.3493]))]) \n",
            "\n",
            "Epoch: 20450 | Loss: 0.02358826994895935 | Test loss: 0.05515220761299133\n",
            "OrderedDict([('weights', tensor([0.5827])), ('bias', tensor([0.3493]))]) \n",
            "\n",
            "Epoch: 20460 | Loss: 0.02357109822332859 | Test loss: 0.055112700909376144\n",
            "OrderedDict([('weights', tensor([0.5827])), ('bias', tensor([0.3492]))]) \n",
            "\n",
            "Epoch: 20470 | Loss: 0.023553943261504173 | Test loss: 0.055071454495191574\n",
            "OrderedDict([('weights', tensor([0.5828])), ('bias', tensor([0.3492]))]) \n",
            "\n",
            "Epoch: 20480 | Loss: 0.02353678271174431 | Test loss: 0.055033713579177856\n",
            "OrderedDict([('weights', tensor([0.5829])), ('bias', tensor([0.3492]))]) \n",
            "\n",
            "Epoch: 20490 | Loss: 0.02351965382695198 | Test loss: 0.05499245971441269\n",
            "OrderedDict([('weights', tensor([0.5830])), ('bias', tensor([0.3491]))]) \n",
            "\n",
            "Epoch: 20500 | Loss: 0.023502469062805176 | Test loss: 0.054951202124357224\n",
            "OrderedDict([('weights', tensor([0.5831])), ('bias', tensor([0.3491]))]) \n",
            "\n",
            "Epoch: 20510 | Loss: 0.02348530851304531 | Test loss: 0.054913461208343506\n",
            "OrderedDict([('weights', tensor([0.5832])), ('bias', tensor([0.3491]))]) \n",
            "\n",
            "Epoch: 20520 | Loss: 0.023468146100640297 | Test loss: 0.05487046763300896\n",
            "OrderedDict([('weights', tensor([0.5833])), ('bias', tensor([0.3490]))]) \n",
            "\n",
            "Epoch: 20530 | Loss: 0.023450996726751328 | Test loss: 0.05483270436525345\n",
            "OrderedDict([('weights', tensor([0.5833])), ('bias', tensor([0.3490]))]) \n",
            "\n",
            "Epoch: 20540 | Loss: 0.023433852940797806 | Test loss: 0.05479148030281067\n",
            "OrderedDict([('weights', tensor([0.5834])), ('bias', tensor([0.3490]))]) \n",
            "\n",
            "Epoch: 20550 | Loss: 0.02341667376458645 | Test loss: 0.054750241339206696\n",
            "OrderedDict([('weights', tensor([0.5835])), ('bias', tensor([0.3489]))]) \n",
            "\n",
            "Epoch: 20560 | Loss: 0.02339952252805233 | Test loss: 0.0547124519944191\n",
            "OrderedDict([('weights', tensor([0.5836])), ('bias', tensor([0.3489]))]) \n",
            "\n",
            "Epoch: 20570 | Loss: 0.023382382467389107 | Test loss: 0.05467124655842781\n",
            "OrderedDict([('weights', tensor([0.5837])), ('bias', tensor([0.3489]))]) \n",
            "\n",
            "Epoch: 20580 | Loss: 0.023365216329693794 | Test loss: 0.054631710052490234\n",
            "OrderedDict([('weights', tensor([0.5838])), ('bias', tensor([0.3488]))]) \n",
            "\n",
            "Epoch: 20590 | Loss: 0.023348048329353333 | Test loss: 0.05459047108888626\n",
            "OrderedDict([('weights', tensor([0.5838])), ('bias', tensor([0.3488]))]) \n",
            "\n",
            "Epoch: 20600 | Loss: 0.023330874741077423 | Test loss: 0.054552704095840454\n",
            "OrderedDict([('weights', tensor([0.5839])), ('bias', tensor([0.3487]))]) \n",
            "\n",
            "Epoch: 20610 | Loss: 0.023313742130994797 | Test loss: 0.05451145023107529\n",
            "OrderedDict([('weights', tensor([0.5840])), ('bias', tensor([0.3487]))]) \n",
            "\n",
            "Epoch: 20620 | Loss: 0.023296577855944633 | Test loss: 0.05447021871805191\n",
            "OrderedDict([('weights', tensor([0.5841])), ('bias', tensor([0.3487]))]) \n",
            "\n",
            "Epoch: 20630 | Loss: 0.023279394954442978 | Test loss: 0.05442901700735092\n",
            "OrderedDict([('weights', tensor([0.5842])), ('bias', tensor([0.3486]))]) \n",
            "\n",
            "Epoch: 20640 | Loss: 0.023262253031134605 | Test loss: 0.05438949540257454\n",
            "OrderedDict([('weights', tensor([0.5843])), ('bias', tensor([0.3486]))]) \n",
            "\n",
            "Epoch: 20650 | Loss: 0.02324509061872959 | Test loss: 0.05435170605778694\n",
            "OrderedDict([('weights', tensor([0.5844])), ('bias', tensor([0.3486]))]) \n",
            "\n",
            "Epoch: 20660 | Loss: 0.023227959871292114 | Test loss: 0.054310478270053864\n",
            "OrderedDict([('weights', tensor([0.5844])), ('bias', tensor([0.3485]))]) \n",
            "\n",
            "Epoch: 20670 | Loss: 0.023210780695080757 | Test loss: 0.05426923185586929\n",
            "OrderedDict([('weights', tensor([0.5845])), ('bias', tensor([0.3485]))]) \n",
            "\n",
            "Epoch: 20680 | Loss: 0.023193608969449997 | Test loss: 0.054231446236371994\n",
            "OrderedDict([('weights', tensor([0.5846])), ('bias', tensor([0.3485]))]) \n",
            "\n",
            "Epoch: 20690 | Loss: 0.02317647635936737 | Test loss: 0.05419021099805832\n",
            "OrderedDict([('weights', tensor([0.5847])), ('bias', tensor([0.3484]))]) \n",
            "\n",
            "Epoch: 20700 | Loss: 0.02315930649638176 | Test loss: 0.05415071174502373\n",
            "OrderedDict([('weights', tensor([0.5848])), ('bias', tensor([0.3484]))]) \n",
            "\n",
            "Epoch: 20710 | Loss: 0.023142149671912193 | Test loss: 0.05410947650671005\n",
            "OrderedDict([('weights', tensor([0.5849])), ('bias', tensor([0.3484]))]) \n",
            "\n",
            "Epoch: 20720 | Loss: 0.023124974220991135 | Test loss: 0.05406825616955757\n",
            "OrderedDict([('weights', tensor([0.5850])), ('bias', tensor([0.3483]))]) \n",
            "\n",
            "Epoch: 20730 | Loss: 0.023107826709747314 | Test loss: 0.05403045937418938\n",
            "OrderedDict([('weights', tensor([0.5850])), ('bias', tensor([0.3483]))]) \n",
            "\n",
            "Epoch: 20740 | Loss: 0.023090682923793793 | Test loss: 0.053989239037036896\n",
            "OrderedDict([('weights', tensor([0.5851])), ('bias', tensor([0.3482]))]) \n",
            "\n",
            "Epoch: 20750 | Loss: 0.023073500022292137 | Test loss: 0.053947992622852325\n",
            "OrderedDict([('weights', tensor([0.5852])), ('bias', tensor([0.3482]))]) \n",
            "\n",
            "Epoch: 20760 | Loss: 0.023056352511048317 | Test loss: 0.05390849709510803\n",
            "OrderedDict([('weights', tensor([0.5853])), ('bias', tensor([0.3482]))]) \n",
            "\n",
            "Epoch: 20770 | Loss: 0.02303917333483696 | Test loss: 0.05386725813150406\n",
            "OrderedDict([('weights', tensor([0.5854])), ('bias', tensor([0.3481]))]) \n",
            "\n",
            "Epoch: 20780 | Loss: 0.023022040724754333 | Test loss: 0.05382947251200676\n",
            "OrderedDict([('weights', tensor([0.5855])), ('bias', tensor([0.3481]))]) \n",
            "\n",
            "Epoch: 20790 | Loss: 0.023004883900284767 | Test loss: 0.05378822609782219\n",
            "OrderedDict([('weights', tensor([0.5856])), ('bias', tensor([0.3481]))]) \n",
            "\n",
            "Epoch: 20800 | Loss: 0.02298770472407341 | Test loss: 0.05374700948596001\n",
            "OrderedDict([('weights', tensor([0.5856])), ('bias', tensor([0.3480]))]) \n",
            "\n",
            "Epoch: 20810 | Loss: 0.022970564663410187 | Test loss: 0.05370922014117241\n",
            "OrderedDict([('weights', tensor([0.5857])), ('bias', tensor([0.3480]))]) \n",
            "\n",
            "Epoch: 20820 | Loss: 0.02295338734984398 | Test loss: 0.053669728338718414\n",
            "OrderedDict([('weights', tensor([0.5858])), ('bias', tensor([0.3480]))]) \n",
            "\n",
            "Epoch: 20830 | Loss: 0.02293625846505165 | Test loss: 0.05362848564982414\n",
            "OrderedDict([('weights', tensor([0.5859])), ('bias', tensor([0.3479]))]) \n",
            "\n",
            "Epoch: 20840 | Loss: 0.02291908487677574 | Test loss: 0.05358723923563957\n",
            "OrderedDict([('weights', tensor([0.5860])), ('bias', tensor([0.3479]))]) \n",
            "\n",
            "Epoch: 20850 | Loss: 0.02290191315114498 | Test loss: 0.053549475967884064\n",
            "OrderedDict([('weights', tensor([0.5861])), ('bias', tensor([0.3478]))]) \n",
            "\n",
            "Epoch: 20860 | Loss: 0.022884787991642952 | Test loss: 0.05350824445486069\n",
            "OrderedDict([('weights', tensor([0.5862])), ('bias', tensor([0.3478]))]) \n",
            "\n",
            "Epoch: 20870 | Loss: 0.022867608815431595 | Test loss: 0.05346698686480522\n",
            "OrderedDict([('weights', tensor([0.5862])), ('bias', tensor([0.3478]))]) \n",
            "\n",
            "Epoch: 20880 | Loss: 0.022850461304187775 | Test loss: 0.053427498787641525\n",
            "OrderedDict([('weights', tensor([0.5863])), ('bias', tensor([0.3477]))]) \n",
            "\n",
            "Epoch: 20890 | Loss: 0.022833283990621567 | Test loss: 0.05338625982403755\n",
            "OrderedDict([('weights', tensor([0.5864])), ('bias', tensor([0.3477]))]) \n",
            "\n",
            "Epoch: 20900 | Loss: 0.022816127166152 | Test loss: 0.05334847420454025\n",
            "OrderedDict([('weights', tensor([0.5865])), ('bias', tensor([0.3477]))]) \n",
            "\n",
            "Epoch: 20910 | Loss: 0.022798990830779076 | Test loss: 0.053307242691516876\n",
            "OrderedDict([('weights', tensor([0.5866])), ('bias', tensor([0.3476]))]) \n",
            "\n",
            "Epoch: 20920 | Loss: 0.02278180979192257 | Test loss: 0.0532660111784935\n",
            "OrderedDict([('weights', tensor([0.5867])), ('bias', tensor([0.3476]))]) \n",
            "\n",
            "Epoch: 20930 | Loss: 0.022764649242162704 | Test loss: 0.053228236734867096\n",
            "OrderedDict([('weights', tensor([0.5868])), ('bias', tensor([0.3476]))]) \n",
            "\n",
            "Epoch: 20940 | Loss: 0.022747481241822243 | Test loss: 0.05318528413772583\n",
            "OrderedDict([('weights', tensor([0.5868])), ('bias', tensor([0.3475]))]) \n",
            "\n",
            "Epoch: 20950 | Loss: 0.022730344906449318 | Test loss: 0.05314747616648674\n",
            "OrderedDict([('weights', tensor([0.5869])), ('bias', tensor([0.3475]))]) \n",
            "\n",
            "Epoch: 20960 | Loss: 0.02271318808197975 | Test loss: 0.053106240928173065\n",
            "OrderedDict([('weights', tensor([0.5870])), ('bias', tensor([0.3475]))]) \n",
            "\n",
            "Epoch: 20970 | Loss: 0.022696012631058693 | Test loss: 0.05306500941514969\n",
            "OrderedDict([('weights', tensor([0.5871])), ('bias', tensor([0.3474]))]) \n",
            "\n",
            "Epoch: 20980 | Loss: 0.022678863257169724 | Test loss: 0.05302724242210388\n",
            "OrderedDict([('weights', tensor([0.5872])), ('bias', tensor([0.3474]))]) \n",
            "\n",
            "Epoch: 20990 | Loss: 0.022661715745925903 | Test loss: 0.05298600345849991\n",
            "OrderedDict([('weights', tensor([0.5873])), ('bias', tensor([0.3473]))]) \n",
            "\n",
            "Epoch: 21000 | Loss: 0.022644566372036934 | Test loss: 0.05294648930430412\n",
            "OrderedDict([('weights', tensor([0.5873])), ('bias', tensor([0.3473]))]) \n",
            "\n",
            "Epoch: 21010 | Loss: 0.022627390921115875 | Test loss: 0.05290525406599045\n",
            "OrderedDict([('weights', tensor([0.5874])), ('bias', tensor([0.3473]))]) \n",
            "\n",
            "Epoch: 21020 | Loss: 0.022610217332839966 | Test loss: 0.05286748334765434\n",
            "OrderedDict([('weights', tensor([0.5875])), ('bias', tensor([0.3472]))]) \n",
            "\n",
            "Epoch: 21030 | Loss: 0.022593077272176743 | Test loss: 0.05282623693346977\n",
            "OrderedDict([('weights', tensor([0.5876])), ('bias', tensor([0.3472]))]) \n",
            "\n",
            "Epoch: 21040 | Loss: 0.02257591485977173 | Test loss: 0.052785009145736694\n",
            "OrderedDict([('weights', tensor([0.5877])), ('bias', tensor([0.3472]))]) \n",
            "\n",
            "Epoch: 21050 | Loss: 0.02255874313414097 | Test loss: 0.052745502442121506\n",
            "OrderedDict([('weights', tensor([0.5878])), ('bias', tensor([0.3471]))]) \n",
            "\n",
            "Epoch: 21060 | Loss: 0.02254159189760685 | Test loss: 0.052704256027936935\n",
            "OrderedDict([('weights', tensor([0.5879])), ('bias', tensor([0.3471]))]) \n",
            "\n",
            "Epoch: 21070 | Loss: 0.022524427622556686 | Test loss: 0.05266651511192322\n",
            "OrderedDict([('weights', tensor([0.5879])), ('bias', tensor([0.3471]))]) \n",
            "\n",
            "Epoch: 21080 | Loss: 0.02250729873776436 | Test loss: 0.05262526124715805\n",
            "OrderedDict([('weights', tensor([0.5880])), ('bias', tensor([0.3470]))]) \n",
            "\n",
            "Epoch: 21090 | Loss: 0.022490113973617554 | Test loss: 0.052584003657102585\n",
            "OrderedDict([('weights', tensor([0.5881])), ('bias', tensor([0.3470]))]) \n",
            "\n",
            "Epoch: 21100 | Loss: 0.02247295342385769 | Test loss: 0.05254626274108887\n",
            "OrderedDict([('weights', tensor([0.5882])), ('bias', tensor([0.3470]))]) \n",
            "\n",
            "Epoch: 21110 | Loss: 0.022455791011452675 | Test loss: 0.05250326916575432\n",
            "OrderedDict([('weights', tensor([0.5883])), ('bias', tensor([0.3469]))]) \n",
            "\n",
            "Epoch: 21120 | Loss: 0.022438641637563705 | Test loss: 0.05246550589799881\n",
            "OrderedDict([('weights', tensor([0.5884])), ('bias', tensor([0.3469]))]) \n",
            "\n",
            "Epoch: 21130 | Loss: 0.022421497851610184 | Test loss: 0.05242428183555603\n",
            "OrderedDict([('weights', tensor([0.5885])), ('bias', tensor([0.3468]))]) \n",
            "\n",
            "Epoch: 21140 | Loss: 0.022404318675398827 | Test loss: 0.05238304287195206\n",
            "OrderedDict([('weights', tensor([0.5885])), ('bias', tensor([0.3468]))]) \n",
            "\n",
            "Epoch: 21150 | Loss: 0.022387167438864708 | Test loss: 0.05234525352716446\n",
            "OrderedDict([('weights', tensor([0.5886])), ('bias', tensor([0.3468]))]) \n",
            "\n",
            "Epoch: 21160 | Loss: 0.022370027378201485 | Test loss: 0.05230404809117317\n",
            "OrderedDict([('weights', tensor([0.5887])), ('bias', tensor([0.3467]))]) \n",
            "\n",
            "Epoch: 21170 | Loss: 0.022352861240506172 | Test loss: 0.052264511585235596\n",
            "OrderedDict([('weights', tensor([0.5888])), ('bias', tensor([0.3467]))]) \n",
            "\n",
            "Epoch: 21180 | Loss: 0.02233569324016571 | Test loss: 0.05222327262163162\n",
            "OrderedDict([('weights', tensor([0.5889])), ('bias', tensor([0.3467]))]) \n",
            "\n",
            "Epoch: 21190 | Loss: 0.0223185196518898 | Test loss: 0.052185505628585815\n",
            "OrderedDict([('weights', tensor([0.5890])), ('bias', tensor([0.3466]))]) \n",
            "\n",
            "Epoch: 21200 | Loss: 0.022301387041807175 | Test loss: 0.05214425176382065\n",
            "OrderedDict([('weights', tensor([0.5891])), ('bias', tensor([0.3466]))]) \n",
            "\n",
            "Epoch: 21210 | Loss: 0.02228422276675701 | Test loss: 0.05210302025079727\n",
            "OrderedDict([('weights', tensor([0.5891])), ('bias', tensor([0.3466]))]) \n",
            "\n",
            "Epoch: 21220 | Loss: 0.022267039865255356 | Test loss: 0.05206181854009628\n",
            "OrderedDict([('weights', tensor([0.5892])), ('bias', tensor([0.3465]))]) \n",
            "\n",
            "Epoch: 21230 | Loss: 0.022249897941946983 | Test loss: 0.0520222969353199\n",
            "OrderedDict([('weights', tensor([0.5893])), ('bias', tensor([0.3465]))]) \n",
            "\n",
            "Epoch: 21240 | Loss: 0.02223273552954197 | Test loss: 0.0519845075905323\n",
            "OrderedDict([('weights', tensor([0.5894])), ('bias', tensor([0.3465]))]) \n",
            "\n",
            "Epoch: 21250 | Loss: 0.022215604782104492 | Test loss: 0.051943279802799225\n",
            "OrderedDict([('weights', tensor([0.5895])), ('bias', tensor([0.3464]))]) \n",
            "\n",
            "Epoch: 21260 | Loss: 0.022198425605893135 | Test loss: 0.051902033388614655\n",
            "OrderedDict([('weights', tensor([0.5896])), ('bias', tensor([0.3464]))]) \n",
            "\n",
            "Epoch: 21270 | Loss: 0.022181253880262375 | Test loss: 0.051864247769117355\n",
            "OrderedDict([('weights', tensor([0.5897])), ('bias', tensor([0.3463]))]) \n",
            "\n",
            "Epoch: 21280 | Loss: 0.02216412127017975 | Test loss: 0.05182301253080368\n",
            "OrderedDict([('weights', tensor([0.5897])), ('bias', tensor([0.3463]))]) \n",
            "\n",
            "Epoch: 21290 | Loss: 0.022146951407194138 | Test loss: 0.05178351327776909\n",
            "OrderedDict([('weights', tensor([0.5898])), ('bias', tensor([0.3463]))]) \n",
            "\n",
            "Epoch: 21300 | Loss: 0.02212979458272457 | Test loss: 0.051742278039455414\n",
            "OrderedDict([('weights', tensor([0.5899])), ('bias', tensor([0.3462]))]) \n",
            "\n",
            "Epoch: 21310 | Loss: 0.022112619131803513 | Test loss: 0.051701050251722336\n",
            "OrderedDict([('weights', tensor([0.5900])), ('bias', tensor([0.3462]))]) \n",
            "\n",
            "Epoch: 21320 | Loss: 0.022095471620559692 | Test loss: 0.05166326090693474\n",
            "OrderedDict([('weights', tensor([0.5901])), ('bias', tensor([0.3462]))]) \n",
            "\n",
            "Epoch: 21330 | Loss: 0.02207832783460617 | Test loss: 0.05162204056978226\n",
            "OrderedDict([('weights', tensor([0.5902])), ('bias', tensor([0.3461]))]) \n",
            "\n",
            "Epoch: 21340 | Loss: 0.022061144933104515 | Test loss: 0.05158079415559769\n",
            "OrderedDict([('weights', tensor([0.5903])), ('bias', tensor([0.3461]))]) \n",
            "\n",
            "Epoch: 21350 | Loss: 0.022043997421860695 | Test loss: 0.0515412911772728\n",
            "OrderedDict([('weights', tensor([0.5903])), ('bias', tensor([0.3461]))]) \n",
            "\n",
            "Epoch: 21360 | Loss: 0.02202681638300419 | Test loss: 0.05150005966424942\n",
            "OrderedDict([('weights', tensor([0.5904])), ('bias', tensor([0.3460]))]) \n",
            "\n",
            "Epoch: 21370 | Loss: 0.02200968563556671 | Test loss: 0.05146227404475212\n",
            "OrderedDict([('weights', tensor([0.5905])), ('bias', tensor([0.3460]))]) \n",
            "\n",
            "Epoch: 21380 | Loss: 0.021992528811097145 | Test loss: 0.05142102763056755\n",
            "OrderedDict([('weights', tensor([0.5906])), ('bias', tensor([0.3460]))]) \n",
            "\n",
            "Epoch: 21390 | Loss: 0.021975349634885788 | Test loss: 0.05137981101870537\n",
            "OrderedDict([('weights', tensor([0.5907])), ('bias', tensor([0.3459]))]) \n",
            "\n",
            "Epoch: 21400 | Loss: 0.021958209574222565 | Test loss: 0.05134202167391777\n",
            "OrderedDict([('weights', tensor([0.5908])), ('bias', tensor([0.3459]))]) \n",
            "\n",
            "Epoch: 21410 | Loss: 0.021941032260656357 | Test loss: 0.051302529871463776\n",
            "OrderedDict([('weights', tensor([0.5908])), ('bias', tensor([0.3458]))]) \n",
            "\n",
            "Epoch: 21420 | Loss: 0.02192390337586403 | Test loss: 0.051261287182569504\n",
            "OrderedDict([('weights', tensor([0.5909])), ('bias', tensor([0.3458]))]) \n",
            "\n",
            "Epoch: 21430 | Loss: 0.02190672978758812 | Test loss: 0.051220040768384933\n",
            "OrderedDict([('weights', tensor([0.5910])), ('bias', tensor([0.3458]))]) \n",
            "\n",
            "Epoch: 21440 | Loss: 0.02188955806195736 | Test loss: 0.051182277500629425\n",
            "OrderedDict([('weights', tensor([0.5911])), ('bias', tensor([0.3457]))]) \n",
            "\n",
            "Epoch: 21450 | Loss: 0.02187243290245533 | Test loss: 0.05114104598760605\n",
            "OrderedDict([('weights', tensor([0.5912])), ('bias', tensor([0.3457]))]) \n",
            "\n",
            "Epoch: 21460 | Loss: 0.021855253726243973 | Test loss: 0.05109978839755058\n",
            "OrderedDict([('weights', tensor([0.5913])), ('bias', tensor([0.3457]))]) \n",
            "\n",
            "Epoch: 21470 | Loss: 0.021838106215000153 | Test loss: 0.05106030032038689\n",
            "OrderedDict([('weights', tensor([0.5914])), ('bias', tensor([0.3456]))]) \n",
            "\n",
            "Epoch: 21480 | Loss: 0.021820928901433945 | Test loss: 0.05101906135678291\n",
            "OrderedDict([('weights', tensor([0.5914])), ('bias', tensor([0.3456]))]) \n",
            "\n",
            "Epoch: 21490 | Loss: 0.02180377207696438 | Test loss: 0.050981275737285614\n",
            "OrderedDict([('weights', tensor([0.5915])), ('bias', tensor([0.3456]))]) \n",
            "\n",
            "Epoch: 21500 | Loss: 0.021786635741591454 | Test loss: 0.05094004422426224\n",
            "OrderedDict([('weights', tensor([0.5916])), ('bias', tensor([0.3455]))]) \n",
            "\n",
            "Epoch: 21510 | Loss: 0.021769454702734947 | Test loss: 0.05089881271123886\n",
            "OrderedDict([('weights', tensor([0.5917])), ('bias', tensor([0.3455]))]) \n",
            "\n",
            "Epoch: 21520 | Loss: 0.021752294152975082 | Test loss: 0.05086103826761246\n",
            "OrderedDict([('weights', tensor([0.5918])), ('bias', tensor([0.3454]))]) \n",
            "\n",
            "Epoch: 21530 | Loss: 0.02173512615263462 | Test loss: 0.05081808567047119\n",
            "OrderedDict([('weights', tensor([0.5919])), ('bias', tensor([0.3454]))]) \n",
            "\n",
            "Epoch: 21540 | Loss: 0.021717991679906845 | Test loss: 0.0507802776992321\n",
            "OrderedDict([('weights', tensor([0.5920])), ('bias', tensor([0.3454]))]) \n",
            "\n",
            "Epoch: 21550 | Loss: 0.02170083299279213 | Test loss: 0.050739042460918427\n",
            "OrderedDict([('weights', tensor([0.5920])), ('bias', tensor([0.3453]))]) \n",
            "\n",
            "Epoch: 21560 | Loss: 0.02168365754187107 | Test loss: 0.05069781094789505\n",
            "OrderedDict([('weights', tensor([0.5921])), ('bias', tensor([0.3453]))]) \n",
            "\n",
            "Epoch: 21570 | Loss: 0.0216665081679821 | Test loss: 0.05066004395484924\n",
            "OrderedDict([('weights', tensor([0.5922])), ('bias', tensor([0.3453]))]) \n",
            "\n",
            "Epoch: 21580 | Loss: 0.02164936065673828 | Test loss: 0.05061880499124527\n",
            "OrderedDict([('weights', tensor([0.5923])), ('bias', tensor([0.3452]))]) \n",
            "\n",
            "Epoch: 21590 | Loss: 0.021632211282849312 | Test loss: 0.050579290837049484\n",
            "OrderedDict([('weights', tensor([0.5924])), ('bias', tensor([0.3452]))]) \n",
            "\n",
            "Epoch: 21600 | Loss: 0.021615035831928253 | Test loss: 0.05053805559873581\n",
            "OrderedDict([('weights', tensor([0.5925])), ('bias', tensor([0.3452]))]) \n",
            "\n",
            "Epoch: 21610 | Loss: 0.021597862243652344 | Test loss: 0.050500284880399704\n",
            "OrderedDict([('weights', tensor([0.5926])), ('bias', tensor([0.3451]))]) \n",
            "\n",
            "Epoch: 21620 | Loss: 0.02158072218298912 | Test loss: 0.050459038466215134\n",
            "OrderedDict([('weights', tensor([0.5926])), ('bias', tensor([0.3451]))]) \n",
            "\n",
            "Epoch: 21630 | Loss: 0.021563559770584106 | Test loss: 0.050417810678482056\n",
            "OrderedDict([('weights', tensor([0.5927])), ('bias', tensor([0.3451]))]) \n",
            "\n",
            "Epoch: 21640 | Loss: 0.021546388044953346 | Test loss: 0.05037830397486687\n",
            "OrderedDict([('weights', tensor([0.5928])), ('bias', tensor([0.3450]))]) \n",
            "\n",
            "Epoch: 21650 | Loss: 0.021529236808419228 | Test loss: 0.0503370575606823\n",
            "OrderedDict([('weights', tensor([0.5929])), ('bias', tensor([0.3450]))]) \n",
            "\n",
            "Epoch: 21660 | Loss: 0.021512072533369064 | Test loss: 0.05029931664466858\n",
            "OrderedDict([('weights', tensor([0.5930])), ('bias', tensor([0.3449]))]) \n",
            "\n",
            "Epoch: 21670 | Loss: 0.021494943648576736 | Test loss: 0.05025806277990341\n",
            "OrderedDict([('weights', tensor([0.5931])), ('bias', tensor([0.3449]))]) \n",
            "\n",
            "Epoch: 21680 | Loss: 0.02147775888442993 | Test loss: 0.050216805189847946\n",
            "OrderedDict([('weights', tensor([0.5932])), ('bias', tensor([0.3449]))]) \n",
            "\n",
            "Epoch: 21690 | Loss: 0.021460598334670067 | Test loss: 0.05017906427383423\n",
            "OrderedDict([('weights', tensor([0.5932])), ('bias', tensor([0.3448]))]) \n",
            "\n",
            "Epoch: 21700 | Loss: 0.021443435922265053 | Test loss: 0.05013607069849968\n",
            "OrderedDict([('weights', tensor([0.5933])), ('bias', tensor([0.3448]))]) \n",
            "\n",
            "Epoch: 21710 | Loss: 0.021426286548376083 | Test loss: 0.05009830743074417\n",
            "OrderedDict([('weights', tensor([0.5934])), ('bias', tensor([0.3448]))]) \n",
            "\n",
            "Epoch: 21720 | Loss: 0.02140914276242256 | Test loss: 0.05005708336830139\n",
            "OrderedDict([('weights', tensor([0.5935])), ('bias', tensor([0.3447]))]) \n",
            "\n",
            "Epoch: 21730 | Loss: 0.021391963586211205 | Test loss: 0.05001584440469742\n",
            "OrderedDict([('weights', tensor([0.5936])), ('bias', tensor([0.3447]))]) \n",
            "\n",
            "Epoch: 21740 | Loss: 0.021374812349677086 | Test loss: 0.04997805505990982\n",
            "OrderedDict([('weights', tensor([0.5937])), ('bias', tensor([0.3447]))]) \n",
            "\n",
            "Epoch: 21750 | Loss: 0.021357672289013863 | Test loss: 0.04993684962391853\n",
            "OrderedDict([('weights', tensor([0.5938])), ('bias', tensor([0.3446]))]) \n",
            "\n",
            "Epoch: 21760 | Loss: 0.02134050615131855 | Test loss: 0.04989731311798096\n",
            "OrderedDict([('weights', tensor([0.5938])), ('bias', tensor([0.3446]))]) \n",
            "\n",
            "Epoch: 21770 | Loss: 0.02132333815097809 | Test loss: 0.049856074154376984\n",
            "OrderedDict([('weights', tensor([0.5939])), ('bias', tensor([0.3446]))]) \n",
            "\n",
            "Epoch: 21780 | Loss: 0.02130616456270218 | Test loss: 0.04981830716133118\n",
            "OrderedDict([('weights', tensor([0.5940])), ('bias', tensor([0.3445]))]) \n",
            "\n",
            "Epoch: 21790 | Loss: 0.021289031952619553 | Test loss: 0.04977705329656601\n",
            "OrderedDict([('weights', tensor([0.5941])), ('bias', tensor([0.3445]))]) \n",
            "\n",
            "Epoch: 21800 | Loss: 0.02127186767756939 | Test loss: 0.04973582178354263\n",
            "OrderedDict([('weights', tensor([0.5942])), ('bias', tensor([0.3444]))]) \n",
            "\n",
            "Epoch: 21810 | Loss: 0.021254684776067734 | Test loss: 0.049694620072841644\n",
            "OrderedDict([('weights', tensor([0.5943])), ('bias', tensor([0.3444]))]) \n",
            "\n",
            "Epoch: 21820 | Loss: 0.02123754285275936 | Test loss: 0.04965509846806526\n",
            "OrderedDict([('weights', tensor([0.5943])), ('bias', tensor([0.3444]))]) \n",
            "\n",
            "Epoch: 21830 | Loss: 0.021220380440354347 | Test loss: 0.049617309123277664\n",
            "OrderedDict([('weights', tensor([0.5944])), ('bias', tensor([0.3443]))]) \n",
            "\n",
            "Epoch: 21840 | Loss: 0.02120324969291687 | Test loss: 0.049576081335544586\n",
            "OrderedDict([('weights', tensor([0.5945])), ('bias', tensor([0.3443]))]) \n",
            "\n",
            "Epoch: 21850 | Loss: 0.021186070516705513 | Test loss: 0.049534834921360016\n",
            "OrderedDict([('weights', tensor([0.5946])), ('bias', tensor([0.3443]))]) \n",
            "\n",
            "Epoch: 21860 | Loss: 0.021168898791074753 | Test loss: 0.04949704930186272\n",
            "OrderedDict([('weights', tensor([0.5947])), ('bias', tensor([0.3442]))]) \n",
            "\n",
            "Epoch: 21870 | Loss: 0.021151766180992126 | Test loss: 0.04945581406354904\n",
            "OrderedDict([('weights', tensor([0.5948])), ('bias', tensor([0.3442]))]) \n",
            "\n",
            "Epoch: 21880 | Loss: 0.021134596318006516 | Test loss: 0.04941631481051445\n",
            "OrderedDict([('weights', tensor([0.5949])), ('bias', tensor([0.3442]))]) \n",
            "\n",
            "Epoch: 21890 | Loss: 0.02111743949353695 | Test loss: 0.049375079572200775\n",
            "OrderedDict([('weights', tensor([0.5949])), ('bias', tensor([0.3441]))]) \n",
            "\n",
            "Epoch: 21900 | Loss: 0.02110026404261589 | Test loss: 0.0493338517844677\n",
            "OrderedDict([('weights', tensor([0.5950])), ('bias', tensor([0.3441]))]) \n",
            "\n",
            "Epoch: 21910 | Loss: 0.02108311653137207 | Test loss: 0.0492960624396801\n",
            "OrderedDict([('weights', tensor([0.5951])), ('bias', tensor([0.3440]))]) \n",
            "\n",
            "Epoch: 21920 | Loss: 0.02106597274541855 | Test loss: 0.04925484210252762\n",
            "OrderedDict([('weights', tensor([0.5952])), ('bias', tensor([0.3440]))]) \n",
            "\n",
            "Epoch: 21930 | Loss: 0.021048789843916893 | Test loss: 0.04921359568834305\n",
            "OrderedDict([('weights', tensor([0.5953])), ('bias', tensor([0.3440]))]) \n",
            "\n",
            "Epoch: 21940 | Loss: 0.021031642332673073 | Test loss: 0.049174100160598755\n",
            "OrderedDict([('weights', tensor([0.5954])), ('bias', tensor([0.3439]))]) \n",
            "\n",
            "Epoch: 21950 | Loss: 0.021014461293816566 | Test loss: 0.04913458973169327\n",
            "OrderedDict([('weights', tensor([0.5955])), ('bias', tensor([0.3439]))]) \n",
            "\n",
            "Epoch: 21960 | Loss: 0.02099732495844364 | Test loss: 0.049093347042798996\n",
            "OrderedDict([('weights', tensor([0.5955])), ('bias', tensor([0.3439]))]) \n",
            "\n",
            "Epoch: 21970 | Loss: 0.02098016068339348 | Test loss: 0.04905560612678528\n",
            "OrderedDict([('weights', tensor([0.5956])), ('bias', tensor([0.3438]))]) \n",
            "\n",
            "Epoch: 21980 | Loss: 0.020962994545698166 | Test loss: 0.04901261255145073\n",
            "OrderedDict([('weights', tensor([0.5957])), ('bias', tensor([0.3438]))]) \n",
            "\n",
            "Epoch: 21990 | Loss: 0.020945854485034943 | Test loss: 0.04897482320666313\n",
            "OrderedDict([('weights', tensor([0.5958])), ('bias', tensor([0.3438]))]) \n",
            "\n",
            "Epoch: 22000 | Loss: 0.020928677171468735 | Test loss: 0.04893533140420914\n",
            "OrderedDict([('weights', tensor([0.5959])), ('bias', tensor([0.3437]))]) \n",
            "\n",
            "Epoch: 22010 | Loss: 0.02091151475906372 | Test loss: 0.04889236018061638\n",
            "OrderedDict([('weights', tensor([0.5960])), ('bias', tensor([0.3437]))]) \n",
            "\n",
            "Epoch: 22020 | Loss: 0.020894382148981094 | Test loss: 0.04885458946228027\n",
            "OrderedDict([('weights', tensor([0.5961])), ('bias', tensor([0.3437]))]) \n",
            "\n",
            "Epoch: 22030 | Loss: 0.020877227187156677 | Test loss: 0.04881337285041809\n",
            "OrderedDict([('weights', tensor([0.5961])), ('bias', tensor([0.3436]))]) \n",
            "\n",
            "Epoch: 22040 | Loss: 0.020860077813267708 | Test loss: 0.04877384752035141\n",
            "OrderedDict([('weights', tensor([0.5962])), ('bias', tensor([0.3436]))]) \n",
            "\n",
            "Epoch: 22050 | Loss: 0.02084289863705635 | Test loss: 0.048732589930295944\n",
            "OrderedDict([('weights', tensor([0.5963])), ('bias', tensor([0.3435]))]) \n",
            "\n",
            "Epoch: 22060 | Loss: 0.02082575298845768 | Test loss: 0.04869310185313225\n",
            "OrderedDict([('weights', tensor([0.5964])), ('bias', tensor([0.3435]))]) \n",
            "\n",
            "Epoch: 22070 | Loss: 0.020808592438697815 | Test loss: 0.048653583973646164\n",
            "OrderedDict([('weights', tensor([0.5965])), ('bias', tensor([0.3435]))]) \n",
            "\n",
            "Epoch: 22080 | Loss: 0.0207914300262928 | Test loss: 0.048612356185913086\n",
            "OrderedDict([('weights', tensor([0.5966])), ('bias', tensor([0.3434]))]) \n",
            "\n",
            "Epoch: 22090 | Loss: 0.020774248987436295 | Test loss: 0.0485728457570076\n",
            "OrderedDict([('weights', tensor([0.5967])), ('bias', tensor([0.3434]))]) \n",
            "\n",
            "Epoch: 22100 | Loss: 0.020757099613547325 | Test loss: 0.04853161424398422\n",
            "OrderedDict([('weights', tensor([0.5967])), ('bias', tensor([0.3434]))]) \n",
            "\n",
            "Epoch: 22110 | Loss: 0.02073993906378746 | Test loss: 0.04849383980035782\n",
            "OrderedDict([('weights', tensor([0.5968])), ('bias', tensor([0.3433]))]) \n",
            "\n",
            "Epoch: 22120 | Loss: 0.020722771063447 | Test loss: 0.048450879752635956\n",
            "OrderedDict([('weights', tensor([0.5969])), ('bias', tensor([0.3433]))]) \n",
            "\n",
            "Epoch: 22130 | Loss: 0.020705625414848328 | Test loss: 0.04841136932373047\n",
            "OrderedDict([('weights', tensor([0.5970])), ('bias', tensor([0.3433]))]) \n",
            "\n",
            "Epoch: 22140 | Loss: 0.020688464865088463 | Test loss: 0.048373591154813766\n",
            "OrderedDict([('weights', tensor([0.5971])), ('bias', tensor([0.3432]))]) \n",
            "\n",
            "Epoch: 22150 | Loss: 0.02067130245268345 | Test loss: 0.04833061248064041\n",
            "OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3432]))]) \n",
            "\n",
            "Epoch: 22160 | Loss: 0.02065415307879448 | Test loss: 0.048292845487594604\n",
            "OrderedDict([('weights', tensor([0.5973])), ('bias', tensor([0.3432]))]) \n",
            "\n",
            "Epoch: 22170 | Loss: 0.02063700556755066 | Test loss: 0.04825160652399063\n",
            "OrderedDict([('weights', tensor([0.5973])), ('bias', tensor([0.3431]))]) \n",
            "\n",
            "Epoch: 22180 | Loss: 0.02061985246837139 | Test loss: 0.048212092369794846\n",
            "OrderedDict([('weights', tensor([0.5974])), ('bias', tensor([0.3431]))]) \n",
            "\n",
            "Epoch: 22190 | Loss: 0.020602675154805183 | Test loss: 0.04817258566617966\n",
            "OrderedDict([('weights', tensor([0.5975])), ('bias', tensor([0.3430]))]) \n",
            "\n",
            "Epoch: 22200 | Loss: 0.020585540682077408 | Test loss: 0.04813135787844658\n",
            "OrderedDict([('weights', tensor([0.5976])), ('bias', tensor([0.3430]))]) \n",
            "\n",
            "Epoch: 22210 | Loss: 0.0205683670938015 | Test loss: 0.048091839998960495\n",
            "OrderedDict([('weights', tensor([0.5977])), ('bias', tensor([0.3430]))]) \n",
            "\n",
            "Epoch: 22220 | Loss: 0.020551204681396484 | Test loss: 0.04805061221122742\n",
            "OrderedDict([('weights', tensor([0.5978])), ('bias', tensor([0.3429]))]) \n",
            "\n",
            "Epoch: 22230 | Loss: 0.020534032955765724 | Test loss: 0.04801110550761223\n",
            "OrderedDict([('weights', tensor([0.5978])), ('bias', tensor([0.3429]))]) \n",
            "\n",
            "Epoch: 22240 | Loss: 0.020516881719231606 | Test loss: 0.04796985909342766\n",
            "OrderedDict([('weights', tensor([0.5979])), ('bias', tensor([0.3429]))]) \n",
            "\n",
            "Epoch: 22250 | Loss: 0.020499736070632935 | Test loss: 0.04793035238981247\n",
            "OrderedDict([('weights', tensor([0.5980])), ('bias', tensor([0.3428]))]) \n",
            "\n",
            "Epoch: 22260 | Loss: 0.020482558757066727 | Test loss: 0.04788913577795029\n",
            "OrderedDict([('weights', tensor([0.5981])), ('bias', tensor([0.3428]))]) \n",
            "\n",
            "Epoch: 22270 | Loss: 0.02046540379524231 | Test loss: 0.04784960672259331\n",
            "OrderedDict([('weights', tensor([0.5982])), ('bias', tensor([0.3428]))]) \n",
            "\n",
            "Epoch: 22280 | Loss: 0.020448243245482445 | Test loss: 0.04781185835599899\n",
            "OrderedDict([('weights', tensor([0.5983])), ('bias', tensor([0.3427]))]) \n",
            "\n",
            "Epoch: 22290 | Loss: 0.02043108083307743 | Test loss: 0.04776887223124504\n",
            "OrderedDict([('weights', tensor([0.5984])), ('bias', tensor([0.3427]))]) \n",
            "\n",
            "Epoch: 22300 | Loss: 0.02041393145918846 | Test loss: 0.04773110896348953\n",
            "OrderedDict([('weights', tensor([0.5984])), ('bias', tensor([0.3427]))]) \n",
            "\n",
            "Epoch: 22310 | Loss: 0.02039676532149315 | Test loss: 0.04769159108400345\n",
            "OrderedDict([('weights', tensor([0.5985])), ('bias', tensor([0.3426]))]) \n",
            "\n",
            "Epoch: 22320 | Loss: 0.020379623398184776 | Test loss: 0.04765036702156067\n",
            "OrderedDict([('weights', tensor([0.5986])), ('bias', tensor([0.3426]))]) \n",
            "\n",
            "Epoch: 22330 | Loss: 0.020362457260489464 | Test loss: 0.047610849142074585\n",
            "OrderedDict([('weights', tensor([0.5987])), ('bias', tensor([0.3425]))]) \n",
            "\n",
            "Epoch: 22340 | Loss: 0.020345313474535942 | Test loss: 0.04756965488195419\n",
            "OrderedDict([('weights', tensor([0.5988])), ('bias', tensor([0.3425]))]) \n",
            "\n",
            "Epoch: 22350 | Loss: 0.020328151062130928 | Test loss: 0.04753011465072632\n",
            "OrderedDict([('weights', tensor([0.5989])), ('bias', tensor([0.3425]))]) \n",
            "\n",
            "Epoch: 22360 | Loss: 0.020310986787080765 | Test loss: 0.047488875687122345\n",
            "OrderedDict([('weights', tensor([0.5990])), ('bias', tensor([0.3424]))]) \n",
            "\n",
            "Epoch: 22370 | Loss: 0.020293835550546646 | Test loss: 0.04744935780763626\n",
            "OrderedDict([('weights', tensor([0.5990])), ('bias', tensor([0.3424]))]) \n",
            "\n",
            "Epoch: 22380 | Loss: 0.02027665451169014 | Test loss: 0.04740814492106438\n",
            "OrderedDict([('weights', tensor([0.5991])), ('bias', tensor([0.3424]))]) \n",
            "\n",
            "Epoch: 22390 | Loss: 0.020259512588381767 | Test loss: 0.04736862704157829\n",
            "OrderedDict([('weights', tensor([0.5992])), ('bias', tensor([0.3423]))]) \n",
            "\n",
            "Epoch: 22400 | Loss: 0.02024232968688011 | Test loss: 0.0473274290561676\n",
            "OrderedDict([('weights', tensor([0.5993])), ('bias', tensor([0.3423]))]) \n",
            "\n",
            "Epoch: 22410 | Loss: 0.02022518776357174 | Test loss: 0.04728790000081062\n",
            "OrderedDict([('weights', tensor([0.5994])), ('bias', tensor([0.3423]))]) \n",
            "\n",
            "Epoch: 22420 | Loss: 0.020208025351166725 | Test loss: 0.047250114381313324\n",
            "OrderedDict([('weights', tensor([0.5995])), ('bias', tensor([0.3422]))]) \n",
            "\n",
            "Epoch: 22430 | Loss: 0.020190861076116562 | Test loss: 0.04720715433359146\n",
            "OrderedDict([('weights', tensor([0.5996])), ('bias', tensor([0.3422]))]) \n",
            "\n",
            "Epoch: 22440 | Loss: 0.02017371915280819 | Test loss: 0.04716935753822327\n",
            "OrderedDict([('weights', tensor([0.5996])), ('bias', tensor([0.3421]))]) \n",
            "\n",
            "Epoch: 22450 | Loss: 0.02015654370188713 | Test loss: 0.04712985083460808\n",
            "OrderedDict([('weights', tensor([0.5997])), ('bias', tensor([0.3421]))]) \n",
            "\n",
            "Epoch: 22460 | Loss: 0.020139411091804504 | Test loss: 0.0470886155962944\n",
            "OrderedDict([('weights', tensor([0.5998])), ('bias', tensor([0.3421]))]) \n",
            "\n",
            "Epoch: 22470 | Loss: 0.020122241228818893 | Test loss: 0.04704912379384041\n",
            "OrderedDict([('weights', tensor([0.5999])), ('bias', tensor([0.3420]))]) \n",
            "\n",
            "Epoch: 22480 | Loss: 0.020105084404349327 | Test loss: 0.04700788855552673\n",
            "OrderedDict([('weights', tensor([0.6000])), ('bias', tensor([0.3420]))]) \n",
            "\n",
            "Epoch: 22490 | Loss: 0.02008793130517006 | Test loss: 0.046968378126621246\n",
            "OrderedDict([('weights', tensor([0.6001])), ('bias', tensor([0.3420]))]) \n",
            "\n",
            "Epoch: 22500 | Loss: 0.020070767030119896 | Test loss: 0.046927131712436676\n",
            "OrderedDict([('weights', tensor([0.6002])), ('bias', tensor([0.3419]))]) \n",
            "\n",
            "Epoch: 22510 | Loss: 0.020053617656230927 | Test loss: 0.04688764363527298\n",
            "OrderedDict([('weights', tensor([0.6002])), ('bias', tensor([0.3419]))]) \n",
            "\n",
            "Epoch: 22520 | Loss: 0.02003643475472927 | Test loss: 0.04684639722108841\n",
            "OrderedDict([('weights', tensor([0.6003])), ('bias', tensor([0.3419]))]) \n",
            "\n",
            "Epoch: 22530 | Loss: 0.02001928724348545 | Test loss: 0.046806901693344116\n",
            "OrderedDict([('weights', tensor([0.6004])), ('bias', tensor([0.3418]))]) \n",
            "\n",
            "Epoch: 22540 | Loss: 0.020002106204628944 | Test loss: 0.04676739126443863\n",
            "OrderedDict([('weights', tensor([0.6005])), ('bias', tensor([0.3418]))]) \n",
            "\n",
            "Epoch: 22550 | Loss: 0.01998496986925602 | Test loss: 0.04672614857554436\n",
            "OrderedDict([('weights', tensor([0.6006])), ('bias', tensor([0.3418]))]) \n",
            "\n",
            "Epoch: 22560 | Loss: 0.019967805594205856 | Test loss: 0.04668840765953064\n",
            "OrderedDict([('weights', tensor([0.6007])), ('bias', tensor([0.3417]))]) \n",
            "\n",
            "Epoch: 22570 | Loss: 0.019950639456510544 | Test loss: 0.04664541408419609\n",
            "OrderedDict([('weights', tensor([0.6008])), ('bias', tensor([0.3417]))]) \n",
            "\n",
            "Epoch: 22580 | Loss: 0.01993349939584732 | Test loss: 0.04660762473940849\n",
            "OrderedDict([('weights', tensor([0.6008])), ('bias', tensor([0.3416]))]) \n",
            "\n",
            "Epoch: 22590 | Loss: 0.019916322082281113 | Test loss: 0.0465681329369545\n",
            "OrderedDict([('weights', tensor([0.6009])), ('bias', tensor([0.3416]))]) \n",
            "\n",
            "Epoch: 22600 | Loss: 0.0198991596698761 | Test loss: 0.04652516171336174\n",
            "OrderedDict([('weights', tensor([0.6010])), ('bias', tensor([0.3416]))]) \n",
            "\n",
            "Epoch: 22610 | Loss: 0.019882027059793472 | Test loss: 0.046487390995025635\n",
            "OrderedDict([('weights', tensor([0.6011])), ('bias', tensor([0.3415]))]) \n",
            "\n",
            "Epoch: 22620 | Loss: 0.019864872097969055 | Test loss: 0.04644617438316345\n",
            "OrderedDict([('weights', tensor([0.6012])), ('bias', tensor([0.3415]))]) \n",
            "\n",
            "Epoch: 22630 | Loss: 0.019847722724080086 | Test loss: 0.04640664905309677\n",
            "OrderedDict([('weights', tensor([0.6013])), ('bias', tensor([0.3415]))]) \n",
            "\n",
            "Epoch: 22640 | Loss: 0.01983054354786873 | Test loss: 0.046365391463041306\n",
            "OrderedDict([('weights', tensor([0.6013])), ('bias', tensor([0.3414]))]) \n",
            "\n",
            "Epoch: 22650 | Loss: 0.019813397899270058 | Test loss: 0.04632590338587761\n",
            "OrderedDict([('weights', tensor([0.6014])), ('bias', tensor([0.3414]))]) \n",
            "\n",
            "Epoch: 22660 | Loss: 0.019796237349510193 | Test loss: 0.046286385506391525\n",
            "OrderedDict([('weights', tensor([0.6015])), ('bias', tensor([0.3414]))]) \n",
            "\n",
            "Epoch: 22670 | Loss: 0.01977907493710518 | Test loss: 0.04624515771865845\n",
            "OrderedDict([('weights', tensor([0.6016])), ('bias', tensor([0.3413]))]) \n",
            "\n",
            "Epoch: 22680 | Loss: 0.019761893898248672 | Test loss: 0.04620564728975296\n",
            "OrderedDict([('weights', tensor([0.6017])), ('bias', tensor([0.3413]))]) \n",
            "\n",
            "Epoch: 22690 | Loss: 0.019744744524359703 | Test loss: 0.046164415776729584\n",
            "OrderedDict([('weights', tensor([0.6018])), ('bias', tensor([0.3413]))]) \n",
            "\n",
            "Epoch: 22700 | Loss: 0.019727583974599838 | Test loss: 0.04612664133310318\n",
            "OrderedDict([('weights', tensor([0.6019])), ('bias', tensor([0.3412]))]) \n",
            "\n",
            "Epoch: 22710 | Loss: 0.019710415974259377 | Test loss: 0.04608368128538132\n",
            "OrderedDict([('weights', tensor([0.6019])), ('bias', tensor([0.3412]))]) \n",
            "\n",
            "Epoch: 22720 | Loss: 0.019693270325660706 | Test loss: 0.04604417085647583\n",
            "OrderedDict([('weights', tensor([0.6020])), ('bias', tensor([0.3411]))]) \n",
            "\n",
            "Epoch: 22730 | Loss: 0.01967610977590084 | Test loss: 0.04600639268755913\n",
            "OrderedDict([('weights', tensor([0.6021])), ('bias', tensor([0.3411]))]) \n",
            "\n",
            "Epoch: 22740 | Loss: 0.019658943638205528 | Test loss: 0.04596341401338577\n",
            "OrderedDict([('weights', tensor([0.6022])), ('bias', tensor([0.3411]))]) \n",
            "\n",
            "Epoch: 22750 | Loss: 0.019641797989606857 | Test loss: 0.045925647020339966\n",
            "OrderedDict([('weights', tensor([0.6023])), ('bias', tensor([0.3410]))]) \n",
            "\n",
            "Epoch: 22760 | Loss: 0.019624654203653336 | Test loss: 0.04588440805673599\n",
            "OrderedDict([('weights', tensor([0.6024])), ('bias', tensor([0.3410]))]) \n",
            "\n",
            "Epoch: 22770 | Loss: 0.01960749737918377 | Test loss: 0.04584489390254021\n",
            "OrderedDict([('weights', tensor([0.6025])), ('bias', tensor([0.3410]))]) \n",
            "\n",
            "Epoch: 22780 | Loss: 0.01959032006561756 | Test loss: 0.04580538719892502\n",
            "OrderedDict([('weights', tensor([0.6025])), ('bias', tensor([0.3409]))]) \n",
            "\n",
            "Epoch: 22790 | Loss: 0.019573185592889786 | Test loss: 0.04576415941119194\n",
            "OrderedDict([('weights', tensor([0.6026])), ('bias', tensor([0.3409]))]) \n",
            "\n",
            "Epoch: 22800 | Loss: 0.019556012004613876 | Test loss: 0.045724641531705856\n",
            "OrderedDict([('weights', tensor([0.6027])), ('bias', tensor([0.3409]))]) \n",
            "\n",
            "Epoch: 22810 | Loss: 0.019538849592208862 | Test loss: 0.04568341374397278\n",
            "OrderedDict([('weights', tensor([0.6028])), ('bias', tensor([0.3408]))]) \n",
            "\n",
            "Epoch: 22820 | Loss: 0.019521677866578102 | Test loss: 0.04564390704035759\n",
            "OrderedDict([('weights', tensor([0.6029])), ('bias', tensor([0.3408]))]) \n",
            "\n",
            "Epoch: 22830 | Loss: 0.019504526630043983 | Test loss: 0.04560266062617302\n",
            "OrderedDict([('weights', tensor([0.6030])), ('bias', tensor([0.3408]))]) \n",
            "\n",
            "Epoch: 22840 | Loss: 0.019487380981445312 | Test loss: 0.04556315392255783\n",
            "OrderedDict([('weights', tensor([0.6031])), ('bias', tensor([0.3407]))]) \n",
            "\n",
            "Epoch: 22850 | Loss: 0.019470203667879105 | Test loss: 0.04552193731069565\n",
            "OrderedDict([('weights', tensor([0.6031])), ('bias', tensor([0.3407]))]) \n",
            "\n",
            "Epoch: 22860 | Loss: 0.019453048706054688 | Test loss: 0.04548240825533867\n",
            "OrderedDict([('weights', tensor([0.6032])), ('bias', tensor([0.3406]))]) \n",
            "\n",
            "Epoch: 22870 | Loss: 0.019435888156294823 | Test loss: 0.045444659888744354\n",
            "OrderedDict([('weights', tensor([0.6033])), ('bias', tensor([0.3406]))]) \n",
            "\n",
            "Epoch: 22880 | Loss: 0.01941872574388981 | Test loss: 0.0454016737639904\n",
            "OrderedDict([('weights', tensor([0.6034])), ('bias', tensor([0.3406]))]) \n",
            "\n",
            "Epoch: 22890 | Loss: 0.01940157637000084 | Test loss: 0.045363910496234894\n",
            "OrderedDict([('weights', tensor([0.6035])), ('bias', tensor([0.3405]))]) \n",
            "\n",
            "Epoch: 22900 | Loss: 0.019384410232305527 | Test loss: 0.04532439261674881\n",
            "OrderedDict([('weights', tensor([0.6036])), ('bias', tensor([0.3405]))]) \n",
            "\n",
            "Epoch: 22910 | Loss: 0.019367268308997154 | Test loss: 0.04528316855430603\n",
            "OrderedDict([('weights', tensor([0.6037])), ('bias', tensor([0.3405]))]) \n",
            "\n",
            "Epoch: 22920 | Loss: 0.019350102171301842 | Test loss: 0.045243650674819946\n",
            "OrderedDict([('weights', tensor([0.6037])), ('bias', tensor([0.3404]))]) \n",
            "\n",
            "Epoch: 22930 | Loss: 0.01933295838534832 | Test loss: 0.045202456414699554\n",
            "OrderedDict([('weights', tensor([0.6038])), ('bias', tensor([0.3404]))]) \n",
            "\n",
            "Epoch: 22940 | Loss: 0.019315794110298157 | Test loss: 0.04516291618347168\n",
            "OrderedDict([('weights', tensor([0.6039])), ('bias', tensor([0.3404]))]) \n",
            "\n",
            "Epoch: 22950 | Loss: 0.019298631697893143 | Test loss: 0.045121677219867706\n",
            "OrderedDict([('weights', tensor([0.6040])), ('bias', tensor([0.3403]))]) \n",
            "\n",
            "Epoch: 22960 | Loss: 0.019281480461359024 | Test loss: 0.04508215934038162\n",
            "OrderedDict([('weights', tensor([0.6041])), ('bias', tensor([0.3403]))]) \n",
            "\n",
            "Epoch: 22970 | Loss: 0.019264299422502518 | Test loss: 0.04504094645380974\n",
            "OrderedDict([('weights', tensor([0.6042])), ('bias', tensor([0.3403]))]) \n",
            "\n",
            "Epoch: 22980 | Loss: 0.019247157499194145 | Test loss: 0.045001428574323654\n",
            "OrderedDict([('weights', tensor([0.6043])), ('bias', tensor([0.3402]))]) \n",
            "\n",
            "Epoch: 22990 | Loss: 0.01922997459769249 | Test loss: 0.044960230588912964\n",
            "OrderedDict([('weights', tensor([0.6043])), ('bias', tensor([0.3402]))]) \n",
            "\n",
            "Epoch: 23000 | Loss: 0.019212832674384117 | Test loss: 0.044920701533555984\n",
            "OrderedDict([('weights', tensor([0.6044])), ('bias', tensor([0.3401]))]) \n",
            "\n",
            "Epoch: 23010 | Loss: 0.019195670261979103 | Test loss: 0.044882915914058685\n",
            "OrderedDict([('weights', tensor([0.6045])), ('bias', tensor([0.3401]))]) \n",
            "\n",
            "Epoch: 23020 | Loss: 0.01917850598692894 | Test loss: 0.04483995586633682\n",
            "OrderedDict([('weights', tensor([0.6046])), ('bias', tensor([0.3401]))]) \n",
            "\n",
            "Epoch: 23030 | Loss: 0.019161362200975418 | Test loss: 0.04480215907096863\n",
            "OrderedDict([('weights', tensor([0.6047])), ('bias', tensor([0.3400]))]) \n",
            "\n",
            "Epoch: 23040 | Loss: 0.01914418861269951 | Test loss: 0.04476265236735344\n",
            "OrderedDict([('weights', tensor([0.6048])), ('bias', tensor([0.3400]))]) \n",
            "\n",
            "Epoch: 23050 | Loss: 0.019127056002616882 | Test loss: 0.044721417129039764\n",
            "OrderedDict([('weights', tensor([0.6048])), ('bias', tensor([0.3400]))]) \n",
            "\n",
            "Epoch: 23060 | Loss: 0.01910988613963127 | Test loss: 0.04468192532658577\n",
            "OrderedDict([('weights', tensor([0.6049])), ('bias', tensor([0.3399]))]) \n",
            "\n",
            "Epoch: 23070 | Loss: 0.019092729315161705 | Test loss: 0.044640690088272095\n",
            "OrderedDict([('weights', tensor([0.6050])), ('bias', tensor([0.3399]))]) \n",
            "\n",
            "Epoch: 23080 | Loss: 0.019075576215982437 | Test loss: 0.04460117965936661\n",
            "OrderedDict([('weights', tensor([0.6051])), ('bias', tensor([0.3399]))]) \n",
            "\n",
            "Epoch: 23090 | Loss: 0.019058411940932274 | Test loss: 0.04455993324518204\n",
            "OrderedDict([('weights', tensor([0.6052])), ('bias', tensor([0.3398]))]) \n",
            "\n",
            "Epoch: 23100 | Loss: 0.019041260704398155 | Test loss: 0.04452044516801834\n",
            "OrderedDict([('weights', tensor([0.6053])), ('bias', tensor([0.3398]))]) \n",
            "\n",
            "Epoch: 23110 | Loss: 0.01902407966554165 | Test loss: 0.04447919875383377\n",
            "OrderedDict([('weights', tensor([0.6054])), ('bias', tensor([0.3397]))]) \n",
            "\n",
            "Epoch: 23120 | Loss: 0.01900693215429783 | Test loss: 0.04443970322608948\n",
            "OrderedDict([('weights', tensor([0.6054])), ('bias', tensor([0.3397]))]) \n",
            "\n",
            "Epoch: 23130 | Loss: 0.018989751115441322 | Test loss: 0.04440019279718399\n",
            "OrderedDict([('weights', tensor([0.6055])), ('bias', tensor([0.3397]))]) \n",
            "\n",
            "Epoch: 23140 | Loss: 0.0189726110547781 | Test loss: 0.04435895010828972\n",
            "OrderedDict([('weights', tensor([0.6056])), ('bias', tensor([0.3396]))]) \n",
            "\n",
            "Epoch: 23150 | Loss: 0.018955450505018234 | Test loss: 0.044321209192276\n",
            "OrderedDict([('weights', tensor([0.6057])), ('bias', tensor([0.3396]))]) \n",
            "\n",
            "Epoch: 23160 | Loss: 0.018938282504677773 | Test loss: 0.04427821561694145\n",
            "OrderedDict([('weights', tensor([0.6058])), ('bias', tensor([0.3396]))]) \n",
            "\n",
            "Epoch: 23170 | Loss: 0.0189211443066597 | Test loss: 0.044240426272153854\n",
            "OrderedDict([('weights', tensor([0.6059])), ('bias', tensor([0.3395]))]) \n",
            "\n",
            "Epoch: 23180 | Loss: 0.01890396699309349 | Test loss: 0.04420093446969986\n",
            "OrderedDict([('weights', tensor([0.6060])), ('bias', tensor([0.3395]))]) \n",
            "\n",
            "Epoch: 23190 | Loss: 0.018886804580688477 | Test loss: 0.0441579632461071\n",
            "OrderedDict([('weights', tensor([0.6060])), ('bias', tensor([0.3395]))]) \n",
            "\n",
            "Epoch: 23200 | Loss: 0.01886967197060585 | Test loss: 0.044120192527770996\n",
            "OrderedDict([('weights', tensor([0.6061])), ('bias', tensor([0.3394]))]) \n",
            "\n",
            "Epoch: 23210 | Loss: 0.018852517008781433 | Test loss: 0.044078975915908813\n",
            "OrderedDict([('weights', tensor([0.6062])), ('bias', tensor([0.3394]))]) \n",
            "\n",
            "Epoch: 23220 | Loss: 0.018835367634892464 | Test loss: 0.04403945058584213\n",
            "OrderedDict([('weights', tensor([0.6063])), ('bias', tensor([0.3394]))]) \n",
            "\n",
            "Epoch: 23230 | Loss: 0.018818188458681107 | Test loss: 0.04399819299578667\n",
            "OrderedDict([('weights', tensor([0.6064])), ('bias', tensor([0.3393]))]) \n",
            "\n",
            "Epoch: 23240 | Loss: 0.018801042810082436 | Test loss: 0.04395870491862297\n",
            "OrderedDict([('weights', tensor([0.6065])), ('bias', tensor([0.3393]))]) \n",
            "\n",
            "Epoch: 23250 | Loss: 0.01878388226032257 | Test loss: 0.04391918703913689\n",
            "OrderedDict([('weights', tensor([0.6066])), ('bias', tensor([0.3392]))]) \n",
            "\n",
            "Epoch: 23260 | Loss: 0.018766719847917557 | Test loss: 0.04387795925140381\n",
            "OrderedDict([('weights', tensor([0.6066])), ('bias', tensor([0.3392]))]) \n",
            "\n",
            "Epoch: 23270 | Loss: 0.01874953880906105 | Test loss: 0.04383844882249832\n",
            "OrderedDict([('weights', tensor([0.6067])), ('bias', tensor([0.3392]))]) \n",
            "\n",
            "Epoch: 23280 | Loss: 0.01873238943517208 | Test loss: 0.043797217309474945\n",
            "OrderedDict([('weights', tensor([0.6068])), ('bias', tensor([0.3391]))]) \n",
            "\n",
            "Epoch: 23290 | Loss: 0.018715228885412216 | Test loss: 0.04375944286584854\n",
            "OrderedDict([('weights', tensor([0.6069])), ('bias', tensor([0.3391]))]) \n",
            "\n",
            "Epoch: 23300 | Loss: 0.018698060885071754 | Test loss: 0.04371648281812668\n",
            "OrderedDict([('weights', tensor([0.6070])), ('bias', tensor([0.3391]))]) \n",
            "\n",
            "Epoch: 23310 | Loss: 0.018680915236473083 | Test loss: 0.04367697238922119\n",
            "OrderedDict([('weights', tensor([0.6071])), ('bias', tensor([0.3390]))]) \n",
            "\n",
            "Epoch: 23320 | Loss: 0.01866375468671322 | Test loss: 0.04363919422030449\n",
            "OrderedDict([('weights', tensor([0.6072])), ('bias', tensor([0.3390]))]) \n",
            "\n",
            "Epoch: 23330 | Loss: 0.018646588549017906 | Test loss: 0.043596215546131134\n",
            "OrderedDict([('weights', tensor([0.6072])), ('bias', tensor([0.3390]))]) \n",
            "\n",
            "Epoch: 23340 | Loss: 0.018629442900419235 | Test loss: 0.04355844855308533\n",
            "OrderedDict([('weights', tensor([0.6073])), ('bias', tensor([0.3389]))]) \n",
            "\n",
            "Epoch: 23350 | Loss: 0.018612299114465714 | Test loss: 0.043517209589481354\n",
            "OrderedDict([('weights', tensor([0.6074])), ('bias', tensor([0.3389]))]) \n",
            "\n",
            "Epoch: 23360 | Loss: 0.018595142289996147 | Test loss: 0.04347769543528557\n",
            "OrderedDict([('weights', tensor([0.6075])), ('bias', tensor([0.3389]))]) \n",
            "\n",
            "Epoch: 23370 | Loss: 0.01857796497642994 | Test loss: 0.04343818873167038\n",
            "OrderedDict([('weights', tensor([0.6076])), ('bias', tensor([0.3388]))]) \n",
            "\n",
            "Epoch: 23380 | Loss: 0.018560830503702164 | Test loss: 0.0433969609439373\n",
            "OrderedDict([('weights', tensor([0.6077])), ('bias', tensor([0.3388]))]) \n",
            "\n",
            "Epoch: 23390 | Loss: 0.018543656915426254 | Test loss: 0.04335744306445122\n",
            "OrderedDict([('weights', tensor([0.6078])), ('bias', tensor([0.3387]))]) \n",
            "\n",
            "Epoch: 23400 | Loss: 0.01852649450302124 | Test loss: 0.04331621527671814\n",
            "OrderedDict([('weights', tensor([0.6078])), ('bias', tensor([0.3387]))]) \n",
            "\n",
            "Epoch: 23410 | Loss: 0.01850932277739048 | Test loss: 0.04327670857310295\n",
            "OrderedDict([('weights', tensor([0.6079])), ('bias', tensor([0.3387]))]) \n",
            "\n",
            "Epoch: 23420 | Loss: 0.01849217154085636 | Test loss: 0.04323546215891838\n",
            "OrderedDict([('weights', tensor([0.6080])), ('bias', tensor([0.3386]))]) \n",
            "\n",
            "Epoch: 23430 | Loss: 0.01847502589225769 | Test loss: 0.04319595545530319\n",
            "OrderedDict([('weights', tensor([0.6081])), ('bias', tensor([0.3386]))]) \n",
            "\n",
            "Epoch: 23440 | Loss: 0.018457848578691483 | Test loss: 0.043154727667570114\n",
            "OrderedDict([('weights', tensor([0.6082])), ('bias', tensor([0.3386]))]) \n",
            "\n",
            "Epoch: 23450 | Loss: 0.018440693616867065 | Test loss: 0.04311520978808403\n",
            "OrderedDict([('weights', tensor([0.6083])), ('bias', tensor([0.3385]))]) \n",
            "\n",
            "Epoch: 23460 | Loss: 0.0184235330671072 | Test loss: 0.043077461421489716\n",
            "OrderedDict([('weights', tensor([0.6083])), ('bias', tensor([0.3385]))]) \n",
            "\n",
            "Epoch: 23470 | Loss: 0.018406370654702187 | Test loss: 0.043034475296735764\n",
            "OrderedDict([('weights', tensor([0.6084])), ('bias', tensor([0.3385]))]) \n",
            "\n",
            "Epoch: 23480 | Loss: 0.018389221280813217 | Test loss: 0.042996712028980255\n",
            "OrderedDict([('weights', tensor([0.6085])), ('bias', tensor([0.3384]))]) \n",
            "\n",
            "Epoch: 23490 | Loss: 0.018372055143117905 | Test loss: 0.04295719414949417\n",
            "OrderedDict([('weights', tensor([0.6086])), ('bias', tensor([0.3384]))]) \n",
            "\n",
            "Epoch: 23500 | Loss: 0.018354913219809532 | Test loss: 0.04291597008705139\n",
            "OrderedDict([('weights', tensor([0.6087])), ('bias', tensor([0.3383]))]) \n",
            "\n",
            "Epoch: 23510 | Loss: 0.01833774708211422 | Test loss: 0.04287645220756531\n",
            "OrderedDict([('weights', tensor([0.6088])), ('bias', tensor([0.3383]))]) \n",
            "\n",
            "Epoch: 23520 | Loss: 0.018320603296160698 | Test loss: 0.04283524677157402\n",
            "OrderedDict([('weights', tensor([0.6089])), ('bias', tensor([0.3383]))]) \n",
            "\n",
            "Epoch: 23530 | Loss: 0.018303439021110535 | Test loss: 0.04279571771621704\n",
            "OrderedDict([('weights', tensor([0.6089])), ('bias', tensor([0.3382]))]) \n",
            "\n",
            "Epoch: 23540 | Loss: 0.01828627660870552 | Test loss: 0.04275447875261307\n",
            "OrderedDict([('weights', tensor([0.6090])), ('bias', tensor([0.3382]))]) \n",
            "\n",
            "Epoch: 23550 | Loss: 0.018269125372171402 | Test loss: 0.042714960873126984\n",
            "OrderedDict([('weights', tensor([0.6091])), ('bias', tensor([0.3382]))]) \n",
            "\n",
            "Epoch: 23560 | Loss: 0.018251944333314896 | Test loss: 0.0426737479865551\n",
            "OrderedDict([('weights', tensor([0.6092])), ('bias', tensor([0.3381]))]) \n",
            "\n",
            "Epoch: 23570 | Loss: 0.018234802410006523 | Test loss: 0.042634230107069016\n",
            "OrderedDict([('weights', tensor([0.6093])), ('bias', tensor([0.3381]))]) \n",
            "\n",
            "Epoch: 23580 | Loss: 0.018217619508504868 | Test loss: 0.042593032121658325\n",
            "OrderedDict([('weights', tensor([0.6094])), ('bias', tensor([0.3381]))]) \n",
            "\n",
            "Epoch: 23590 | Loss: 0.018200477585196495 | Test loss: 0.042553503066301346\n",
            "OrderedDict([('weights', tensor([0.6095])), ('bias', tensor([0.3380]))]) \n",
            "\n",
            "Epoch: 23600 | Loss: 0.01818331517279148 | Test loss: 0.04251570627093315\n",
            "OrderedDict([('weights', tensor([0.6095])), ('bias', tensor([0.3380]))]) \n",
            "\n",
            "Epoch: 23610 | Loss: 0.018166150897741318 | Test loss: 0.042472757399082184\n",
            "OrderedDict([('weights', tensor([0.6096])), ('bias', tensor([0.3380]))]) \n",
            "\n",
            "Epoch: 23620 | Loss: 0.018149007111787796 | Test loss: 0.04243496060371399\n",
            "OrderedDict([('weights', tensor([0.6097])), ('bias', tensor([0.3379]))]) \n",
            "\n",
            "Epoch: 23630 | Loss: 0.018131833523511887 | Test loss: 0.0423954539000988\n",
            "OrderedDict([('weights', tensor([0.6098])), ('bias', tensor([0.3379]))]) \n",
            "\n",
            "Epoch: 23640 | Loss: 0.01811470091342926 | Test loss: 0.042354218661785126\n",
            "OrderedDict([('weights', tensor([0.6099])), ('bias', tensor([0.3378]))]) \n",
            "\n",
            "Epoch: 23650 | Loss: 0.01809753105044365 | Test loss: 0.04231472685933113\n",
            "OrderedDict([('weights', tensor([0.6100])), ('bias', tensor([0.3378]))]) \n",
            "\n",
            "Epoch: 23660 | Loss: 0.018080374225974083 | Test loss: 0.042273491621017456\n",
            "OrderedDict([('weights', tensor([0.6101])), ('bias', tensor([0.3378]))]) \n",
            "\n",
            "Epoch: 23670 | Loss: 0.018063221126794815 | Test loss: 0.04223398119211197\n",
            "OrderedDict([('weights', tensor([0.6101])), ('bias', tensor([0.3377]))]) \n",
            "\n",
            "Epoch: 23680 | Loss: 0.01804606057703495 | Test loss: 0.0421927347779274\n",
            "OrderedDict([('weights', tensor([0.6102])), ('bias', tensor([0.3377]))]) \n",
            "\n",
            "Epoch: 23690 | Loss: 0.018028905615210533 | Test loss: 0.0421532467007637\n",
            "OrderedDict([('weights', tensor([0.6103])), ('bias', tensor([0.3377]))]) \n",
            "\n",
            "Epoch: 23700 | Loss: 0.018011724576354027 | Test loss: 0.04211200028657913\n",
            "OrderedDict([('weights', tensor([0.6104])), ('bias', tensor([0.3376]))]) \n",
            "\n",
            "Epoch: 23710 | Loss: 0.017994577065110207 | Test loss: 0.04207250475883484\n",
            "OrderedDict([('weights', tensor([0.6105])), ('bias', tensor([0.3376]))]) \n",
            "\n",
            "Epoch: 23720 | Loss: 0.0179773960262537 | Test loss: 0.04203299805521965\n",
            "OrderedDict([('weights', tensor([0.6106])), ('bias', tensor([0.3376]))]) \n",
            "\n",
            "Epoch: 23730 | Loss: 0.017960255965590477 | Test loss: 0.04199175164103508\n",
            "OrderedDict([('weights', tensor([0.6107])), ('bias', tensor([0.3375]))]) \n",
            "\n",
            "Epoch: 23740 | Loss: 0.017943095415830612 | Test loss: 0.04195401072502136\n",
            "OrderedDict([('weights', tensor([0.6107])), ('bias', tensor([0.3375]))]) \n",
            "\n",
            "Epoch: 23750 | Loss: 0.01792592741549015 | Test loss: 0.04191101714968681\n",
            "OrderedDict([('weights', tensor([0.6108])), ('bias', tensor([0.3375]))]) \n",
            "\n",
            "Epoch: 23760 | Loss: 0.017908789217472076 | Test loss: 0.041873227804899216\n",
            "OrderedDict([('weights', tensor([0.6109])), ('bias', tensor([0.3374]))]) \n",
            "\n",
            "Epoch: 23770 | Loss: 0.01789161190390587 | Test loss: 0.041833728551864624\n",
            "OrderedDict([('weights', tensor([0.6110])), ('bias', tensor([0.3374]))]) \n",
            "\n",
            "Epoch: 23780 | Loss: 0.017874449491500854 | Test loss: 0.04179076477885246\n",
            "OrderedDict([('weights', tensor([0.6111])), ('bias', tensor([0.3373]))]) \n",
            "\n",
            "Epoch: 23790 | Loss: 0.017857316881418228 | Test loss: 0.04175298660993576\n",
            "OrderedDict([('weights', tensor([0.6112])), ('bias', tensor([0.3373]))]) \n",
            "\n",
            "Epoch: 23800 | Loss: 0.01784016191959381 | Test loss: 0.041711777448654175\n",
            "OrderedDict([('weights', tensor([0.6113])), ('bias', tensor([0.3373]))]) \n",
            "\n",
            "Epoch: 23810 | Loss: 0.01782301254570484 | Test loss: 0.041672248393297195\n",
            "OrderedDict([('weights', tensor([0.6113])), ('bias', tensor([0.3372]))]) \n",
            "\n",
            "Epoch: 23820 | Loss: 0.017805833369493484 | Test loss: 0.04163099452853203\n",
            "OrderedDict([('weights', tensor([0.6114])), ('bias', tensor([0.3372]))]) \n",
            "\n",
            "Epoch: 23830 | Loss: 0.017788687720894814 | Test loss: 0.04159151390194893\n",
            "OrderedDict([('weights', tensor([0.6115])), ('bias', tensor([0.3372]))]) \n",
            "\n",
            "Epoch: 23840 | Loss: 0.01777152717113495 | Test loss: 0.04155198857188225\n",
            "OrderedDict([('weights', tensor([0.6116])), ('bias', tensor([0.3371]))]) \n",
            "\n",
            "Epoch: 23850 | Loss: 0.017754364758729935 | Test loss: 0.04151076823472977\n",
            "OrderedDict([('weights', tensor([0.6117])), ('bias', tensor([0.3371]))]) \n",
            "\n",
            "Epoch: 23860 | Loss: 0.01773718371987343 | Test loss: 0.04147125035524368\n",
            "OrderedDict([('weights', tensor([0.6118])), ('bias', tensor([0.3371]))]) \n",
            "\n",
            "Epoch: 23870 | Loss: 0.01772003434598446 | Test loss: 0.0414300262928009\n",
            "OrderedDict([('weights', tensor([0.6118])), ('bias', tensor([0.3370]))]) \n",
            "\n",
            "Epoch: 23880 | Loss: 0.017702873796224594 | Test loss: 0.041392236948013306\n",
            "OrderedDict([('weights', tensor([0.6119])), ('bias', tensor([0.3370]))]) \n",
            "\n",
            "Epoch: 23890 | Loss: 0.017685705795884132 | Test loss: 0.04134929180145264\n",
            "OrderedDict([('weights', tensor([0.6120])), ('bias', tensor([0.3370]))]) \n",
            "\n",
            "Epoch: 23900 | Loss: 0.01766856014728546 | Test loss: 0.04130977392196655\n",
            "OrderedDict([('weights', tensor([0.6121])), ('bias', tensor([0.3369]))]) \n",
            "\n",
            "Epoch: 23910 | Loss: 0.017651399597525597 | Test loss: 0.04127199575304985\n",
            "OrderedDict([('weights', tensor([0.6122])), ('bias', tensor([0.3369]))]) \n",
            "\n",
            "Epoch: 23920 | Loss: 0.017634233459830284 | Test loss: 0.041229017078876495\n",
            "OrderedDict([('weights', tensor([0.6123])), ('bias', tensor([0.3368]))]) \n",
            "\n",
            "Epoch: 23930 | Loss: 0.017617087811231613 | Test loss: 0.04119125008583069\n",
            "OrderedDict([('weights', tensor([0.6124])), ('bias', tensor([0.3368]))]) \n",
            "\n",
            "Epoch: 23940 | Loss: 0.01759994402527809 | Test loss: 0.04115000367164612\n",
            "OrderedDict([('weights', tensor([0.6124])), ('bias', tensor([0.3368]))]) \n",
            "\n",
            "Epoch: 23950 | Loss: 0.017582787200808525 | Test loss: 0.04111049696803093\n",
            "OrderedDict([('weights', tensor([0.6125])), ('bias', tensor([0.3367]))]) \n",
            "\n",
            "Epoch: 23960 | Loss: 0.017565609887242317 | Test loss: 0.04107099026441574\n",
            "OrderedDict([('weights', tensor([0.6126])), ('bias', tensor([0.3367]))]) \n",
            "\n",
            "Epoch: 23970 | Loss: 0.01754847541451454 | Test loss: 0.04102976247668266\n",
            "OrderedDict([('weights', tensor([0.6127])), ('bias', tensor([0.3367]))]) \n",
            "\n",
            "Epoch: 23980 | Loss: 0.017531301826238632 | Test loss: 0.04099024459719658\n",
            "OrderedDict([('weights', tensor([0.6128])), ('bias', tensor([0.3366]))]) \n",
            "\n",
            "Epoch: 23990 | Loss: 0.017514139413833618 | Test loss: 0.0409490168094635\n",
            "OrderedDict([('weights', tensor([0.6129])), ('bias', tensor([0.3366]))]) \n",
            "\n",
            "Epoch: 24000 | Loss: 0.017496967688202858 | Test loss: 0.04090951010584831\n",
            "OrderedDict([('weights', tensor([0.6130])), ('bias', tensor([0.3366]))]) \n",
            "\n",
            "Epoch: 24010 | Loss: 0.01747981645166874 | Test loss: 0.04086827486753464\n",
            "OrderedDict([('weights', tensor([0.6130])), ('bias', tensor([0.3365]))]) \n",
            "\n",
            "Epoch: 24020 | Loss: 0.01746267080307007 | Test loss: 0.04082875698804855\n",
            "OrderedDict([('weights', tensor([0.6131])), ('bias', tensor([0.3365]))]) \n",
            "\n",
            "Epoch: 24030 | Loss: 0.01744549348950386 | Test loss: 0.040787529200315475\n",
            "OrderedDict([('weights', tensor([0.6132])), ('bias', tensor([0.3365]))]) \n",
            "\n",
            "Epoch: 24040 | Loss: 0.017428338527679443 | Test loss: 0.04074801132082939\n",
            "OrderedDict([('weights', tensor([0.6133])), ('bias', tensor([0.3364]))]) \n",
            "\n",
            "Epoch: 24050 | Loss: 0.01741117797791958 | Test loss: 0.040710270404815674\n",
            "OrderedDict([('weights', tensor([0.6134])), ('bias', tensor([0.3364]))]) \n",
            "\n",
            "Epoch: 24060 | Loss: 0.017394015565514565 | Test loss: 0.040667276829481125\n",
            "OrderedDict([('weights', tensor([0.6135])), ('bias', tensor([0.3363]))]) \n",
            "\n",
            "Epoch: 24070 | Loss: 0.017376868054270744 | Test loss: 0.040629513561725616\n",
            "OrderedDict([('weights', tensor([0.6136])), ('bias', tensor([0.3363]))]) \n",
            "\n",
            "Epoch: 24080 | Loss: 0.017359700053930283 | Test loss: 0.04058999568223953\n",
            "OrderedDict([('weights', tensor([0.6136])), ('bias', tensor([0.3363]))]) \n",
            "\n",
            "Epoch: 24090 | Loss: 0.01734255813062191 | Test loss: 0.04054878279566765\n",
            "OrderedDict([('weights', tensor([0.6137])), ('bias', tensor([0.3362]))]) \n",
            "\n",
            "Epoch: 24100 | Loss: 0.017325391992926598 | Test loss: 0.04050925374031067\n",
            "OrderedDict([('weights', tensor([0.6138])), ('bias', tensor([0.3362]))]) \n",
            "\n",
            "Epoch: 24110 | Loss: 0.017308248206973076 | Test loss: 0.04046804830431938\n",
            "OrderedDict([('weights', tensor([0.6139])), ('bias', tensor([0.3362]))]) \n",
            "\n",
            "Epoch: 24120 | Loss: 0.017291083931922913 | Test loss: 0.0404285192489624\n",
            "OrderedDict([('weights', tensor([0.6140])), ('bias', tensor([0.3361]))]) \n",
            "\n",
            "Epoch: 24130 | Loss: 0.0172739215195179 | Test loss: 0.04038728028535843\n",
            "OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3361]))]) \n",
            "\n",
            "Epoch: 24140 | Loss: 0.01725677028298378 | Test loss: 0.040347762405872345\n",
            "OrderedDict([('weights', tensor([0.6142])), ('bias', tensor([0.3361]))]) \n",
            "\n",
            "Epoch: 24150 | Loss: 0.017239589244127274 | Test loss: 0.04030654951930046\n",
            "OrderedDict([('weights', tensor([0.6142])), ('bias', tensor([0.3360]))]) \n",
            "\n",
            "Epoch: 24160 | Loss: 0.0172224473208189 | Test loss: 0.04026703163981438\n",
            "OrderedDict([('weights', tensor([0.6143])), ('bias', tensor([0.3360]))]) \n",
            "\n",
            "Epoch: 24170 | Loss: 0.017205264419317245 | Test loss: 0.040225833654403687\n",
            "OrderedDict([('weights', tensor([0.6144])), ('bias', tensor([0.3359]))]) \n",
            "\n",
            "Epoch: 24180 | Loss: 0.017188122496008873 | Test loss: 0.04018629714846611\n",
            "OrderedDict([('weights', tensor([0.6145])), ('bias', tensor([0.3359]))]) \n",
            "\n",
            "Epoch: 24190 | Loss: 0.01717096008360386 | Test loss: 0.04014850780367851\n",
            "OrderedDict([('weights', tensor([0.6146])), ('bias', tensor([0.3359]))]) \n",
            "\n",
            "Epoch: 24200 | Loss: 0.017153795808553696 | Test loss: 0.04010555148124695\n",
            "OrderedDict([('weights', tensor([0.6147])), ('bias', tensor([0.3358]))]) \n",
            "\n",
            "Epoch: 24210 | Loss: 0.017136652022600174 | Test loss: 0.04006776213645935\n",
            "OrderedDict([('weights', tensor([0.6148])), ('bias', tensor([0.3358]))]) \n",
            "\n",
            "Epoch: 24220 | Loss: 0.017119478434324265 | Test loss: 0.04002825543284416\n",
            "OrderedDict([('weights', tensor([0.6148])), ('bias', tensor([0.3358]))]) \n",
            "\n",
            "Epoch: 24230 | Loss: 0.017102345824241638 | Test loss: 0.03998702019453049\n",
            "OrderedDict([('weights', tensor([0.6149])), ('bias', tensor([0.3357]))]) \n",
            "\n",
            "Epoch: 24240 | Loss: 0.017085175961256027 | Test loss: 0.03994752839207649\n",
            "OrderedDict([('weights', tensor([0.6150])), ('bias', tensor([0.3357]))]) \n",
            "\n",
            "Epoch: 24250 | Loss: 0.01706801913678646 | Test loss: 0.03990629315376282\n",
            "OrderedDict([('weights', tensor([0.6151])), ('bias', tensor([0.3357]))]) \n",
            "\n",
            "Epoch: 24260 | Loss: 0.017050866037607193 | Test loss: 0.03986678272485733\n",
            "OrderedDict([('weights', tensor([0.6152])), ('bias', tensor([0.3356]))]) \n",
            "\n",
            "Epoch: 24270 | Loss: 0.017033705487847328 | Test loss: 0.03982553631067276\n",
            "OrderedDict([('weights', tensor([0.6153])), ('bias', tensor([0.3356]))]) \n",
            "\n",
            "Epoch: 24280 | Loss: 0.01701655052602291 | Test loss: 0.039786048233509064\n",
            "OrderedDict([('weights', tensor([0.6153])), ('bias', tensor([0.3356]))]) \n",
            "\n",
            "Epoch: 24290 | Loss: 0.016999369487166405 | Test loss: 0.03974480181932449\n",
            "OrderedDict([('weights', tensor([0.6154])), ('bias', tensor([0.3355]))]) \n",
            "\n",
            "Epoch: 24300 | Loss: 0.016982221975922585 | Test loss: 0.0397053062915802\n",
            "OrderedDict([('weights', tensor([0.6155])), ('bias', tensor([0.3355]))]) \n",
            "\n",
            "Epoch: 24310 | Loss: 0.016965040937066078 | Test loss: 0.03966579958796501\n",
            "OrderedDict([('weights', tensor([0.6156])), ('bias', tensor([0.3354]))]) \n",
            "\n",
            "Epoch: 24320 | Loss: 0.016947900876402855 | Test loss: 0.03962455317378044\n",
            "OrderedDict([('weights', tensor([0.6157])), ('bias', tensor([0.3354]))]) \n",
            "\n",
            "Epoch: 24330 | Loss: 0.01693074032664299 | Test loss: 0.039586812257766724\n",
            "OrderedDict([('weights', tensor([0.6158])), ('bias', tensor([0.3354]))]) \n",
            "\n",
            "Epoch: 24340 | Loss: 0.01691357232630253 | Test loss: 0.039543818682432175\n",
            "OrderedDict([('weights', tensor([0.6159])), ('bias', tensor([0.3353]))]) \n",
            "\n",
            "Epoch: 24350 | Loss: 0.016896434128284454 | Test loss: 0.03950602933764458\n",
            "OrderedDict([('weights', tensor([0.6159])), ('bias', tensor([0.3353]))]) \n",
            "\n",
            "Epoch: 24360 | Loss: 0.016879256814718246 | Test loss: 0.039466530084609985\n",
            "OrderedDict([('weights', tensor([0.6160])), ('bias', tensor([0.3353]))]) \n",
            "\n",
            "Epoch: 24370 | Loss: 0.016862094402313232 | Test loss: 0.039423566311597824\n",
            "OrderedDict([('weights', tensor([0.6161])), ('bias', tensor([0.3352]))]) \n",
            "\n",
            "Epoch: 24380 | Loss: 0.016844961792230606 | Test loss: 0.03938578814268112\n",
            "OrderedDict([('weights', tensor([0.6162])), ('bias', tensor([0.3352]))]) \n",
            "\n",
            "Epoch: 24390 | Loss: 0.01682780683040619 | Test loss: 0.039344578981399536\n",
            "OrderedDict([('weights', tensor([0.6163])), ('bias', tensor([0.3352]))]) \n",
            "\n",
            "Epoch: 24400 | Loss: 0.01681065745651722 | Test loss: 0.03930504992604256\n",
            "OrderedDict([('weights', tensor([0.6164])), ('bias', tensor([0.3351]))]) \n",
            "\n",
            "Epoch: 24410 | Loss: 0.016793478280305862 | Test loss: 0.03926379606127739\n",
            "OrderedDict([('weights', tensor([0.6165])), ('bias', tensor([0.3351]))]) \n",
            "\n",
            "Epoch: 24420 | Loss: 0.01677633263170719 | Test loss: 0.03922431543469429\n",
            "OrderedDict([('weights', tensor([0.6165])), ('bias', tensor([0.3351]))]) \n",
            "\n",
            "Epoch: 24430 | Loss: 0.016759172081947327 | Test loss: 0.03918479010462761\n",
            "OrderedDict([('weights', tensor([0.6166])), ('bias', tensor([0.3350]))]) \n",
            "\n",
            "Epoch: 24440 | Loss: 0.016742009669542313 | Test loss: 0.03914356976747513\n",
            "OrderedDict([('weights', tensor([0.6167])), ('bias', tensor([0.3350]))]) \n",
            "\n",
            "Epoch: 24450 | Loss: 0.016724828630685806 | Test loss: 0.039104051887989044\n",
            "OrderedDict([('weights', tensor([0.6168])), ('bias', tensor([0.3349]))]) \n",
            "\n",
            "Epoch: 24460 | Loss: 0.016707679256796837 | Test loss: 0.039062827825546265\n",
            "OrderedDict([('weights', tensor([0.6169])), ('bias', tensor([0.3349]))]) \n",
            "\n",
            "Epoch: 24470 | Loss: 0.016690518707036972 | Test loss: 0.03902503848075867\n",
            "OrderedDict([('weights', tensor([0.6170])), ('bias', tensor([0.3349]))]) \n",
            "\n",
            "Epoch: 24480 | Loss: 0.01667335070669651 | Test loss: 0.038982093334198\n",
            "OrderedDict([('weights', tensor([0.6171])), ('bias', tensor([0.3348]))]) \n",
            "\n",
            "Epoch: 24490 | Loss: 0.01665620505809784 | Test loss: 0.038942575454711914\n",
            "OrderedDict([('weights', tensor([0.6171])), ('bias', tensor([0.3348]))]) \n",
            "\n",
            "Epoch: 24500 | Loss: 0.016639044508337975 | Test loss: 0.03890479728579521\n",
            "OrderedDict([('weights', tensor([0.6172])), ('bias', tensor([0.3348]))]) \n",
            "\n",
            "Epoch: 24510 | Loss: 0.016621878370642662 | Test loss: 0.03886181861162186\n",
            "OrderedDict([('weights', tensor([0.6173])), ('bias', tensor([0.3347]))]) \n",
            "\n",
            "Epoch: 24520 | Loss: 0.01660473272204399 | Test loss: 0.03882405161857605\n",
            "OrderedDict([('weights', tensor([0.6174])), ('bias', tensor([0.3347]))]) \n",
            "\n",
            "Epoch: 24530 | Loss: 0.01658758893609047 | Test loss: 0.03878280520439148\n",
            "OrderedDict([('weights', tensor([0.6175])), ('bias', tensor([0.3347]))]) \n",
            "\n",
            "Epoch: 24540 | Loss: 0.016570432111620903 | Test loss: 0.03874329850077629\n",
            "OrderedDict([('weights', tensor([0.6176])), ('bias', tensor([0.3346]))]) \n",
            "\n",
            "Epoch: 24550 | Loss: 0.016553254798054695 | Test loss: 0.0387037917971611\n",
            "OrderedDict([('weights', tensor([0.6177])), ('bias', tensor([0.3346]))]) \n",
            "\n",
            "Epoch: 24560 | Loss: 0.01653612032532692 | Test loss: 0.038662564009428024\n",
            "OrderedDict([('weights', tensor([0.6177])), ('bias', tensor([0.3345]))]) \n",
            "\n",
            "Epoch: 24570 | Loss: 0.01651894673705101 | Test loss: 0.03862304612994194\n",
            "OrderedDict([('weights', tensor([0.6178])), ('bias', tensor([0.3345]))]) \n",
            "\n",
            "Epoch: 24580 | Loss: 0.016501784324645996 | Test loss: 0.03858181834220886\n",
            "OrderedDict([('weights', tensor([0.6179])), ('bias', tensor([0.3345]))]) \n",
            "\n",
            "Epoch: 24590 | Loss: 0.016484612599015236 | Test loss: 0.038542311638593674\n",
            "OrderedDict([('weights', tensor([0.6180])), ('bias', tensor([0.3344]))]) \n",
            "\n",
            "Epoch: 24600 | Loss: 0.016467461362481117 | Test loss: 0.03850107640028\n",
            "OrderedDict([('weights', tensor([0.6181])), ('bias', tensor([0.3344]))]) \n",
            "\n",
            "Epoch: 24610 | Loss: 0.016450313851237297 | Test loss: 0.038461558520793915\n",
            "OrderedDict([('weights', tensor([0.6182])), ('bias', tensor([0.3344]))]) \n",
            "\n",
            "Epoch: 24620 | Loss: 0.01643313840031624 | Test loss: 0.03842033073306084\n",
            "OrderedDict([('weights', tensor([0.6183])), ('bias', tensor([0.3343]))]) \n",
            "\n",
            "Epoch: 24630 | Loss: 0.01641598343849182 | Test loss: 0.03838081285357475\n",
            "OrderedDict([('weights', tensor([0.6183])), ('bias', tensor([0.3343]))]) \n",
            "\n",
            "Epoch: 24640 | Loss: 0.016398822888731956 | Test loss: 0.038343071937561035\n",
            "OrderedDict([('weights', tensor([0.6184])), ('bias', tensor([0.3343]))]) \n",
            "\n",
            "Epoch: 24650 | Loss: 0.016381660476326942 | Test loss: 0.038300078362226486\n",
            "OrderedDict([('weights', tensor([0.6185])), ('bias', tensor([0.3342]))]) \n",
            "\n",
            "Epoch: 24660 | Loss: 0.016364512965083122 | Test loss: 0.03826231509447098\n",
            "OrderedDict([('weights', tensor([0.6186])), ('bias', tensor([0.3342]))]) \n",
            "\n",
            "Epoch: 24670 | Loss: 0.01634734496474266 | Test loss: 0.038222797214984894\n",
            "OrderedDict([('weights', tensor([0.6187])), ('bias', tensor([0.3342]))]) \n",
            "\n",
            "Epoch: 24680 | Loss: 0.016330203041434288 | Test loss: 0.03818158432841301\n",
            "OrderedDict([('weights', tensor([0.6188])), ('bias', tensor([0.3341]))]) \n",
            "\n",
            "Epoch: 24690 | Loss: 0.016313036903738976 | Test loss: 0.03814205527305603\n",
            "OrderedDict([('weights', tensor([0.6188])), ('bias', tensor([0.3341]))]) \n",
            "\n",
            "Epoch: 24700 | Loss: 0.016295893117785454 | Test loss: 0.03810084983706474\n",
            "OrderedDict([('weights', tensor([0.6189])), ('bias', tensor([0.3340]))]) \n",
            "\n",
            "Epoch: 24710 | Loss: 0.01627873070538044 | Test loss: 0.038061320781707764\n",
            "OrderedDict([('weights', tensor([0.6190])), ('bias', tensor([0.3340]))]) \n",
            "\n",
            "Epoch: 24720 | Loss: 0.016261566430330276 | Test loss: 0.03802008181810379\n",
            "OrderedDict([('weights', tensor([0.6191])), ('bias', tensor([0.3340]))]) \n",
            "\n",
            "Epoch: 24730 | Loss: 0.016244415193796158 | Test loss: 0.037980563938617706\n",
            "OrderedDict([('weights', tensor([0.6192])), ('bias', tensor([0.3339]))]) \n",
            "\n",
            "Epoch: 24740 | Loss: 0.01622723415493965 | Test loss: 0.03793935105204582\n",
            "OrderedDict([('weights', tensor([0.6193])), ('bias', tensor([0.3339]))]) \n",
            "\n",
            "Epoch: 24750 | Loss: 0.01621009223163128 | Test loss: 0.03789983317255974\n",
            "OrderedDict([('weights', tensor([0.6194])), ('bias', tensor([0.3339]))]) \n",
            "\n",
            "Epoch: 24760 | Loss: 0.016192909330129623 | Test loss: 0.03785863518714905\n",
            "OrderedDict([('weights', tensor([0.6194])), ('bias', tensor([0.3338]))]) \n",
            "\n",
            "Epoch: 24770 | Loss: 0.01617576740682125 | Test loss: 0.03781909868121147\n",
            "OrderedDict([('weights', tensor([0.6195])), ('bias', tensor([0.3338]))]) \n",
            "\n",
            "Epoch: 24780 | Loss: 0.016158604994416237 | Test loss: 0.037781309336423874\n",
            "OrderedDict([('weights', tensor([0.6196])), ('bias', tensor([0.3338]))]) \n",
            "\n",
            "Epoch: 24790 | Loss: 0.016141438856720924 | Test loss: 0.03773835301399231\n",
            "OrderedDict([('weights', tensor([0.6197])), ('bias', tensor([0.3337]))]) \n",
            "\n",
            "Epoch: 24800 | Loss: 0.016124296933412552 | Test loss: 0.03770056366920471\n",
            "OrderedDict([('weights', tensor([0.6198])), ('bias', tensor([0.3337]))]) \n",
            "\n",
            "Epoch: 24810 | Loss: 0.016107123345136642 | Test loss: 0.03766105696558952\n",
            "OrderedDict([('weights', tensor([0.6199])), ('bias', tensor([0.3337]))]) \n",
            "\n",
            "Epoch: 24820 | Loss: 0.016089990735054016 | Test loss: 0.03761982172727585\n",
            "OrderedDict([('weights', tensor([0.6200])), ('bias', tensor([0.3336]))]) \n",
            "\n",
            "Epoch: 24830 | Loss: 0.016072820872068405 | Test loss: 0.037580329924821854\n",
            "OrderedDict([('weights', tensor([0.6200])), ('bias', tensor([0.3336]))]) \n",
            "\n",
            "Epoch: 24840 | Loss: 0.01605566404759884 | Test loss: 0.03753909468650818\n",
            "OrderedDict([('weights', tensor([0.6201])), ('bias', tensor([0.3335]))]) \n",
            "\n",
            "Epoch: 24850 | Loss: 0.01603851094841957 | Test loss: 0.03749958425760269\n",
            "OrderedDict([('weights', tensor([0.6202])), ('bias', tensor([0.3335]))]) \n",
            "\n",
            "Epoch: 24860 | Loss: 0.016021350398659706 | Test loss: 0.03745833784341812\n",
            "OrderedDict([('weights', tensor([0.6203])), ('bias', tensor([0.3335]))]) \n",
            "\n",
            "Epoch: 24870 | Loss: 0.016004197299480438 | Test loss: 0.037418849766254425\n",
            "OrderedDict([('weights', tensor([0.6204])), ('bias', tensor([0.3334]))]) \n",
            "\n",
            "Epoch: 24880 | Loss: 0.015987014397978783 | Test loss: 0.037377603352069855\n",
            "OrderedDict([('weights', tensor([0.6205])), ('bias', tensor([0.3334]))]) \n",
            "\n",
            "Epoch: 24890 | Loss: 0.015969866886734962 | Test loss: 0.03733810782432556\n",
            "OrderedDict([('weights', tensor([0.6206])), ('bias', tensor([0.3334]))]) \n",
            "\n",
            "Epoch: 24900 | Loss: 0.015952685847878456 | Test loss: 0.03729860112071037\n",
            "OrderedDict([('weights', tensor([0.6206])), ('bias', tensor([0.3333]))]) \n",
            "\n",
            "Epoch: 24910 | Loss: 0.015935545787215233 | Test loss: 0.0372573547065258\n",
            "OrderedDict([('weights', tensor([0.6207])), ('bias', tensor([0.3333]))]) \n",
            "\n",
            "Epoch: 24920 | Loss: 0.015918385237455368 | Test loss: 0.037219613790512085\n",
            "OrderedDict([('weights', tensor([0.6208])), ('bias', tensor([0.3333]))]) \n",
            "\n",
            "Epoch: 24930 | Loss: 0.015901217237114906 | Test loss: 0.037176620215177536\n",
            "OrderedDict([('weights', tensor([0.6209])), ('bias', tensor([0.3332]))]) \n",
            "\n",
            "Epoch: 24940 | Loss: 0.015884079039096832 | Test loss: 0.03713883087038994\n",
            "OrderedDict([('weights', tensor([0.6210])), ('bias', tensor([0.3332]))]) \n",
            "\n",
            "Epoch: 24950 | Loss: 0.015866901725530624 | Test loss: 0.03709933161735535\n",
            "OrderedDict([('weights', tensor([0.6211])), ('bias', tensor([0.3331]))]) \n",
            "\n",
            "Epoch: 24960 | Loss: 0.01584973931312561 | Test loss: 0.037056367844343185\n",
            "OrderedDict([('weights', tensor([0.6212])), ('bias', tensor([0.3331]))]) \n",
            "\n",
            "Epoch: 24970 | Loss: 0.015832604840397835 | Test loss: 0.03701858967542648\n",
            "OrderedDict([('weights', tensor([0.6212])), ('bias', tensor([0.3331]))]) \n",
            "\n",
            "Epoch: 24980 | Loss: 0.015815451741218567 | Test loss: 0.0369773805141449\n",
            "OrderedDict([('weights', tensor([0.6213])), ('bias', tensor([0.3330]))]) \n",
            "\n",
            "Epoch: 24990 | Loss: 0.015798302367329597 | Test loss: 0.03693785145878792\n",
            "OrderedDict([('weights', tensor([0.6214])), ('bias', tensor([0.3330]))]) \n",
            "\n",
            "Epoch: 25000 | Loss: 0.01578112319111824 | Test loss: 0.03689659759402275\n",
            "OrderedDict([('weights', tensor([0.6215])), ('bias', tensor([0.3330]))]) \n",
            "\n",
            "Epoch: 25010 | Loss: 0.01576397754251957 | Test loss: 0.03685711696743965\n",
            "OrderedDict([('weights', tensor([0.6216])), ('bias', tensor([0.3329]))]) \n",
            "\n",
            "Epoch: 25020 | Loss: 0.015746816992759705 | Test loss: 0.03681759163737297\n",
            "OrderedDict([('weights', tensor([0.6217])), ('bias', tensor([0.3329]))]) \n",
            "\n",
            "Epoch: 25030 | Loss: 0.01572965458035469 | Test loss: 0.03677637130022049\n",
            "OrderedDict([('weights', tensor([0.6218])), ('bias', tensor([0.3329]))]) \n",
            "\n",
            "Epoch: 25040 | Loss: 0.015712473541498184 | Test loss: 0.036736853420734406\n",
            "OrderedDict([('weights', tensor([0.6218])), ('bias', tensor([0.3328]))]) \n",
            "\n",
            "Epoch: 25050 | Loss: 0.015695326030254364 | Test loss: 0.036695629358291626\n",
            "OrderedDict([('weights', tensor([0.6219])), ('bias', tensor([0.3328]))]) \n",
            "\n",
            "Epoch: 25060 | Loss: 0.01567816361784935 | Test loss: 0.03665784001350403\n",
            "OrderedDict([('weights', tensor([0.6220])), ('bias', tensor([0.3328]))]) \n",
            "\n",
            "Epoch: 25070 | Loss: 0.015660995617508888 | Test loss: 0.03661489486694336\n",
            "OrderedDict([('weights', tensor([0.6221])), ('bias', tensor([0.3327]))]) \n",
            "\n",
            "Epoch: 25080 | Loss: 0.015643849968910217 | Test loss: 0.036575376987457275\n",
            "OrderedDict([('weights', tensor([0.6222])), ('bias', tensor([0.3327]))]) \n",
            "\n",
            "Epoch: 25090 | Loss: 0.015626689419150352 | Test loss: 0.03653759881854057\n",
            "OrderedDict([('weights', tensor([0.6223])), ('bias', tensor([0.3326]))]) \n",
            "\n",
            "Epoch: 25100 | Loss: 0.01560952328145504 | Test loss: 0.03649462014436722\n",
            "OrderedDict([('weights', tensor([0.6223])), ('bias', tensor([0.3326]))]) \n",
            "\n",
            "Epoch: 25110 | Loss: 0.015592376701533794 | Test loss: 0.03645685315132141\n",
            "OrderedDict([('weights', tensor([0.6224])), ('bias', tensor([0.3326]))]) \n",
            "\n",
            "Epoch: 25120 | Loss: 0.015575232915580273 | Test loss: 0.03641560673713684\n",
            "OrderedDict([('weights', tensor([0.6225])), ('bias', tensor([0.3325]))]) \n",
            "\n",
            "Epoch: 25130 | Loss: 0.015558077022433281 | Test loss: 0.03637610003352165\n",
            "OrderedDict([('weights', tensor([0.6226])), ('bias', tensor([0.3325]))]) \n",
            "\n",
            "Epoch: 25140 | Loss: 0.015540899708867073 | Test loss: 0.036336593329906464\n",
            "OrderedDict([('weights', tensor([0.6227])), ('bias', tensor([0.3325]))]) \n",
            "\n",
            "Epoch: 25150 | Loss: 0.015523766167461872 | Test loss: 0.036295365542173386\n",
            "OrderedDict([('weights', tensor([0.6228])), ('bias', tensor([0.3324]))]) \n",
            "\n",
            "Epoch: 25160 | Loss: 0.015506592579185963 | Test loss: 0.0362558476626873\n",
            "OrderedDict([('weights', tensor([0.6229])), ('bias', tensor([0.3324]))]) \n",
            "\n",
            "Epoch: 25170 | Loss: 0.015489429235458374 | Test loss: 0.036214619874954224\n",
            "OrderedDict([('weights', tensor([0.6229])), ('bias', tensor([0.3324]))]) \n",
            "\n",
            "Epoch: 25180 | Loss: 0.015472257509827614 | Test loss: 0.036175113171339035\n",
            "OrderedDict([('weights', tensor([0.6230])), ('bias', tensor([0.3323]))]) \n",
            "\n",
            "Epoch: 25190 | Loss: 0.015455106273293495 | Test loss: 0.03613387793302536\n",
            "OrderedDict([('weights', tensor([0.6231])), ('bias', tensor([0.3323]))]) \n",
            "\n",
            "Epoch: 25200 | Loss: 0.015437958762049675 | Test loss: 0.036094360053539276\n",
            "OrderedDict([('weights', tensor([0.6232])), ('bias', tensor([0.3323]))]) \n",
            "\n",
            "Epoch: 25210 | Loss: 0.015420782379806042 | Test loss: 0.0360531322658062\n",
            "OrderedDict([('weights', tensor([0.6233])), ('bias', tensor([0.3322]))]) \n",
            "\n",
            "Epoch: 25220 | Loss: 0.0154036283493042 | Test loss: 0.036013614386320114\n",
            "OrderedDict([('weights', tensor([0.6234])), ('bias', tensor([0.3322]))]) \n",
            "\n",
            "Epoch: 25230 | Loss: 0.015386467799544334 | Test loss: 0.035975873470306396\n",
            "OrderedDict([('weights', tensor([0.6235])), ('bias', tensor([0.3321]))]) \n",
            "\n",
            "Epoch: 25240 | Loss: 0.01536930538713932 | Test loss: 0.03593287989497185\n",
            "OrderedDict([('weights', tensor([0.6235])), ('bias', tensor([0.3321]))]) \n",
            "\n",
            "Epoch: 25250 | Loss: 0.0153521578758955 | Test loss: 0.03589511662721634\n",
            "OrderedDict([('weights', tensor([0.6236])), ('bias', tensor([0.3321]))]) \n",
            "\n",
            "Epoch: 25260 | Loss: 0.015334988944232464 | Test loss: 0.035855598747730255\n",
            "OrderedDict([('weights', tensor([0.6237])), ('bias', tensor([0.3320]))]) \n",
            "\n",
            "Epoch: 25270 | Loss: 0.015317847952246666 | Test loss: 0.03581438586115837\n",
            "OrderedDict([('weights', tensor([0.6238])), ('bias', tensor([0.3320]))]) \n",
            "\n",
            "Epoch: 25280 | Loss: 0.015300681814551353 | Test loss: 0.03577485680580139\n",
            "OrderedDict([('weights', tensor([0.6239])), ('bias', tensor([0.3320]))]) \n",
            "\n",
            "Epoch: 25290 | Loss: 0.015283538028597832 | Test loss: 0.035733651369810104\n",
            "OrderedDict([('weights', tensor([0.6240])), ('bias', tensor([0.3319]))]) \n",
            "\n",
            "Epoch: 25300 | Loss: 0.015266375616192818 | Test loss: 0.035694122314453125\n",
            "OrderedDict([('weights', tensor([0.6241])), ('bias', tensor([0.3319]))]) \n",
            "\n",
            "Epoch: 25310 | Loss: 0.01524921040982008 | Test loss: 0.03565288335084915\n",
            "OrderedDict([('weights', tensor([0.6241])), ('bias', tensor([0.3319]))]) \n",
            "\n",
            "Epoch: 25320 | Loss: 0.015232059173285961 | Test loss: 0.03561336547136307\n",
            "OrderedDict([('weights', tensor([0.6242])), ('bias', tensor([0.3318]))]) \n",
            "\n",
            "Epoch: 25330 | Loss: 0.015214879997074604 | Test loss: 0.035572152584791183\n",
            "OrderedDict([('weights', tensor([0.6243])), ('bias', tensor([0.3318]))]) \n",
            "\n",
            "Epoch: 25340 | Loss: 0.015197737142443657 | Test loss: 0.0355326347053051\n",
            "OrderedDict([('weights', tensor([0.6244])), ('bias', tensor([0.3318]))]) \n",
            "\n",
            "Epoch: 25350 | Loss: 0.015180555172264576 | Test loss: 0.03549143671989441\n",
            "OrderedDict([('weights', tensor([0.6245])), ('bias', tensor([0.3317]))]) \n",
            "\n",
            "Epoch: 25360 | Loss: 0.015163412317633629 | Test loss: 0.03545190021395683\n",
            "OrderedDict([('weights', tensor([0.6246])), ('bias', tensor([0.3317]))]) \n",
            "\n",
            "Epoch: 25370 | Loss: 0.015146249905228615 | Test loss: 0.035414110869169235\n",
            "OrderedDict([('weights', tensor([0.6247])), ('bias', tensor([0.3316]))]) \n",
            "\n",
            "Epoch: 25380 | Loss: 0.015129083767533302 | Test loss: 0.03537115454673767\n",
            "OrderedDict([('weights', tensor([0.6247])), ('bias', tensor([0.3316]))]) \n",
            "\n",
            "Epoch: 25390 | Loss: 0.015111942775547504 | Test loss: 0.03533336520195007\n",
            "OrderedDict([('weights', tensor([0.6248])), ('bias', tensor([0.3316]))]) \n",
            "\n",
            "Epoch: 25400 | Loss: 0.015094769187271595 | Test loss: 0.035293858498334885\n",
            "OrderedDict([('weights', tensor([0.6249])), ('bias', tensor([0.3315]))]) \n",
            "\n",
            "Epoch: 25410 | Loss: 0.015077635645866394 | Test loss: 0.03525262326002121\n",
            "OrderedDict([('weights', tensor([0.6250])), ('bias', tensor([0.3315]))]) \n",
            "\n",
            "Epoch: 25420 | Loss: 0.015060466714203358 | Test loss: 0.035213131457567215\n",
            "OrderedDict([('weights', tensor([0.6251])), ('bias', tensor([0.3315]))]) \n",
            "\n",
            "Epoch: 25430 | Loss: 0.015043306164443493 | Test loss: 0.03517189621925354\n",
            "OrderedDict([('weights', tensor([0.6252])), ('bias', tensor([0.3314]))]) \n",
            "\n",
            "Epoch: 25440 | Loss: 0.015026154927909374 | Test loss: 0.03513238951563835\n",
            "OrderedDict([('weights', tensor([0.6253])), ('bias', tensor([0.3314]))]) \n",
            "\n",
            "Epoch: 25450 | Loss: 0.015008995309472084 | Test loss: 0.035091131925582886\n",
            "OrderedDict([('weights', tensor([0.6253])), ('bias', tensor([0.3314]))]) \n",
            "\n",
            "Epoch: 25460 | Loss: 0.014991842210292816 | Test loss: 0.035051651298999786\n",
            "OrderedDict([('weights', tensor([0.6254])), ('bias', tensor([0.3313]))]) \n",
            "\n",
            "Epoch: 25470 | Loss: 0.01497465930879116 | Test loss: 0.035010404884815216\n",
            "OrderedDict([('weights', tensor([0.6255])), ('bias', tensor([0.3313]))]) \n",
            "\n",
            "Epoch: 25480 | Loss: 0.014957512728869915 | Test loss: 0.03497090935707092\n",
            "OrderedDict([('weights', tensor([0.6256])), ('bias', tensor([0.3313]))]) \n",
            "\n",
            "Epoch: 25490 | Loss: 0.014940330758690834 | Test loss: 0.034931402653455734\n",
            "OrderedDict([('weights', tensor([0.6257])), ('bias', tensor([0.3312]))]) \n",
            "\n",
            "Epoch: 25500 | Loss: 0.01492319069802761 | Test loss: 0.034890156239271164\n",
            "OrderedDict([('weights', tensor([0.6258])), ('bias', tensor([0.3312]))]) \n",
            "\n",
            "Epoch: 25510 | Loss: 0.014906029216945171 | Test loss: 0.034852415323257446\n",
            "OrderedDict([('weights', tensor([0.6258])), ('bias', tensor([0.3311]))]) \n",
            "\n",
            "Epoch: 25520 | Loss: 0.014888862147927284 | Test loss: 0.0348094180226326\n",
            "OrderedDict([('weights', tensor([0.6259])), ('bias', tensor([0.3311]))]) \n",
            "\n",
            "Epoch: 25530 | Loss: 0.01487172394990921 | Test loss: 0.034771628677845\n",
            "OrderedDict([('weights', tensor([0.6260])), ('bias', tensor([0.3311]))]) \n",
            "\n",
            "Epoch: 25540 | Loss: 0.014854547567665577 | Test loss: 0.03473213315010071\n",
            "OrderedDict([('weights', tensor([0.6261])), ('bias', tensor([0.3310]))]) \n",
            "\n",
            "Epoch: 25550 | Loss: 0.014837387017905712 | Test loss: 0.03468916937708855\n",
            "OrderedDict([('weights', tensor([0.6262])), ('bias', tensor([0.3310]))]) \n",
            "\n",
            "Epoch: 25560 | Loss: 0.014820249751210213 | Test loss: 0.034651391208171844\n",
            "OrderedDict([('weights', tensor([0.6263])), ('bias', tensor([0.3310]))]) \n",
            "\n",
            "Epoch: 25570 | Loss: 0.014803096652030945 | Test loss: 0.03461018204689026\n",
            "OrderedDict([('weights', tensor([0.6264])), ('bias', tensor([0.3309]))]) \n",
            "\n",
            "Epoch: 25580 | Loss: 0.0147859500721097 | Test loss: 0.03457065299153328\n",
            "OrderedDict([('weights', tensor([0.6264])), ('bias', tensor([0.3309]))]) \n",
            "\n",
            "Epoch: 25590 | Loss: 0.014768769964575768 | Test loss: 0.034529395401477814\n",
            "OrderedDict([('weights', tensor([0.6265])), ('bias', tensor([0.3309]))]) \n",
            "\n",
            "Epoch: 25600 | Loss: 0.014751622453331947 | Test loss: 0.034489911049604416\n",
            "OrderedDict([('weights', tensor([0.6266])), ('bias', tensor([0.3308]))]) \n",
            "\n",
            "Epoch: 25610 | Loss: 0.014734461903572083 | Test loss: 0.03445039317011833\n",
            "OrderedDict([('weights', tensor([0.6267])), ('bias', tensor([0.3308]))]) \n",
            "\n",
            "Epoch: 25620 | Loss: 0.014717298559844494 | Test loss: 0.03440917283296585\n",
            "OrderedDict([('weights', tensor([0.6268])), ('bias', tensor([0.3307]))]) \n",
            "\n",
            "Epoch: 25630 | Loss: 0.014700117520987988 | Test loss: 0.03436965495347977\n",
            "OrderedDict([('weights', tensor([0.6269])), ('bias', tensor([0.3307]))]) \n",
            "\n",
            "Epoch: 25640 | Loss: 0.014682970941066742 | Test loss: 0.03432843089103699\n",
            "OrderedDict([('weights', tensor([0.6270])), ('bias', tensor([0.3307]))]) \n",
            "\n",
            "Epoch: 25650 | Loss: 0.014665809459984303 | Test loss: 0.03429064154624939\n",
            "OrderedDict([('weights', tensor([0.6270])), ('bias', tensor([0.3306]))]) \n",
            "\n",
            "Epoch: 25660 | Loss: 0.01464864332228899 | Test loss: 0.034247688949108124\n",
            "OrderedDict([('weights', tensor([0.6271])), ('bias', tensor([0.3306]))]) \n",
            "\n",
            "Epoch: 25670 | Loss: 0.014631494879722595 | Test loss: 0.03420817106962204\n",
            "OrderedDict([('weights', tensor([0.6272])), ('bias', tensor([0.3306]))]) \n",
            "\n",
            "Epoch: 25680 | Loss: 0.014614331535995007 | Test loss: 0.034170396625995636\n",
            "OrderedDict([('weights', tensor([0.6273])), ('bias', tensor([0.3305]))]) \n",
            "\n",
            "Epoch: 25690 | Loss: 0.014597168192267418 | Test loss: 0.03412742167711258\n",
            "OrderedDict([('weights', tensor([0.6274])), ('bias', tensor([0.3305]))]) \n",
            "\n",
            "Epoch: 25700 | Loss: 0.014580021612346172 | Test loss: 0.03408965468406677\n",
            "OrderedDict([('weights', tensor([0.6275])), ('bias', tensor([0.3305]))]) \n",
            "\n",
            "Epoch: 25710 | Loss: 0.01456287782639265 | Test loss: 0.0340484082698822\n",
            "OrderedDict([('weights', tensor([0.6276])), ('bias', tensor([0.3304]))]) \n",
            "\n",
            "Epoch: 25720 | Loss: 0.014545721933245659 | Test loss: 0.034008901566267014\n",
            "OrderedDict([('weights', tensor([0.6276])), ('bias', tensor([0.3304]))]) \n",
            "\n",
            "Epoch: 25730 | Loss: 0.014528547413647175 | Test loss: 0.033969394862651825\n",
            "OrderedDict([('weights', tensor([0.6277])), ('bias', tensor([0.3304]))]) \n",
            "\n",
            "Epoch: 25740 | Loss: 0.014511413872241974 | Test loss: 0.03392816334962845\n",
            "OrderedDict([('weights', tensor([0.6278])), ('bias', tensor([0.3303]))]) \n",
            "\n",
            "Epoch: 25750 | Loss: 0.01449423748999834 | Test loss: 0.033888645470142365\n",
            "OrderedDict([('weights', tensor([0.6279])), ('bias', tensor([0.3303]))]) \n",
            "\n",
            "Epoch: 25760 | Loss: 0.014477074146270752 | Test loss: 0.033847421407699585\n",
            "OrderedDict([('weights', tensor([0.6280])), ('bias', tensor([0.3302]))]) \n",
            "\n",
            "Epoch: 25770 | Loss: 0.014459902420639992 | Test loss: 0.033807914704084396\n",
            "OrderedDict([('weights', tensor([0.6281])), ('bias', tensor([0.3302]))]) \n",
            "\n",
            "Epoch: 25780 | Loss: 0.014442751184105873 | Test loss: 0.03376667946577072\n",
            "OrderedDict([('weights', tensor([0.6282])), ('bias', tensor([0.3302]))]) \n",
            "\n",
            "Epoch: 25790 | Loss: 0.014425600878894329 | Test loss: 0.03372716158628464\n",
            "OrderedDict([('weights', tensor([0.6282])), ('bias', tensor([0.3301]))]) \n",
            "\n",
            "Epoch: 25800 | Loss: 0.01440842729061842 | Test loss: 0.033685941249132156\n",
            "OrderedDict([('weights', tensor([0.6283])), ('bias', tensor([0.3301]))]) \n",
            "\n",
            "Epoch: 25810 | Loss: 0.014391273260116577 | Test loss: 0.03364641219377518\n",
            "OrderedDict([('weights', tensor([0.6284])), ('bias', tensor([0.3301]))]) \n",
            "\n",
            "Epoch: 25820 | Loss: 0.014374112710356712 | Test loss: 0.03360866755247116\n",
            "OrderedDict([('weights', tensor([0.6285])), ('bias', tensor([0.3300]))]) \n",
            "\n",
            "Epoch: 25830 | Loss: 0.014356950297951698 | Test loss: 0.03356568142771721\n",
            "OrderedDict([('weights', tensor([0.6286])), ('bias', tensor([0.3300]))]) \n",
            "\n",
            "Epoch: 25840 | Loss: 0.014339802786707878 | Test loss: 0.0335279181599617\n",
            "OrderedDict([('weights', tensor([0.6287])), ('bias', tensor([0.3300]))]) \n",
            "\n",
            "Epoch: 25850 | Loss: 0.014322633855044842 | Test loss: 0.033488400280475616\n",
            "OrderedDict([('weights', tensor([0.6288])), ('bias', tensor([0.3299]))]) \n",
            "\n",
            "Epoch: 25860 | Loss: 0.01430549006909132 | Test loss: 0.03344718739390373\n",
            "OrderedDict([('weights', tensor([0.6288])), ('bias', tensor([0.3299]))]) \n",
            "\n",
            "Epoch: 25870 | Loss: 0.014288326725363731 | Test loss: 0.03340765833854675\n",
            "OrderedDict([('weights', tensor([0.6289])), ('bias', tensor([0.3299]))]) \n",
            "\n",
            "Epoch: 25880 | Loss: 0.01427118293941021 | Test loss: 0.03336646035313606\n",
            "OrderedDict([('weights', tensor([0.6290])), ('bias', tensor([0.3298]))]) \n",
            "\n",
            "Epoch: 25890 | Loss: 0.014254018664360046 | Test loss: 0.03332691639661789\n",
            "OrderedDict([('weights', tensor([0.6291])), ('bias', tensor([0.3298]))]) \n",
            "\n",
            "Epoch: 25900 | Loss: 0.014236855320632458 | Test loss: 0.03328568488359451\n",
            "OrderedDict([('weights', tensor([0.6292])), ('bias', tensor([0.3297]))]) \n",
            "\n",
            "Epoch: 25910 | Loss: 0.014219704084098339 | Test loss: 0.03324616700410843\n",
            "OrderedDict([('weights', tensor([0.6293])), ('bias', tensor([0.3297]))]) \n",
            "\n",
            "Epoch: 25920 | Loss: 0.014202525839209557 | Test loss: 0.033204954117536545\n",
            "OrderedDict([('weights', tensor([0.6293])), ('bias', tensor([0.3297]))]) \n",
            "\n",
            "Epoch: 25930 | Loss: 0.01418538112193346 | Test loss: 0.03316543623805046\n",
            "OrderedDict([('weights', tensor([0.6294])), ('bias', tensor([0.3296]))]) \n",
            "\n",
            "Epoch: 25940 | Loss: 0.014168200083076954 | Test loss: 0.03312423825263977\n",
            "OrderedDict([('weights', tensor([0.6295])), ('bias', tensor([0.3296]))]) \n",
            "\n",
            "Epoch: 25950 | Loss: 0.014151057228446007 | Test loss: 0.03308470919728279\n",
            "OrderedDict([('weights', tensor([0.6296])), ('bias', tensor([0.3296]))]) \n",
            "\n",
            "Epoch: 25960 | Loss: 0.014133894816040993 | Test loss: 0.033046919852495193\n",
            "OrderedDict([('weights', tensor([0.6297])), ('bias', tensor([0.3295]))]) \n",
            "\n",
            "Epoch: 25970 | Loss: 0.01411672867834568 | Test loss: 0.03300395607948303\n",
            "OrderedDict([('weights', tensor([0.6298])), ('bias', tensor([0.3295]))]) \n",
            "\n",
            "Epoch: 25980 | Loss: 0.014099587686359882 | Test loss: 0.032966166734695435\n",
            "OrderedDict([('weights', tensor([0.6299])), ('bias', tensor([0.3295]))]) \n",
            "\n",
            "Epoch: 25990 | Loss: 0.014082414098083973 | Test loss: 0.032926660031080246\n",
            "OrderedDict([('weights', tensor([0.6299])), ('bias', tensor([0.3294]))]) \n",
            "\n",
            "Epoch: 26000 | Loss: 0.014065280556678772 | Test loss: 0.03288542479276657\n",
            "OrderedDict([('weights', tensor([0.6300])), ('bias', tensor([0.3294]))]) \n",
            "\n",
            "Epoch: 26010 | Loss: 0.014048109762370586 | Test loss: 0.032845932990312576\n",
            "OrderedDict([('weights', tensor([0.6301])), ('bias', tensor([0.3293]))]) \n",
            "\n",
            "Epoch: 26020 | Loss: 0.01403095293790102 | Test loss: 0.0328046977519989\n",
            "OrderedDict([('weights', tensor([0.6302])), ('bias', tensor([0.3293]))]) \n",
            "\n",
            "Epoch: 26030 | Loss: 0.014013799838721752 | Test loss: 0.03276519104838371\n",
            "OrderedDict([('weights', tensor([0.6303])), ('bias', tensor([0.3293]))]) \n",
            "\n",
            "Epoch: 26040 | Loss: 0.013996640220284462 | Test loss: 0.03272393345832825\n",
            "OrderedDict([('weights', tensor([0.6304])), ('bias', tensor([0.3292]))]) \n",
            "\n",
            "Epoch: 26050 | Loss: 0.013979485258460045 | Test loss: 0.03268445283174515\n",
            "OrderedDict([('weights', tensor([0.6305])), ('bias', tensor([0.3292]))]) \n",
            "\n",
            "Epoch: 26060 | Loss: 0.013962304219603539 | Test loss: 0.03264320641756058\n",
            "OrderedDict([('weights', tensor([0.6305])), ('bias', tensor([0.3292]))]) \n",
            "\n",
            "Epoch: 26070 | Loss: 0.013945157639682293 | Test loss: 0.032603710889816284\n",
            "OrderedDict([('weights', tensor([0.6306])), ('bias', tensor([0.3291]))]) \n",
            "\n",
            "Epoch: 26080 | Loss: 0.013927973806858063 | Test loss: 0.032564204186201096\n",
            "OrderedDict([('weights', tensor([0.6307])), ('bias', tensor([0.3291]))]) \n",
            "\n",
            "Epoch: 26090 | Loss: 0.013910835608839989 | Test loss: 0.032522957772016525\n",
            "OrderedDict([('weights', tensor([0.6308])), ('bias', tensor([0.3291]))]) \n",
            "\n",
            "Epoch: 26100 | Loss: 0.013893675990402699 | Test loss: 0.03248521685600281\n",
            "OrderedDict([('weights', tensor([0.6309])), ('bias', tensor([0.3290]))]) \n",
            "\n",
            "Epoch: 26110 | Loss: 0.013876507058739662 | Test loss: 0.03244221955537796\n",
            "OrderedDict([('weights', tensor([0.6310])), ('bias', tensor([0.3290]))]) \n",
            "\n",
            "Epoch: 26120 | Loss: 0.013859366998076439 | Test loss: 0.03240443021059036\n",
            "OrderedDict([('weights', tensor([0.6311])), ('bias', tensor([0.3290]))]) \n",
            "\n",
            "Epoch: 26130 | Loss: 0.013842192478477955 | Test loss: 0.03236493468284607\n",
            "OrderedDict([('weights', tensor([0.6311])), ('bias', tensor([0.3289]))]) \n",
            "\n",
            "Epoch: 26140 | Loss: 0.01382503192871809 | Test loss: 0.03232197090983391\n",
            "OrderedDict([('weights', tensor([0.6312])), ('bias', tensor([0.3289]))]) \n",
            "\n",
            "Epoch: 26150 | Loss: 0.013807895593345165 | Test loss: 0.032284192740917206\n",
            "OrderedDict([('weights', tensor([0.6313])), ('bias', tensor([0.3288]))]) \n",
            "\n",
            "Epoch: 26160 | Loss: 0.013790741562843323 | Test loss: 0.03224298357963562\n",
            "OrderedDict([('weights', tensor([0.6314])), ('bias', tensor([0.3288]))]) \n",
            "\n",
            "Epoch: 26170 | Loss: 0.013773593120276928 | Test loss: 0.03220345452427864\n",
            "OrderedDict([('weights', tensor([0.6315])), ('bias', tensor([0.3288]))]) \n",
            "\n",
            "Epoch: 26180 | Loss: 0.013756414875388145 | Test loss: 0.032162196934223175\n",
            "OrderedDict([('weights', tensor([0.6316])), ('bias', tensor([0.3287]))]) \n",
            "\n",
            "Epoch: 26190 | Loss: 0.013739267364144325 | Test loss: 0.03212271258234978\n",
            "OrderedDict([('weights', tensor([0.6317])), ('bias', tensor([0.3287]))]) \n",
            "\n",
            "Epoch: 26200 | Loss: 0.01372210681438446 | Test loss: 0.03208319470286369\n",
            "OrderedDict([('weights', tensor([0.6317])), ('bias', tensor([0.3287]))]) \n",
            "\n",
            "Epoch: 26210 | Loss: 0.013704943470656872 | Test loss: 0.03204197436571121\n",
            "OrderedDict([('weights', tensor([0.6318])), ('bias', tensor([0.3286]))]) \n",
            "\n",
            "Epoch: 26220 | Loss: 0.013687762431800365 | Test loss: 0.03200245648622513\n",
            "OrderedDict([('weights', tensor([0.6319])), ('bias', tensor([0.3286]))]) \n",
            "\n",
            "Epoch: 26230 | Loss: 0.01367061398923397 | Test loss: 0.03196123242378235\n",
            "OrderedDict([('weights', tensor([0.6320])), ('bias', tensor([0.3286]))]) \n",
            "\n",
            "Epoch: 26240 | Loss: 0.01365345437079668 | Test loss: 0.03192344307899475\n",
            "OrderedDict([('weights', tensor([0.6321])), ('bias', tensor([0.3285]))]) \n",
            "\n",
            "Epoch: 26250 | Loss: 0.013636288233101368 | Test loss: 0.031880490481853485\n",
            "OrderedDict([('weights', tensor([0.6322])), ('bias', tensor([0.3285]))]) \n",
            "\n",
            "Epoch: 26260 | Loss: 0.013619139790534973 | Test loss: 0.0318409726023674\n",
            "OrderedDict([('weights', tensor([0.6323])), ('bias', tensor([0.3285]))]) \n",
            "\n",
            "Epoch: 26270 | Loss: 0.013601976446807384 | Test loss: 0.031803198158741\n",
            "OrderedDict([('weights', tensor([0.6323])), ('bias', tensor([0.3284]))]) \n",
            "\n",
            "Epoch: 26280 | Loss: 0.013584814965724945 | Test loss: 0.03176022320985794\n",
            "OrderedDict([('weights', tensor([0.6324])), ('bias', tensor([0.3284]))]) \n",
            "\n",
            "Epoch: 26290 | Loss: 0.01356766652315855 | Test loss: 0.031722456216812134\n",
            "OrderedDict([('weights', tensor([0.6325])), ('bias', tensor([0.3283]))]) \n",
            "\n",
            "Epoch: 26300 | Loss: 0.013550522737205029 | Test loss: 0.031681209802627563\n",
            "OrderedDict([('weights', tensor([0.6326])), ('bias', tensor([0.3283]))]) \n",
            "\n",
            "Epoch: 26310 | Loss: 0.013533366844058037 | Test loss: 0.031641703099012375\n",
            "OrderedDict([('weights', tensor([0.6327])), ('bias', tensor([0.3283]))]) \n",
            "\n",
            "Epoch: 26320 | Loss: 0.013516190461814404 | Test loss: 0.031602196395397186\n",
            "OrderedDict([('weights', tensor([0.6328])), ('bias', tensor([0.3282]))]) \n",
            "\n",
            "Epoch: 26330 | Loss: 0.013499056920409203 | Test loss: 0.03156096488237381\n",
            "OrderedDict([('weights', tensor([0.6328])), ('bias', tensor([0.3282]))]) \n",
            "\n",
            "Epoch: 26340 | Loss: 0.013481882400810719 | Test loss: 0.031521447002887726\n",
            "OrderedDict([('weights', tensor([0.6329])), ('bias', tensor([0.3282]))]) \n",
            "\n",
            "Epoch: 26350 | Loss: 0.01346471905708313 | Test loss: 0.031480222940444946\n",
            "OrderedDict([('weights', tensor([0.6330])), ('bias', tensor([0.3281]))]) \n",
            "\n",
            "Epoch: 26360 | Loss: 0.01344754733145237 | Test loss: 0.03144071623682976\n",
            "OrderedDict([('weights', tensor([0.6331])), ('bias', tensor([0.3281]))]) \n",
            "\n",
            "Epoch: 26370 | Loss: 0.013430396094918251 | Test loss: 0.03139948099851608\n",
            "OrderedDict([('weights', tensor([0.6332])), ('bias', tensor([0.3281]))]) \n",
            "\n",
            "Epoch: 26380 | Loss: 0.013413247652351856 | Test loss: 0.03135996311903\n",
            "OrderedDict([('weights', tensor([0.6333])), ('bias', tensor([0.3280]))]) \n",
            "\n",
            "Epoch: 26390 | Loss: 0.013396072201430798 | Test loss: 0.03131874278187752\n",
            "OrderedDict([('weights', tensor([0.6334])), ('bias', tensor([0.3280]))]) \n",
            "\n",
            "Epoch: 26400 | Loss: 0.013378918170928955 | Test loss: 0.03127921372652054\n",
            "OrderedDict([('weights', tensor([0.6334])), ('bias', tensor([0.3280]))]) \n",
            "\n",
            "Epoch: 26410 | Loss: 0.01336175762116909 | Test loss: 0.03124147094786167\n",
            "OrderedDict([('weights', tensor([0.6335])), ('bias', tensor([0.3279]))]) \n",
            "\n",
            "Epoch: 26420 | Loss: 0.013344595208764076 | Test loss: 0.03119848296046257\n",
            "OrderedDict([('weights', tensor([0.6336])), ('bias', tensor([0.3279]))]) \n",
            "\n",
            "Epoch: 26430 | Loss: 0.013327447697520256 | Test loss: 0.031160717830061913\n",
            "OrderedDict([('weights', tensor([0.6337])), ('bias', tensor([0.3278]))]) \n",
            "\n",
            "Epoch: 26440 | Loss: 0.013310277834534645 | Test loss: 0.03112119995057583\n",
            "OrderedDict([('weights', tensor([0.6338])), ('bias', tensor([0.3278]))]) \n",
            "\n",
            "Epoch: 26450 | Loss: 0.013293136842548847 | Test loss: 0.031079988926649094\n",
            "OrderedDict([('weights', tensor([0.6339])), ('bias', tensor([0.3278]))]) \n",
            "\n",
            "Epoch: 26460 | Loss: 0.01327597163617611 | Test loss: 0.031040459871292114\n",
            "OrderedDict([('weights', tensor([0.6340])), ('bias', tensor([0.3277]))]) \n",
            "\n",
            "Epoch: 26470 | Loss: 0.013258827850222588 | Test loss: 0.030999261885881424\n",
            "OrderedDict([('weights', tensor([0.6340])), ('bias', tensor([0.3277]))]) \n",
            "\n",
            "Epoch: 26480 | Loss: 0.013241663575172424 | Test loss: 0.0309597197920084\n",
            "OrderedDict([('weights', tensor([0.6341])), ('bias', tensor([0.3277]))]) \n",
            "\n",
            "Epoch: 26490 | Loss: 0.013224500231444836 | Test loss: 0.030918484553694725\n",
            "OrderedDict([('weights', tensor([0.6342])), ('bias', tensor([0.3276]))]) \n",
            "\n",
            "Epoch: 26500 | Loss: 0.013207348994910717 | Test loss: 0.03087896667420864\n",
            "OrderedDict([('weights', tensor([0.6343])), ('bias', tensor([0.3276]))]) \n",
            "\n",
            "Epoch: 26510 | Loss: 0.013190170750021935 | Test loss: 0.030837755650281906\n",
            "OrderedDict([('weights', tensor([0.6344])), ('bias', tensor([0.3276]))]) \n",
            "\n",
            "Epoch: 26520 | Loss: 0.013173026032745838 | Test loss: 0.030798237770795822\n",
            "OrderedDict([('weights', tensor([0.6345])), ('bias', tensor([0.3275]))]) \n",
            "\n",
            "Epoch: 26530 | Loss: 0.013155844993889332 | Test loss: 0.030757039785385132\n",
            "OrderedDict([('weights', tensor([0.6346])), ('bias', tensor([0.3275]))]) \n",
            "\n",
            "Epoch: 26540 | Loss: 0.013138702139258385 | Test loss: 0.030717510730028152\n",
            "OrderedDict([('weights', tensor([0.6346])), ('bias', tensor([0.3275]))]) \n",
            "\n",
            "Epoch: 26550 | Loss: 0.01312153972685337 | Test loss: 0.030679721385240555\n",
            "OrderedDict([('weights', tensor([0.6347])), ('bias', tensor([0.3274]))]) \n",
            "\n",
            "Epoch: 26560 | Loss: 0.013104373589158058 | Test loss: 0.030636757612228394\n",
            "OrderedDict([('weights', tensor([0.6348])), ('bias', tensor([0.3274]))]) \n",
            "\n",
            "Epoch: 26570 | Loss: 0.01308723259717226 | Test loss: 0.030598968267440796\n",
            "OrderedDict([('weights', tensor([0.6349])), ('bias', tensor([0.3273]))]) \n",
            "\n",
            "Epoch: 26580 | Loss: 0.01307005900889635 | Test loss: 0.030559461563825607\n",
            "OrderedDict([('weights', tensor([0.6350])), ('bias', tensor([0.3273]))]) \n",
            "\n",
            "Epoch: 26590 | Loss: 0.01305292546749115 | Test loss: 0.03051822818815708\n",
            "OrderedDict([('weights', tensor([0.6351])), ('bias', tensor([0.3273]))]) \n",
            "\n",
            "Epoch: 26600 | Loss: 0.013035754673182964 | Test loss: 0.030478734523057938\n",
            "OrderedDict([('weights', tensor([0.6352])), ('bias', tensor([0.3272]))]) \n",
            "\n",
            "Epoch: 26610 | Loss: 0.013018597848713398 | Test loss: 0.030437499284744263\n",
            "OrderedDict([('weights', tensor([0.6352])), ('bias', tensor([0.3272]))]) \n",
            "\n",
            "Epoch: 26620 | Loss: 0.01300144474953413 | Test loss: 0.030397992581129074\n",
            "OrderedDict([('weights', tensor([0.6353])), ('bias', tensor([0.3272]))]) \n",
            "\n",
            "Epoch: 26630 | Loss: 0.01298428513109684 | Test loss: 0.03035673499107361\n",
            "OrderedDict([('weights', tensor([0.6354])), ('bias', tensor([0.3271]))]) \n",
            "\n",
            "Epoch: 26640 | Loss: 0.012967130169272423 | Test loss: 0.03031725250184536\n",
            "OrderedDict([('weights', tensor([0.6355])), ('bias', tensor([0.3271]))]) \n",
            "\n",
            "Epoch: 26650 | Loss: 0.012949949130415916 | Test loss: 0.03027600608766079\n",
            "OrderedDict([('weights', tensor([0.6356])), ('bias', tensor([0.3271]))]) \n",
            "\n",
            "Epoch: 26660 | Loss: 0.012932802550494671 | Test loss: 0.030236512422561646\n",
            "OrderedDict([('weights', tensor([0.6357])), ('bias', tensor([0.3270]))]) \n",
            "\n",
            "Epoch: 26670 | Loss: 0.01291561871767044 | Test loss: 0.030197005718946457\n",
            "OrderedDict([('weights', tensor([0.6358])), ('bias', tensor([0.3270]))]) \n",
            "\n",
            "Epoch: 26680 | Loss: 0.012898480519652367 | Test loss: 0.030155759304761887\n",
            "OrderedDict([('weights', tensor([0.6358])), ('bias', tensor([0.3269]))]) \n",
            "\n",
            "Epoch: 26690 | Loss: 0.012881320901215076 | Test loss: 0.03011801838874817\n",
            "OrderedDict([('weights', tensor([0.6359])), ('bias', tensor([0.3269]))]) \n",
            "\n",
            "Epoch: 26700 | Loss: 0.01286415196955204 | Test loss: 0.030075019225478172\n",
            "OrderedDict([('weights', tensor([0.6360])), ('bias', tensor([0.3269]))]) \n",
            "\n",
            "Epoch: 26710 | Loss: 0.012847011908888817 | Test loss: 0.030037229880690575\n",
            "OrderedDict([('weights', tensor([0.6361])), ('bias', tensor([0.3268]))]) \n",
            "\n",
            "Epoch: 26720 | Loss: 0.012829837389290333 | Test loss: 0.02999773621559143\n",
            "OrderedDict([('weights', tensor([0.6362])), ('bias', tensor([0.3268]))]) \n",
            "\n",
            "Epoch: 26730 | Loss: 0.012812676839530468 | Test loss: 0.02995477244257927\n",
            "OrderedDict([('weights', tensor([0.6363])), ('bias', tensor([0.3268]))]) \n",
            "\n",
            "Epoch: 26740 | Loss: 0.012795540504157543 | Test loss: 0.029916996136307716\n",
            "OrderedDict([('weights', tensor([0.6363])), ('bias', tensor([0.3267]))]) \n",
            "\n",
            "Epoch: 26750 | Loss: 0.0127783864736557 | Test loss: 0.02987578511238098\n",
            "OrderedDict([('weights', tensor([0.6364])), ('bias', tensor([0.3267]))]) \n",
            "\n",
            "Epoch: 26760 | Loss: 0.012761238031089306 | Test loss: 0.029836256057024002\n",
            "OrderedDict([('weights', tensor([0.6365])), ('bias', tensor([0.3267]))]) \n",
            "\n",
            "Epoch: 26770 | Loss: 0.012744059786200523 | Test loss: 0.029794996604323387\n",
            "OrderedDict([('weights', tensor([0.6366])), ('bias', tensor([0.3266]))]) \n",
            "\n",
            "Epoch: 26780 | Loss: 0.012726912274956703 | Test loss: 0.02975551411509514\n",
            "OrderedDict([('weights', tensor([0.6367])), ('bias', tensor([0.3266]))]) \n",
            "\n",
            "Epoch: 26790 | Loss: 0.012709751725196838 | Test loss: 0.029715996235609055\n",
            "OrderedDict([('weights', tensor([0.6368])), ('bias', tensor([0.3266]))]) \n",
            "\n",
            "Epoch: 26800 | Loss: 0.01269258838146925 | Test loss: 0.029674774035811424\n",
            "OrderedDict([('weights', tensor([0.6369])), ('bias', tensor([0.3265]))]) \n",
            "\n",
            "Epoch: 26810 | Loss: 0.012675407342612743 | Test loss: 0.02963525615632534\n",
            "OrderedDict([('weights', tensor([0.6369])), ('bias', tensor([0.3265]))]) \n",
            "\n",
            "Epoch: 26820 | Loss: 0.012658258900046349 | Test loss: 0.02959403395652771\n",
            "OrderedDict([('weights', tensor([0.6370])), ('bias', tensor([0.3264]))]) \n",
            "\n",
            "Epoch: 26830 | Loss: 0.012641099281609058 | Test loss: 0.029556244611740112\n",
            "OrderedDict([('weights', tensor([0.6371])), ('bias', tensor([0.3264]))]) \n",
            "\n",
            "Epoch: 26840 | Loss: 0.012623933143913746 | Test loss: 0.029513293877243996\n",
            "OrderedDict([('weights', tensor([0.6372])), ('bias', tensor([0.3264]))]) \n",
            "\n",
            "Epoch: 26850 | Loss: 0.012606784701347351 | Test loss: 0.02947377599775791\n",
            "OrderedDict([('weights', tensor([0.6373])), ('bias', tensor([0.3263]))]) \n",
            "\n",
            "Epoch: 26860 | Loss: 0.012589624151587486 | Test loss: 0.02943599782884121\n",
            "OrderedDict([('weights', tensor([0.6374])), ('bias', tensor([0.3263]))]) \n",
            "\n",
            "Epoch: 26870 | Loss: 0.012572459876537323 | Test loss: 0.029393022879958153\n",
            "OrderedDict([('weights', tensor([0.6375])), ('bias', tensor([0.3263]))]) \n",
            "\n",
            "Epoch: 26880 | Loss: 0.012555311433970928 | Test loss: 0.029355257749557495\n",
            "OrderedDict([('weights', tensor([0.6375])), ('bias', tensor([0.3262]))]) \n",
            "\n",
            "Epoch: 26890 | Loss: 0.012538167648017406 | Test loss: 0.029314011335372925\n",
            "OrderedDict([('weights', tensor([0.6376])), ('bias', tensor([0.3262]))]) \n",
            "\n",
            "Epoch: 26900 | Loss: 0.012521011754870415 | Test loss: 0.029274504631757736\n",
            "OrderedDict([('weights', tensor([0.6377])), ('bias', tensor([0.3262]))]) \n",
            "\n",
            "Epoch: 26910 | Loss: 0.012503835372626781 | Test loss: 0.029234999790787697\n",
            "OrderedDict([('weights', tensor([0.6378])), ('bias', tensor([0.3261]))]) \n",
            "\n",
            "Epoch: 26920 | Loss: 0.012486702762544155 | Test loss: 0.029193764552474022\n",
            "OrderedDict([('weights', tensor([0.6379])), ('bias', tensor([0.3261]))]) \n",
            "\n",
            "Epoch: 26930 | Loss: 0.012469526380300522 | Test loss: 0.029154246672987938\n",
            "OrderedDict([('weights', tensor([0.6380])), ('bias', tensor([0.3261]))]) \n",
            "\n",
            "Epoch: 26940 | Loss: 0.012452365830540657 | Test loss: 0.029113024473190308\n",
            "OrderedDict([('weights', tensor([0.6381])), ('bias', tensor([0.3260]))]) \n",
            "\n",
            "Epoch: 26950 | Loss: 0.012435192242264748 | Test loss: 0.02907351776957512\n",
            "OrderedDict([('weights', tensor([0.6381])), ('bias', tensor([0.3260]))]) \n",
            "\n",
            "Epoch: 26960 | Loss: 0.012418041005730629 | Test loss: 0.029032284393906593\n",
            "OrderedDict([('weights', tensor([0.6382])), ('bias', tensor([0.3259]))]) \n",
            "\n",
            "Epoch: 26970 | Loss: 0.01240089163184166 | Test loss: 0.02899276651442051\n",
            "OrderedDict([('weights', tensor([0.6383])), ('bias', tensor([0.3259]))]) \n",
            "\n",
            "Epoch: 26980 | Loss: 0.012383717112243176 | Test loss: 0.02895154431462288\n",
            "OrderedDict([('weights', tensor([0.6384])), ('bias', tensor([0.3259]))]) \n",
            "\n",
            "Epoch: 26990 | Loss: 0.012366564013063908 | Test loss: 0.02891201339662075\n",
            "OrderedDict([('weights', tensor([0.6385])), ('bias', tensor([0.3258]))]) \n",
            "\n",
            "Epoch: 27000 | Loss: 0.012349402531981468 | Test loss: 0.028874272480607033\n",
            "OrderedDict([('weights', tensor([0.6386])), ('bias', tensor([0.3258]))]) \n",
            "\n",
            "Epoch: 27010 | Loss: 0.012332240119576454 | Test loss: 0.02883128449320793\n",
            "OrderedDict([('weights', tensor([0.6387])), ('bias', tensor([0.3258]))]) \n",
            "\n",
            "Epoch: 27020 | Loss: 0.012315092608332634 | Test loss: 0.028793519362807274\n",
            "OrderedDict([('weights', tensor([0.6387])), ('bias', tensor([0.3257]))]) \n",
            "\n",
            "Epoch: 27030 | Loss: 0.012297922745347023 | Test loss: 0.02875400148332119\n",
            "OrderedDict([('weights', tensor([0.6388])), ('bias', tensor([0.3257]))]) \n",
            "\n",
            "Epoch: 27040 | Loss: 0.012280781753361225 | Test loss: 0.028712790459394455\n",
            "OrderedDict([('weights', tensor([0.6389])), ('bias', tensor([0.3257]))]) \n",
            "\n",
            "Epoch: 27050 | Loss: 0.012263617478311062 | Test loss: 0.028673261404037476\n",
            "OrderedDict([('weights', tensor([0.6390])), ('bias', tensor([0.3256]))]) \n",
            "\n",
            "Epoch: 27060 | Loss: 0.012246472761034966 | Test loss: 0.028632063418626785\n",
            "OrderedDict([('weights', tensor([0.6391])), ('bias', tensor([0.3256]))]) \n",
            "\n",
            "Epoch: 27070 | Loss: 0.012229309417307377 | Test loss: 0.02859252132475376\n",
            "OrderedDict([('weights', tensor([0.6392])), ('bias', tensor([0.3255]))]) \n",
            "\n",
            "Epoch: 27080 | Loss: 0.012212144210934639 | Test loss: 0.028551286086440086\n",
            "OrderedDict([('weights', tensor([0.6393])), ('bias', tensor([0.3255]))]) \n",
            "\n",
            "Epoch: 27090 | Loss: 0.01219499297440052 | Test loss: 0.028511768206954002\n",
            "OrderedDict([('weights', tensor([0.6393])), ('bias', tensor([0.3255]))]) \n",
            "\n",
            "Epoch: 27100 | Loss: 0.012177815660834312 | Test loss: 0.028470557183027267\n",
            "OrderedDict([('weights', tensor([0.6394])), ('bias', tensor([0.3254]))]) \n",
            "\n",
            "Epoch: 27110 | Loss: 0.01216067187488079 | Test loss: 0.028431039303541183\n",
            "OrderedDict([('weights', tensor([0.6395])), ('bias', tensor([0.3254]))]) \n",
            "\n",
            "Epoch: 27120 | Loss: 0.01214348990470171 | Test loss: 0.028389841318130493\n",
            "OrderedDict([('weights', tensor([0.6396])), ('bias', tensor([0.3254]))]) \n",
            "\n",
            "Epoch: 27130 | Loss: 0.012126347981393337 | Test loss: 0.028350312262773514\n",
            "OrderedDict([('weights', tensor([0.6397])), ('bias', tensor([0.3253]))]) \n",
            "\n",
            "Epoch: 27140 | Loss: 0.012109184637665749 | Test loss: 0.028312522917985916\n",
            "OrderedDict([('weights', tensor([0.6398])), ('bias', tensor([0.3253]))]) \n",
            "\n",
            "Epoch: 27150 | Loss: 0.012092018499970436 | Test loss: 0.028269559144973755\n",
            "OrderedDict([('weights', tensor([0.6398])), ('bias', tensor([0.3253]))]) \n",
            "\n",
            "Epoch: 27160 | Loss: 0.012074877507984638 | Test loss: 0.028231769800186157\n",
            "OrderedDict([('weights', tensor([0.6399])), ('bias', tensor([0.3252]))]) \n",
            "\n",
            "Epoch: 27170 | Loss: 0.012057703919708729 | Test loss: 0.02819226309657097\n",
            "OrderedDict([('weights', tensor([0.6400])), ('bias', tensor([0.3252]))]) \n",
            "\n",
            "Epoch: 27180 | Loss: 0.012040570378303528 | Test loss: 0.028151029720902443\n",
            "OrderedDict([('weights', tensor([0.6401])), ('bias', tensor([0.3252]))]) \n",
            "\n",
            "Epoch: 27190 | Loss: 0.012023399583995342 | Test loss: 0.0281115360558033\n",
            "OrderedDict([('weights', tensor([0.6402])), ('bias', tensor([0.3251]))]) \n",
            "\n",
            "Epoch: 27200 | Loss: 0.012006242759525776 | Test loss: 0.028070300817489624\n",
            "OrderedDict([('weights', tensor([0.6403])), ('bias', tensor([0.3251]))]) \n",
            "\n",
            "Epoch: 27210 | Loss: 0.011989090591669083 | Test loss: 0.028030794113874435\n",
            "OrderedDict([('weights', tensor([0.6404])), ('bias', tensor([0.3250]))]) \n",
            "\n",
            "Epoch: 27220 | Loss: 0.011971930041909218 | Test loss: 0.02798953652381897\n",
            "OrderedDict([('weights', tensor([0.6404])), ('bias', tensor([0.3250]))]) \n",
            "\n",
            "Epoch: 27230 | Loss: 0.011954776011407375 | Test loss: 0.02795005403459072\n",
            "OrderedDict([('weights', tensor([0.6405])), ('bias', tensor([0.3250]))]) \n",
            "\n",
            "Epoch: 27240 | Loss: 0.011937594041228294 | Test loss: 0.02790880762040615\n",
            "OrderedDict([('weights', tensor([0.6406])), ('bias', tensor([0.3249]))]) \n",
            "\n",
            "Epoch: 27250 | Loss: 0.011920447461307049 | Test loss: 0.027869313955307007\n",
            "OrderedDict([('weights', tensor([0.6407])), ('bias', tensor([0.3249]))]) \n",
            "\n",
            "Epoch: 27260 | Loss: 0.011903263628482819 | Test loss: 0.027829807251691818\n",
            "OrderedDict([('weights', tensor([0.6408])), ('bias', tensor([0.3249]))]) \n",
            "\n",
            "Epoch: 27270 | Loss: 0.011886125430464745 | Test loss: 0.027788560837507248\n",
            "OrderedDict([('weights', tensor([0.6409])), ('bias', tensor([0.3248]))]) \n",
            "\n",
            "Epoch: 27280 | Loss: 0.01186896488070488 | Test loss: 0.02775081992149353\n",
            "OrderedDict([('weights', tensor([0.6410])), ('bias', tensor([0.3248]))]) \n",
            "\n",
            "Epoch: 27290 | Loss: 0.011851796880364418 | Test loss: 0.027707820758223534\n",
            "OrderedDict([('weights', tensor([0.6410])), ('bias', tensor([0.3248]))]) \n",
            "\n",
            "Epoch: 27300 | Loss: 0.01183465775102377 | Test loss: 0.027670031413435936\n",
            "OrderedDict([('weights', tensor([0.6411])), ('bias', tensor([0.3247]))]) \n",
            "\n",
            "Epoch: 27310 | Loss: 0.01181748416274786 | Test loss: 0.027630537748336792\n",
            "OrderedDict([('weights', tensor([0.6412])), ('bias', tensor([0.3247]))]) \n",
            "\n",
            "Epoch: 27320 | Loss: 0.01180032268166542 | Test loss: 0.02758757397532463\n",
            "OrderedDict([('weights', tensor([0.6413])), ('bias', tensor([0.3247]))]) \n",
            "\n",
            "Epoch: 27330 | Loss: 0.011783184483647346 | Test loss: 0.027549797669053078\n",
            "OrderedDict([('weights', tensor([0.6414])), ('bias', tensor([0.3246]))]) \n",
            "\n",
            "Epoch: 27340 | Loss: 0.011766031384468079 | Test loss: 0.027508586645126343\n",
            "OrderedDict([('weights', tensor([0.6415])), ('bias', tensor([0.3246]))]) \n",
            "\n",
            "Epoch: 27350 | Loss: 0.011748883873224258 | Test loss: 0.027469057589769363\n",
            "OrderedDict([('weights', tensor([0.6416])), ('bias', tensor([0.3245]))]) \n",
            "\n",
            "Epoch: 27360 | Loss: 0.011731704697012901 | Test loss: 0.02742779813706875\n",
            "OrderedDict([('weights', tensor([0.6416])), ('bias', tensor([0.3245]))]) \n",
            "\n",
            "Epoch: 27370 | Loss: 0.011714556254446507 | Test loss: 0.0273883156478405\n",
            "OrderedDict([('weights', tensor([0.6417])), ('bias', tensor([0.3245]))]) \n",
            "\n",
            "Epoch: 27380 | Loss: 0.011697396636009216 | Test loss: 0.027348797768354416\n",
            "OrderedDict([('weights', tensor([0.6418])), ('bias', tensor([0.3244]))]) \n",
            "\n",
            "Epoch: 27390 | Loss: 0.011680234223604202 | Test loss: 0.027307575568556786\n",
            "OrderedDict([('weights', tensor([0.6419])), ('bias', tensor([0.3244]))]) \n",
            "\n",
            "Epoch: 27400 | Loss: 0.011663052253425121 | Test loss: 0.0272680576890707\n",
            "OrderedDict([('weights', tensor([0.6420])), ('bias', tensor([0.3244]))]) \n",
            "\n",
            "Epoch: 27410 | Loss: 0.011645904742181301 | Test loss: 0.02722683548927307\n",
            "OrderedDict([('weights', tensor([0.6421])), ('bias', tensor([0.3243]))]) \n",
            "\n",
            "Epoch: 27420 | Loss: 0.011628743261098862 | Test loss: 0.027189046144485474\n",
            "OrderedDict([('weights', tensor([0.6422])), ('bias', tensor([0.3243]))]) \n",
            "\n",
            "Epoch: 27430 | Loss: 0.011611578986048698 | Test loss: 0.027146095409989357\n",
            "OrderedDict([('weights', tensor([0.6422])), ('bias', tensor([0.3243]))]) \n",
            "\n",
            "Epoch: 27440 | Loss: 0.011594430543482304 | Test loss: 0.027106577530503273\n",
            "OrderedDict([('weights', tensor([0.6423])), ('bias', tensor([0.3242]))]) \n",
            "\n",
            "Epoch: 27450 | Loss: 0.011577269062399864 | Test loss: 0.02706879936158657\n",
            "OrderedDict([('weights', tensor([0.6424])), ('bias', tensor([0.3242]))]) \n",
            "\n",
            "Epoch: 27460 | Loss: 0.011560104787349701 | Test loss: 0.027025824412703514\n",
            "OrderedDict([('weights', tensor([0.6425])), ('bias', tensor([0.3242]))]) \n",
            "\n",
            "Epoch: 27470 | Loss: 0.011542956344783306 | Test loss: 0.026988059282302856\n",
            "OrderedDict([('weights', tensor([0.6426])), ('bias', tensor([0.3241]))]) \n",
            "\n",
            "Epoch: 27480 | Loss: 0.011525814421474934 | Test loss: 0.026946812868118286\n",
            "OrderedDict([('weights', tensor([0.6427])), ('bias', tensor([0.3241]))]) \n",
            "\n",
            "Epoch: 27490 | Loss: 0.011508656665682793 | Test loss: 0.026907306164503098\n",
            "OrderedDict([('weights', tensor([0.6428])), ('bias', tensor([0.3240]))]) \n",
            "\n",
            "Epoch: 27500 | Loss: 0.011491481214761734 | Test loss: 0.026867801323533058\n",
            "OrderedDict([('weights', tensor([0.6428])), ('bias', tensor([0.3240]))]) \n",
            "\n",
            "Epoch: 27510 | Loss: 0.011474347673356533 | Test loss: 0.026826566085219383\n",
            "OrderedDict([('weights', tensor([0.6429])), ('bias', tensor([0.3240]))]) \n",
            "\n",
            "Epoch: 27520 | Loss: 0.0114571712911129 | Test loss: 0.0267870482057333\n",
            "OrderedDict([('weights', tensor([0.6430])), ('bias', tensor([0.3239]))]) \n",
            "\n",
            "Epoch: 27530 | Loss: 0.01144000981003046 | Test loss: 0.02674582600593567\n",
            "OrderedDict([('weights', tensor([0.6431])), ('bias', tensor([0.3239]))]) \n",
            "\n",
            "Epoch: 27540 | Loss: 0.011422839015722275 | Test loss: 0.02670631930232048\n",
            "OrderedDict([('weights', tensor([0.6432])), ('bias', tensor([0.3239]))]) \n",
            "\n",
            "Epoch: 27550 | Loss: 0.011405685916543007 | Test loss: 0.026665085926651955\n",
            "OrderedDict([('weights', tensor([0.6433])), ('bias', tensor([0.3238]))]) \n",
            "\n",
            "Epoch: 27560 | Loss: 0.011388536542654037 | Test loss: 0.02662556804716587\n",
            "OrderedDict([('weights', tensor([0.6433])), ('bias', tensor([0.3238]))]) \n",
            "\n",
            "Epoch: 27570 | Loss: 0.011371362023055553 | Test loss: 0.02658434584736824\n",
            "OrderedDict([('weights', tensor([0.6434])), ('bias', tensor([0.3238]))]) \n",
            "\n",
            "Epoch: 27580 | Loss: 0.011354208923876286 | Test loss: 0.026544814929366112\n",
            "OrderedDict([('weights', tensor([0.6435])), ('bias', tensor([0.3237]))]) \n",
            "\n",
            "Epoch: 27590 | Loss: 0.01133704837411642 | Test loss: 0.026507074013352394\n",
            "OrderedDict([('weights', tensor([0.6436])), ('bias', tensor([0.3237]))]) \n",
            "\n",
            "Epoch: 27600 | Loss: 0.011319885030388832 | Test loss: 0.026464086025953293\n",
            "OrderedDict([('weights', tensor([0.6437])), ('bias', tensor([0.3237]))]) \n",
            "\n",
            "Epoch: 27610 | Loss: 0.011302737519145012 | Test loss: 0.026426320895552635\n",
            "OrderedDict([('weights', tensor([0.6438])), ('bias', tensor([0.3236]))]) \n",
            "\n",
            "Epoch: 27620 | Loss: 0.011285567656159401 | Test loss: 0.02638680301606655\n",
            "OrderedDict([('weights', tensor([0.6439])), ('bias', tensor([0.3236]))]) \n",
            "\n",
            "Epoch: 27630 | Loss: 0.011268426664173603 | Test loss: 0.026345591992139816\n",
            "OrderedDict([('weights', tensor([0.6439])), ('bias', tensor([0.3235]))]) \n",
            "\n",
            "Epoch: 27640 | Loss: 0.011251261457800865 | Test loss: 0.026306062936782837\n",
            "OrderedDict([('weights', tensor([0.6440])), ('bias', tensor([0.3235]))]) \n",
            "\n",
            "Epoch: 27650 | Loss: 0.011234117671847343 | Test loss: 0.026264864951372147\n",
            "OrderedDict([('weights', tensor([0.6441])), ('bias', tensor([0.3235]))]) \n",
            "\n",
            "Epoch: 27660 | Loss: 0.011216954328119755 | Test loss: 0.026225322857499123\n",
            "OrderedDict([('weights', tensor([0.6442])), ('bias', tensor([0.3234]))]) \n",
            "\n",
            "Epoch: 27670 | Loss: 0.011199789121747017 | Test loss: 0.026184087619185448\n",
            "OrderedDict([('weights', tensor([0.6443])), ('bias', tensor([0.3234]))]) \n",
            "\n",
            "Epoch: 27680 | Loss: 0.011182637885212898 | Test loss: 0.026144569739699364\n",
            "OrderedDict([('weights', tensor([0.6444])), ('bias', tensor([0.3234]))]) \n",
            "\n",
            "Epoch: 27690 | Loss: 0.011165459640324116 | Test loss: 0.02610335871577263\n",
            "OrderedDict([('weights', tensor([0.6445])), ('bias', tensor([0.3233]))]) \n",
            "\n",
            "Epoch: 27700 | Loss: 0.011148317717015743 | Test loss: 0.026063840836286545\n",
            "OrderedDict([('weights', tensor([0.6445])), ('bias', tensor([0.3233]))]) \n",
            "\n",
            "Epoch: 27710 | Loss: 0.011131134815514088 | Test loss: 0.026022642850875854\n",
            "OrderedDict([('weights', tensor([0.6446])), ('bias', tensor([0.3233]))]) \n",
            "\n",
            "Epoch: 27720 | Loss: 0.011113992892205715 | Test loss: 0.025983113795518875\n",
            "OrderedDict([('weights', tensor([0.6447])), ('bias', tensor([0.3232]))]) \n",
            "\n",
            "Epoch: 27730 | Loss: 0.011096829548478127 | Test loss: 0.025945324450731277\n",
            "OrderedDict([('weights', tensor([0.6448])), ('bias', tensor([0.3232]))]) \n",
            "\n",
            "Epoch: 27740 | Loss: 0.011079663410782814 | Test loss: 0.02590234950184822\n",
            "OrderedDict([('weights', tensor([0.6449])), ('bias', tensor([0.3231]))]) \n",
            "\n",
            "Epoch: 27750 | Loss: 0.01106252335011959 | Test loss: 0.02586457133293152\n",
            "OrderedDict([('weights', tensor([0.6450])), ('bias', tensor([0.3231]))]) \n",
            "\n",
            "Epoch: 27760 | Loss: 0.011045348830521107 | Test loss: 0.02582506462931633\n",
            "OrderedDict([('weights', tensor([0.6451])), ('bias', tensor([0.3231]))]) \n",
            "\n",
            "Epoch: 27770 | Loss: 0.011028215289115906 | Test loss: 0.025783831253647804\n",
            "OrderedDict([('weights', tensor([0.6451])), ('bias', tensor([0.3230]))]) \n",
            "\n",
            "Epoch: 27780 | Loss: 0.01101104635745287 | Test loss: 0.02574433758854866\n",
            "OrderedDict([('weights', tensor([0.6452])), ('bias', tensor([0.3230]))]) \n",
            "\n",
            "Epoch: 27790 | Loss: 0.010993887670338154 | Test loss: 0.025703102350234985\n",
            "OrderedDict([('weights', tensor([0.6453])), ('bias', tensor([0.3230]))]) \n",
            "\n",
            "Epoch: 27800 | Loss: 0.010976733639836311 | Test loss: 0.025663595646619797\n",
            "OrderedDict([('weights', tensor([0.6454])), ('bias', tensor([0.3229]))]) \n",
            "\n",
            "Epoch: 27810 | Loss: 0.010959574952721596 | Test loss: 0.02562233805656433\n",
            "OrderedDict([('weights', tensor([0.6455])), ('bias', tensor([0.3229]))]) \n",
            "\n",
            "Epoch: 27820 | Loss: 0.010942420922219753 | Test loss: 0.025582844391465187\n",
            "OrderedDict([('weights', tensor([0.6456])), ('bias', tensor([0.3229]))]) \n",
            "\n",
            "Epoch: 27830 | Loss: 0.010925238952040672 | Test loss: 0.025541609153151512\n",
            "OrderedDict([('weights', tensor([0.6457])), ('bias', tensor([0.3228]))]) \n",
            "\n",
            "Epoch: 27840 | Loss: 0.010908092372119427 | Test loss: 0.025502115488052368\n",
            "OrderedDict([('weights', tensor([0.6457])), ('bias', tensor([0.3228]))]) \n",
            "\n",
            "Epoch: 27850 | Loss: 0.010890906676650047 | Test loss: 0.02546260878443718\n",
            "OrderedDict([('weights', tensor([0.6458])), ('bias', tensor([0.3228]))]) \n",
            "\n",
            "Epoch: 27860 | Loss: 0.010873772203922272 | Test loss: 0.02542136237025261\n",
            "OrderedDict([('weights', tensor([0.6459])), ('bias', tensor([0.3227]))]) \n",
            "\n",
            "Epoch: 27870 | Loss: 0.010856609791517258 | Test loss: 0.02538362145423889\n",
            "OrderedDict([('weights', tensor([0.6460])), ('bias', tensor([0.3227]))]) \n",
            "\n",
            "Epoch: 27880 | Loss: 0.010839441791176796 | Test loss: 0.025340622290968895\n",
            "OrderedDict([('weights', tensor([0.6461])), ('bias', tensor([0.3226]))]) \n",
            "\n",
            "Epoch: 27890 | Loss: 0.010822302661836147 | Test loss: 0.025302832946181297\n",
            "OrderedDict([('weights', tensor([0.6462])), ('bias', tensor([0.3226]))]) \n",
            "\n",
            "Epoch: 27900 | Loss: 0.010805129073560238 | Test loss: 0.025263328105211258\n",
            "OrderedDict([('weights', tensor([0.6463])), ('bias', tensor([0.3226]))]) \n",
            "\n",
            "Epoch: 27910 | Loss: 0.010787967592477798 | Test loss: 0.025220375508069992\n",
            "OrderedDict([('weights', tensor([0.6463])), ('bias', tensor([0.3225]))]) \n",
            "\n",
            "Epoch: 27920 | Loss: 0.010770829394459724 | Test loss: 0.02518259920179844\n",
            "OrderedDict([('weights', tensor([0.6464])), ('bias', tensor([0.3225]))]) \n",
            "\n",
            "Epoch: 27930 | Loss: 0.010753676295280457 | Test loss: 0.025141388177871704\n",
            "OrderedDict([('weights', tensor([0.6465])), ('bias', tensor([0.3225]))]) \n",
            "\n",
            "Epoch: 27940 | Loss: 0.010736528784036636 | Test loss: 0.025101859122514725\n",
            "OrderedDict([('weights', tensor([0.6466])), ('bias', tensor([0.3224]))]) \n",
            "\n",
            "Epoch: 27950 | Loss: 0.01071934960782528 | Test loss: 0.02506059966981411\n",
            "OrderedDict([('weights', tensor([0.6467])), ('bias', tensor([0.3224]))]) \n",
            "\n",
            "Epoch: 27960 | Loss: 0.010702201165258884 | Test loss: 0.02502111718058586\n",
            "OrderedDict([('weights', tensor([0.6468])), ('bias', tensor([0.3224]))]) \n",
            "\n",
            "Epoch: 27970 | Loss: 0.010685041546821594 | Test loss: 0.024981599301099777\n",
            "OrderedDict([('weights', tensor([0.6468])), ('bias', tensor([0.3223]))]) \n",
            "\n",
            "Epoch: 27980 | Loss: 0.01066787913441658 | Test loss: 0.024940377101302147\n",
            "OrderedDict([('weights', tensor([0.6469])), ('bias', tensor([0.3223]))]) \n",
            "\n",
            "Epoch: 27990 | Loss: 0.0106506971642375 | Test loss: 0.024900859221816063\n",
            "OrderedDict([('weights', tensor([0.6470])), ('bias', tensor([0.3223]))]) \n",
            "\n",
            "Epoch: 28000 | Loss: 0.010633549652993679 | Test loss: 0.024859637022018433\n",
            "OrderedDict([('weights', tensor([0.6471])), ('bias', tensor([0.3222]))]) \n",
            "\n",
            "Epoch: 28010 | Loss: 0.01061638817191124 | Test loss: 0.024821847677230835\n",
            "OrderedDict([('weights', tensor([0.6472])), ('bias', tensor([0.3222]))]) \n",
            "\n",
            "Epoch: 28020 | Loss: 0.010599223896861076 | Test loss: 0.02477889694273472\n",
            "OrderedDict([('weights', tensor([0.6473])), ('bias', tensor([0.3221]))]) \n",
            "\n",
            "Epoch: 28030 | Loss: 0.010582075454294682 | Test loss: 0.024739379063248634\n",
            "OrderedDict([('weights', tensor([0.6474])), ('bias', tensor([0.3221]))]) \n",
            "\n",
            "Epoch: 28040 | Loss: 0.010564913973212242 | Test loss: 0.024701600894331932\n",
            "OrderedDict([('weights', tensor([0.6474])), ('bias', tensor([0.3221]))]) \n",
            "\n",
            "Epoch: 28050 | Loss: 0.010547749698162079 | Test loss: 0.024658625945448875\n",
            "OrderedDict([('weights', tensor([0.6475])), ('bias', tensor([0.3220]))]) \n",
            "\n",
            "Epoch: 28060 | Loss: 0.010530601255595684 | Test loss: 0.024620860815048218\n",
            "OrderedDict([('weights', tensor([0.6476])), ('bias', tensor([0.3220]))]) \n",
            "\n",
            "Epoch: 28070 | Loss: 0.010513459332287312 | Test loss: 0.024579614400863647\n",
            "OrderedDict([('weights', tensor([0.6477])), ('bias', tensor([0.3220]))]) \n",
            "\n",
            "Epoch: 28080 | Loss: 0.01049630157649517 | Test loss: 0.02454010769724846\n",
            "OrderedDict([('weights', tensor([0.6478])), ('bias', tensor([0.3219]))]) \n",
            "\n",
            "Epoch: 28090 | Loss: 0.010479126125574112 | Test loss: 0.02450060285627842\n",
            "OrderedDict([('weights', tensor([0.6479])), ('bias', tensor([0.3219]))]) \n",
            "\n",
            "Epoch: 28100 | Loss: 0.010461992584168911 | Test loss: 0.024459367617964745\n",
            "OrderedDict([('weights', tensor([0.6480])), ('bias', tensor([0.3219]))]) \n",
            "\n",
            "Epoch: 28110 | Loss: 0.010444816201925278 | Test loss: 0.02441984973847866\n",
            "OrderedDict([('weights', tensor([0.6480])), ('bias', tensor([0.3218]))]) \n",
            "\n",
            "Epoch: 28120 | Loss: 0.010427654720842838 | Test loss: 0.02437862753868103\n",
            "OrderedDict([('weights', tensor([0.6481])), ('bias', tensor([0.3218]))]) \n",
            "\n",
            "Epoch: 28130 | Loss: 0.010410483926534653 | Test loss: 0.02433912083506584\n",
            "OrderedDict([('weights', tensor([0.6482])), ('bias', tensor([0.3217]))]) \n",
            "\n",
            "Epoch: 28140 | Loss: 0.010393330827355385 | Test loss: 0.024297887459397316\n",
            "OrderedDict([('weights', tensor([0.6483])), ('bias', tensor([0.3217]))]) \n",
            "\n",
            "Epoch: 28150 | Loss: 0.010376181453466415 | Test loss: 0.024258369579911232\n",
            "OrderedDict([('weights', tensor([0.6484])), ('bias', tensor([0.3217]))]) \n",
            "\n",
            "Epoch: 28160 | Loss: 0.010359006933867931 | Test loss: 0.0242171473801136\n",
            "OrderedDict([('weights', tensor([0.6485])), ('bias', tensor([0.3216]))]) \n",
            "\n",
            "Epoch: 28170 | Loss: 0.010341853834688663 | Test loss: 0.024177616462111473\n",
            "OrderedDict([('weights', tensor([0.6486])), ('bias', tensor([0.3216]))]) \n",
            "\n",
            "Epoch: 28180 | Loss: 0.010324693284928799 | Test loss: 0.024139875546097755\n",
            "OrderedDict([('weights', tensor([0.6486])), ('bias', tensor([0.3216]))]) \n",
            "\n",
            "Epoch: 28190 | Loss: 0.01030752994120121 | Test loss: 0.024096887558698654\n",
            "OrderedDict([('weights', tensor([0.6487])), ('bias', tensor([0.3215]))]) \n",
            "\n",
            "Epoch: 28200 | Loss: 0.01029038242995739 | Test loss: 0.024059122428297997\n",
            "OrderedDict([('weights', tensor([0.6488])), ('bias', tensor([0.3215]))]) \n",
            "\n",
            "Epoch: 28210 | Loss: 0.010273212566971779 | Test loss: 0.024019604548811913\n",
            "OrderedDict([('weights', tensor([0.6489])), ('bias', tensor([0.3215]))]) \n",
            "\n",
            "Epoch: 28220 | Loss: 0.010256071574985981 | Test loss: 0.023978393524885178\n",
            "OrderedDict([('weights', tensor([0.6490])), ('bias', tensor([0.3214]))]) \n",
            "\n",
            "Epoch: 28230 | Loss: 0.010238906368613243 | Test loss: 0.023938864469528198\n",
            "OrderedDict([('weights', tensor([0.6491])), ('bias', tensor([0.3214]))]) \n",
            "\n",
            "Epoch: 28240 | Loss: 0.010221762582659721 | Test loss: 0.023897666484117508\n",
            "OrderedDict([('weights', tensor([0.6492])), ('bias', tensor([0.3214]))]) \n",
            "\n",
            "Epoch: 28250 | Loss: 0.010204599238932133 | Test loss: 0.023858124390244484\n",
            "OrderedDict([('weights', tensor([0.6492])), ('bias', tensor([0.3213]))]) \n",
            "\n",
            "Epoch: 28260 | Loss: 0.010187434032559395 | Test loss: 0.02381688915193081\n",
            "OrderedDict([('weights', tensor([0.6493])), ('bias', tensor([0.3213]))]) \n",
            "\n",
            "Epoch: 28270 | Loss: 0.010170282796025276 | Test loss: 0.023777371272444725\n",
            "OrderedDict([('weights', tensor([0.6494])), ('bias', tensor([0.3212]))]) \n",
            "\n",
            "Epoch: 28280 | Loss: 0.010153104551136494 | Test loss: 0.02373616024851799\n",
            "OrderedDict([('weights', tensor([0.6495])), ('bias', tensor([0.3212]))]) \n",
            "\n",
            "Epoch: 28290 | Loss: 0.010135962627828121 | Test loss: 0.023696642369031906\n",
            "OrderedDict([('weights', tensor([0.6496])), ('bias', tensor([0.3212]))]) \n",
            "\n",
            "Epoch: 28300 | Loss: 0.010118779726326466 | Test loss: 0.023655444383621216\n",
            "OrderedDict([('weights', tensor([0.6497])), ('bias', tensor([0.3211]))]) \n",
            "\n",
            "Epoch: 28310 | Loss: 0.010101637803018093 | Test loss: 0.023615915328264236\n",
            "OrderedDict([('weights', tensor([0.6498])), ('bias', tensor([0.3211]))]) \n",
            "\n",
            "Epoch: 28320 | Loss: 0.010084474459290504 | Test loss: 0.02357812598347664\n",
            "OrderedDict([('weights', tensor([0.6498])), ('bias', tensor([0.3211]))]) \n",
            "\n",
            "Epoch: 28330 | Loss: 0.010067308321595192 | Test loss: 0.023535151034593582\n",
            "OrderedDict([('weights', tensor([0.6499])), ('bias', tensor([0.3210]))]) \n",
            "\n",
            "Epoch: 28340 | Loss: 0.010050168260931969 | Test loss: 0.02349737286567688\n",
            "OrderedDict([('weights', tensor([0.6500])), ('bias', tensor([0.3210]))]) \n",
            "\n",
            "Epoch: 28350 | Loss: 0.010032993741333485 | Test loss: 0.02345786616206169\n",
            "OrderedDict([('weights', tensor([0.6501])), ('bias', tensor([0.3210]))]) \n",
            "\n",
            "Epoch: 28360 | Loss: 0.010015860199928284 | Test loss: 0.023416632786393166\n",
            "OrderedDict([('weights', tensor([0.6502])), ('bias', tensor([0.3209]))]) \n",
            "\n",
            "Epoch: 28370 | Loss: 0.009998691268265247 | Test loss: 0.02337713912129402\n",
            "OrderedDict([('weights', tensor([0.6503])), ('bias', tensor([0.3209]))]) \n",
            "\n",
            "Epoch: 28380 | Loss: 0.009981532581150532 | Test loss: 0.023335903882980347\n",
            "OrderedDict([('weights', tensor([0.6503])), ('bias', tensor([0.3209]))]) \n",
            "\n",
            "Epoch: 28390 | Loss: 0.00996437855064869 | Test loss: 0.023296397179365158\n",
            "OrderedDict([('weights', tensor([0.6504])), ('bias', tensor([0.3208]))]) \n",
            "\n",
            "Epoch: 28400 | Loss: 0.009947219863533974 | Test loss: 0.023255139589309692\n",
            "OrderedDict([('weights', tensor([0.6505])), ('bias', tensor([0.3208]))]) \n",
            "\n",
            "Epoch: 28410 | Loss: 0.009930065833032131 | Test loss: 0.02321564592421055\n",
            "OrderedDict([('weights', tensor([0.6506])), ('bias', tensor([0.3207]))]) \n",
            "\n",
            "Epoch: 28420 | Loss: 0.00991288386285305 | Test loss: 0.023174410685896873\n",
            "OrderedDict([('weights', tensor([0.6507])), ('bias', tensor([0.3207]))]) \n",
            "\n",
            "Epoch: 28430 | Loss: 0.009895737282931805 | Test loss: 0.02313491702079773\n",
            "OrderedDict([('weights', tensor([0.6508])), ('bias', tensor([0.3207]))]) \n",
            "\n",
            "Epoch: 28440 | Loss: 0.009878551587462425 | Test loss: 0.02309541031718254\n",
            "OrderedDict([('weights', tensor([0.6509])), ('bias', tensor([0.3206]))]) \n",
            "\n",
            "Epoch: 28450 | Loss: 0.00986141711473465 | Test loss: 0.02305416390299797\n",
            "OrderedDict([('weights', tensor([0.6509])), ('bias', tensor([0.3206]))]) \n",
            "\n",
            "Epoch: 28460 | Loss: 0.009844254702329636 | Test loss: 0.023016422986984253\n",
            "OrderedDict([('weights', tensor([0.6510])), ('bias', tensor([0.3206]))]) \n",
            "\n",
            "Epoch: 28470 | Loss: 0.009827086701989174 | Test loss: 0.022973423823714256\n",
            "OrderedDict([('weights', tensor([0.6511])), ('bias', tensor([0.3205]))]) \n",
            "\n",
            "Epoch: 28480 | Loss: 0.009809947572648525 | Test loss: 0.02293563447892666\n",
            "OrderedDict([('weights', tensor([0.6512])), ('bias', tensor([0.3205]))]) \n",
            "\n",
            "Epoch: 28490 | Loss: 0.009792773984372616 | Test loss: 0.02289612963795662\n",
            "OrderedDict([('weights', tensor([0.6513])), ('bias', tensor([0.3205]))]) \n",
            "\n",
            "Epoch: 28500 | Loss: 0.009775612503290176 | Test loss: 0.022853177040815353\n",
            "OrderedDict([('weights', tensor([0.6514])), ('bias', tensor([0.3204]))]) \n",
            "\n",
            "Epoch: 28510 | Loss: 0.009758474305272102 | Test loss: 0.0228154007345438\n",
            "OrderedDict([('weights', tensor([0.6515])), ('bias', tensor([0.3204]))]) \n",
            "\n",
            "Epoch: 28520 | Loss: 0.009741321206092834 | Test loss: 0.022774189710617065\n",
            "OrderedDict([('weights', tensor([0.6515])), ('bias', tensor([0.3204]))]) \n",
            "\n",
            "Epoch: 28530 | Loss: 0.009724173694849014 | Test loss: 0.022734660655260086\n",
            "OrderedDict([('weights', tensor([0.6516])), ('bias', tensor([0.3203]))]) \n",
            "\n",
            "Epoch: 28540 | Loss: 0.009706994518637657 | Test loss: 0.02269340120255947\n",
            "OrderedDict([('weights', tensor([0.6517])), ('bias', tensor([0.3203]))]) \n",
            "\n",
            "Epoch: 28550 | Loss: 0.009689846076071262 | Test loss: 0.022653918713331223\n",
            "OrderedDict([('weights', tensor([0.6518])), ('bias', tensor([0.3202]))]) \n",
            "\n",
            "Epoch: 28560 | Loss: 0.009672686457633972 | Test loss: 0.02261440083384514\n",
            "OrderedDict([('weights', tensor([0.6519])), ('bias', tensor([0.3202]))]) \n",
            "\n",
            "Epoch: 28570 | Loss: 0.009655524045228958 | Test loss: 0.022573178634047508\n",
            "OrderedDict([('weights', tensor([0.6520])), ('bias', tensor([0.3202]))]) \n",
            "\n",
            "Epoch: 28580 | Loss: 0.009638342075049877 | Test loss: 0.022533660754561424\n",
            "OrderedDict([('weights', tensor([0.6521])), ('bias', tensor([0.3201]))]) \n",
            "\n",
            "Epoch: 28590 | Loss: 0.009621194563806057 | Test loss: 0.022492438554763794\n",
            "OrderedDict([('weights', tensor([0.6521])), ('bias', tensor([0.3201]))]) \n",
            "\n",
            "Epoch: 28600 | Loss: 0.009604033082723618 | Test loss: 0.022454649209976196\n",
            "OrderedDict([('weights', tensor([0.6522])), ('bias', tensor([0.3201]))]) \n",
            "\n",
            "Epoch: 28610 | Loss: 0.009586868807673454 | Test loss: 0.02241169847548008\n",
            "OrderedDict([('weights', tensor([0.6523])), ('bias', tensor([0.3200]))]) \n",
            "\n",
            "Epoch: 28620 | Loss: 0.00956972036510706 | Test loss: 0.022372180595993996\n",
            "OrderedDict([('weights', tensor([0.6524])), ('bias', tensor([0.3200]))]) \n",
            "\n",
            "Epoch: 28630 | Loss: 0.00955255888402462 | Test loss: 0.022334402427077293\n",
            "OrderedDict([('weights', tensor([0.6525])), ('bias', tensor([0.3200]))]) \n",
            "\n",
            "Epoch: 28640 | Loss: 0.009535394608974457 | Test loss: 0.022291427478194237\n",
            "OrderedDict([('weights', tensor([0.6526])), ('bias', tensor([0.3199]))]) \n",
            "\n",
            "Epoch: 28650 | Loss: 0.009518246166408062 | Test loss: 0.02225366234779358\n",
            "OrderedDict([('weights', tensor([0.6527])), ('bias', tensor([0.3199]))]) \n",
            "\n",
            "Epoch: 28660 | Loss: 0.00950110424309969 | Test loss: 0.02221241593360901\n",
            "OrderedDict([('weights', tensor([0.6527])), ('bias', tensor([0.3198]))]) \n",
            "\n",
            "Epoch: 28670 | Loss: 0.009483946487307549 | Test loss: 0.02217290922999382\n",
            "OrderedDict([('weights', tensor([0.6528])), ('bias', tensor([0.3198]))]) \n",
            "\n",
            "Epoch: 28680 | Loss: 0.00946677103638649 | Test loss: 0.02213340438902378\n",
            "OrderedDict([('weights', tensor([0.6529])), ('bias', tensor([0.3198]))]) \n",
            "\n",
            "Epoch: 28690 | Loss: 0.009449637494981289 | Test loss: 0.022092169150710106\n",
            "OrderedDict([('weights', tensor([0.6530])), ('bias', tensor([0.3197]))]) \n",
            "\n",
            "Epoch: 28700 | Loss: 0.009432461112737656 | Test loss: 0.022052651271224022\n",
            "OrderedDict([('weights', tensor([0.6531])), ('bias', tensor([0.3197]))]) \n",
            "\n",
            "Epoch: 28710 | Loss: 0.009415299631655216 | Test loss: 0.02201142907142639\n",
            "OrderedDict([('weights', tensor([0.6532])), ('bias', tensor([0.3197]))]) \n",
            "\n",
            "Epoch: 28720 | Loss: 0.00939812883734703 | Test loss: 0.021971922367811203\n",
            "OrderedDict([('weights', tensor([0.6533])), ('bias', tensor([0.3196]))]) \n",
            "\n",
            "Epoch: 28730 | Loss: 0.009380975738167763 | Test loss: 0.021930688992142677\n",
            "OrderedDict([('weights', tensor([0.6533])), ('bias', tensor([0.3196]))]) \n",
            "\n",
            "Epoch: 28740 | Loss: 0.009363826364278793 | Test loss: 0.021891171112656593\n",
            "OrderedDict([('weights', tensor([0.6534])), ('bias', tensor([0.3196]))]) \n",
            "\n",
            "Epoch: 28750 | Loss: 0.00934665184468031 | Test loss: 0.021849948912858963\n",
            "OrderedDict([('weights', tensor([0.6535])), ('bias', tensor([0.3195]))]) \n",
            "\n",
            "Epoch: 28760 | Loss: 0.009329498745501041 | Test loss: 0.021810417994856834\n",
            "OrderedDict([('weights', tensor([0.6536])), ('bias', tensor([0.3195]))]) \n",
            "\n",
            "Epoch: 28770 | Loss: 0.009312338195741177 | Test loss: 0.021772677078843117\n",
            "OrderedDict([('weights', tensor([0.6537])), ('bias', tensor([0.3195]))]) \n",
            "\n",
            "Epoch: 28780 | Loss: 0.009295174852013588 | Test loss: 0.021729689091444016\n",
            "OrderedDict([('weights', tensor([0.6538])), ('bias', tensor([0.3194]))]) \n",
            "\n",
            "Epoch: 28790 | Loss: 0.009278027340769768 | Test loss: 0.021691923961043358\n",
            "OrderedDict([('weights', tensor([0.6538])), ('bias', tensor([0.3194]))]) \n",
            "\n",
            "Epoch: 28800 | Loss: 0.009260857477784157 | Test loss: 0.021652406081557274\n",
            "OrderedDict([('weights', tensor([0.6539])), ('bias', tensor([0.3193]))]) \n",
            "\n",
            "Epoch: 28810 | Loss: 0.009243716485798359 | Test loss: 0.02161119505763054\n",
            "OrderedDict([('weights', tensor([0.6540])), ('bias', tensor([0.3193]))]) \n",
            "\n",
            "Epoch: 28820 | Loss: 0.009226551279425621 | Test loss: 0.02157166600227356\n",
            "OrderedDict([('weights', tensor([0.6541])), ('bias', tensor([0.3193]))]) \n",
            "\n",
            "Epoch: 28830 | Loss: 0.0092094074934721 | Test loss: 0.02153046801686287\n",
            "OrderedDict([('weights', tensor([0.6542])), ('bias', tensor([0.3192]))]) \n",
            "\n",
            "Epoch: 28840 | Loss: 0.00919224414974451 | Test loss: 0.021490925922989845\n",
            "OrderedDict([('weights', tensor([0.6543])), ('bias', tensor([0.3192]))]) \n",
            "\n",
            "Epoch: 28850 | Loss: 0.009175078943371773 | Test loss: 0.02144969068467617\n",
            "OrderedDict([('weights', tensor([0.6544])), ('bias', tensor([0.3192]))]) \n",
            "\n",
            "Epoch: 28860 | Loss: 0.009157927706837654 | Test loss: 0.021410172805190086\n",
            "OrderedDict([('weights', tensor([0.6544])), ('bias', tensor([0.3191]))]) \n",
            "\n",
            "Epoch: 28870 | Loss: 0.009140749461948872 | Test loss: 0.02136896178126335\n",
            "OrderedDict([('weights', tensor([0.6545])), ('bias', tensor([0.3191]))]) \n",
            "\n",
            "Epoch: 28880 | Loss: 0.009123607538640499 | Test loss: 0.021329443901777267\n",
            "OrderedDict([('weights', tensor([0.6546])), ('bias', tensor([0.3191]))]) \n",
            "\n",
            "Epoch: 28890 | Loss: 0.009106424637138844 | Test loss: 0.021288245916366577\n",
            "OrderedDict([('weights', tensor([0.6547])), ('bias', tensor([0.3190]))]) \n",
            "\n",
            "Epoch: 28900 | Loss: 0.009089282713830471 | Test loss: 0.021248716861009598\n",
            "OrderedDict([('weights', tensor([0.6548])), ('bias', tensor([0.3190]))]) \n",
            "\n",
            "Epoch: 28910 | Loss: 0.009072119370102882 | Test loss: 0.021210927516222\n",
            "OrderedDict([('weights', tensor([0.6549])), ('bias', tensor([0.3190]))]) \n",
            "\n",
            "Epoch: 28920 | Loss: 0.00905495323240757 | Test loss: 0.021167952567338943\n",
            "OrderedDict([('weights', tensor([0.6550])), ('bias', tensor([0.3189]))]) \n",
            "\n",
            "Epoch: 28930 | Loss: 0.009037813171744347 | Test loss: 0.02113017439842224\n",
            "OrderedDict([('weights', tensor([0.6550])), ('bias', tensor([0.3189]))]) \n",
            "\n",
            "Epoch: 28940 | Loss: 0.009020638652145863 | Test loss: 0.021090667694807053\n",
            "OrderedDict([('weights', tensor([0.6551])), ('bias', tensor([0.3188]))]) \n",
            "\n",
            "Epoch: 28950 | Loss: 0.009003505110740662 | Test loss: 0.021049434319138527\n",
            "OrderedDict([('weights', tensor([0.6552])), ('bias', tensor([0.3188]))]) \n",
            "\n",
            "Epoch: 28960 | Loss: 0.008986336179077625 | Test loss: 0.021009940654039383\n",
            "OrderedDict([('weights', tensor([0.6553])), ('bias', tensor([0.3188]))]) \n",
            "\n",
            "Epoch: 28970 | Loss: 0.00896917749196291 | Test loss: 0.020968705415725708\n",
            "OrderedDict([('weights', tensor([0.6554])), ('bias', tensor([0.3187]))]) \n",
            "\n",
            "Epoch: 28980 | Loss: 0.008952023461461067 | Test loss: 0.02092919871211052\n",
            "OrderedDict([('weights', tensor([0.6555])), ('bias', tensor([0.3187]))]) \n",
            "\n",
            "Epoch: 28990 | Loss: 0.008934864774346352 | Test loss: 0.020887941122055054\n",
            "OrderedDict([('weights', tensor([0.6556])), ('bias', tensor([0.3187]))]) \n",
            "\n",
            "Epoch: 29000 | Loss: 0.008917710743844509 | Test loss: 0.02084844745695591\n",
            "OrderedDict([('weights', tensor([0.6556])), ('bias', tensor([0.3186]))]) \n",
            "\n",
            "Epoch: 29010 | Loss: 0.008900528773665428 | Test loss: 0.020807212218642235\n",
            "OrderedDict([('weights', tensor([0.6557])), ('bias', tensor([0.3186]))]) \n",
            "\n",
            "Epoch: 29020 | Loss: 0.008883382193744183 | Test loss: 0.02076771855354309\n",
            "OrderedDict([('weights', tensor([0.6558])), ('bias', tensor([0.3186]))]) \n",
            "\n",
            "Epoch: 29030 | Loss: 0.008866196498274803 | Test loss: 0.020728211849927902\n",
            "OrderedDict([('weights', tensor([0.6559])), ('bias', tensor([0.3185]))]) \n",
            "\n",
            "Epoch: 29040 | Loss: 0.008849062025547028 | Test loss: 0.020686965435743332\n",
            "OrderedDict([('weights', tensor([0.6560])), ('bias', tensor([0.3185]))]) \n",
            "\n",
            "Epoch: 29050 | Loss: 0.008831899613142014 | Test loss: 0.020649224519729614\n",
            "OrderedDict([('weights', tensor([0.6561])), ('bias', tensor([0.3185]))]) \n",
            "\n",
            "Epoch: 29060 | Loss: 0.008814731612801552 | Test loss: 0.020606225356459618\n",
            "OrderedDict([('weights', tensor([0.6562])), ('bias', tensor([0.3184]))]) \n",
            "\n",
            "Epoch: 29070 | Loss: 0.008797592483460903 | Test loss: 0.02056843601167202\n",
            "OrderedDict([('weights', tensor([0.6562])), ('bias', tensor([0.3184]))]) \n",
            "\n",
            "Epoch: 29080 | Loss: 0.008780418895184994 | Test loss: 0.02052893117070198\n",
            "OrderedDict([('weights', tensor([0.6563])), ('bias', tensor([0.3183]))]) \n",
            "\n",
            "Epoch: 29090 | Loss: 0.008763257414102554 | Test loss: 0.020485978573560715\n",
            "OrderedDict([('weights', tensor([0.6564])), ('bias', tensor([0.3183]))]) \n",
            "\n",
            "Epoch: 29100 | Loss: 0.00874611921608448 | Test loss: 0.02044820226728916\n",
            "OrderedDict([('weights', tensor([0.6565])), ('bias', tensor([0.3183]))]) \n",
            "\n",
            "Epoch: 29110 | Loss: 0.008728966116905212 | Test loss: 0.020406991243362427\n",
            "OrderedDict([('weights', tensor([0.6566])), ('bias', tensor([0.3182]))]) \n",
            "\n",
            "Epoch: 29120 | Loss: 0.008711818605661392 | Test loss: 0.020367462188005447\n",
            "OrderedDict([('weights', tensor([0.6567])), ('bias', tensor([0.3182]))]) \n",
            "\n",
            "Epoch: 29130 | Loss: 0.008694639429450035 | Test loss: 0.020326202735304832\n",
            "OrderedDict([('weights', tensor([0.6568])), ('bias', tensor([0.3182]))]) \n",
            "\n",
            "Epoch: 29140 | Loss: 0.00867749098688364 | Test loss: 0.020286720246076584\n",
            "OrderedDict([('weights', tensor([0.6568])), ('bias', tensor([0.3181]))]) \n",
            "\n",
            "Epoch: 29150 | Loss: 0.00866033136844635 | Test loss: 0.0202472023665905\n",
            "OrderedDict([('weights', tensor([0.6569])), ('bias', tensor([0.3181]))]) \n",
            "\n",
            "Epoch: 29160 | Loss: 0.008643168956041336 | Test loss: 0.02020598016679287\n",
            "OrderedDict([('weights', tensor([0.6570])), ('bias', tensor([0.3181]))]) \n",
            "\n",
            "Epoch: 29170 | Loss: 0.008625986985862255 | Test loss: 0.020166462287306786\n",
            "OrderedDict([('weights', tensor([0.6571])), ('bias', tensor([0.3180]))]) \n",
            "\n",
            "Epoch: 29180 | Loss: 0.008608839474618435 | Test loss: 0.020125240087509155\n",
            "OrderedDict([('weights', tensor([0.6572])), ('bias', tensor([0.3180]))]) \n",
            "\n",
            "Epoch: 29190 | Loss: 0.008591677993535995 | Test loss: 0.020087450742721558\n",
            "OrderedDict([('weights', tensor([0.6573])), ('bias', tensor([0.3179]))]) \n",
            "\n",
            "Epoch: 29200 | Loss: 0.008574513718485832 | Test loss: 0.02004450000822544\n",
            "OrderedDict([('weights', tensor([0.6573])), ('bias', tensor([0.3179]))]) \n",
            "\n",
            "Epoch: 29210 | Loss: 0.008557365275919437 | Test loss: 0.020004982128739357\n",
            "OrderedDict([('weights', tensor([0.6574])), ('bias', tensor([0.3179]))]) \n",
            "\n",
            "Epoch: 29220 | Loss: 0.008540203794836998 | Test loss: 0.019967203959822655\n",
            "OrderedDict([('weights', tensor([0.6575])), ('bias', tensor([0.3178]))]) \n",
            "\n",
            "Epoch: 29230 | Loss: 0.008523039519786835 | Test loss: 0.019924229010939598\n",
            "OrderedDict([('weights', tensor([0.6576])), ('bias', tensor([0.3178]))]) \n",
            "\n",
            "Epoch: 29240 | Loss: 0.00850589107722044 | Test loss: 0.01988646388053894\n",
            "OrderedDict([('weights', tensor([0.6577])), ('bias', tensor([0.3178]))]) \n",
            "\n",
            "Epoch: 29250 | Loss: 0.008488749153912067 | Test loss: 0.01984521746635437\n",
            "OrderedDict([('weights', tensor([0.6578])), ('bias', tensor([0.3177]))]) \n",
            "\n",
            "Epoch: 29260 | Loss: 0.008471591398119926 | Test loss: 0.01980571076273918\n",
            "OrderedDict([('weights', tensor([0.6579])), ('bias', tensor([0.3177]))]) \n",
            "\n",
            "Epoch: 29270 | Loss: 0.008454417809844017 | Test loss: 0.019766205921769142\n",
            "OrderedDict([('weights', tensor([0.6579])), ('bias', tensor([0.3177]))]) \n",
            "\n",
            "Epoch: 29280 | Loss: 0.008437284268438816 | Test loss: 0.019724970683455467\n",
            "OrderedDict([('weights', tensor([0.6580])), ('bias', tensor([0.3176]))]) \n",
            "\n",
            "Epoch: 29290 | Loss: 0.008420107886195183 | Test loss: 0.019685452803969383\n",
            "OrderedDict([('weights', tensor([0.6581])), ('bias', tensor([0.3176]))]) \n",
            "\n",
            "Epoch: 29300 | Loss: 0.008402944542467594 | Test loss: 0.019644230604171753\n",
            "OrderedDict([('weights', tensor([0.6582])), ('bias', tensor([0.3176]))]) \n",
            "\n",
            "Epoch: 29310 | Loss: 0.008385775610804558 | Test loss: 0.019604723900556564\n",
            "OrderedDict([('weights', tensor([0.6583])), ('bias', tensor([0.3175]))]) \n",
            "\n",
            "Epoch: 29320 | Loss: 0.00836862064898014 | Test loss: 0.01956349052488804\n",
            "OrderedDict([('weights', tensor([0.6584])), ('bias', tensor([0.3175]))]) \n",
            "\n",
            "Epoch: 29330 | Loss: 0.00835147313773632 | Test loss: 0.019523972645401955\n",
            "OrderedDict([('weights', tensor([0.6585])), ('bias', tensor([0.3174]))]) \n",
            "\n",
            "Epoch: 29340 | Loss: 0.008334295824170113 | Test loss: 0.019482750445604324\n",
            "OrderedDict([('weights', tensor([0.6585])), ('bias', tensor([0.3174]))]) \n",
            "\n",
            "Epoch: 29350 | Loss: 0.00831714365631342 | Test loss: 0.019443219527602196\n",
            "OrderedDict([('weights', tensor([0.6586])), ('bias', tensor([0.3174]))]) \n",
            "\n",
            "Epoch: 29360 | Loss: 0.008299983106553555 | Test loss: 0.019405478611588478\n",
            "OrderedDict([('weights', tensor([0.6587])), ('bias', tensor([0.3173]))]) \n",
            "\n",
            "Epoch: 29370 | Loss: 0.008282821625471115 | Test loss: 0.019362490624189377\n",
            "OrderedDict([('weights', tensor([0.6588])), ('bias', tensor([0.3173]))]) \n",
            "\n",
            "Epoch: 29380 | Loss: 0.008265672251582146 | Test loss: 0.01932472549378872\n",
            "OrderedDict([('weights', tensor([0.6589])), ('bias', tensor([0.3173]))]) \n",
            "\n",
            "Epoch: 29390 | Loss: 0.008248504251241684 | Test loss: 0.019285207614302635\n",
            "OrderedDict([('weights', tensor([0.6590])), ('bias', tensor([0.3172]))]) \n",
            "\n",
            "Epoch: 29400 | Loss: 0.008231361396610737 | Test loss: 0.0192439965903759\n",
            "OrderedDict([('weights', tensor([0.6591])), ('bias', tensor([0.3172]))]) \n",
            "\n",
            "Epoch: 29410 | Loss: 0.008214196190237999 | Test loss: 0.01920446753501892\n",
            "OrderedDict([('weights', tensor([0.6591])), ('bias', tensor([0.3172]))]) \n",
            "\n",
            "Epoch: 29420 | Loss: 0.008197052404284477 | Test loss: 0.01916326954960823\n",
            "OrderedDict([('weights', tensor([0.6592])), ('bias', tensor([0.3171]))]) \n",
            "\n",
            "Epoch: 29430 | Loss: 0.008179889060556889 | Test loss: 0.019123727455735207\n",
            "OrderedDict([('weights', tensor([0.6593])), ('bias', tensor([0.3171]))]) \n",
            "\n",
            "Epoch: 29440 | Loss: 0.00816272385418415 | Test loss: 0.01908249221742153\n",
            "OrderedDict([('weights', tensor([0.6594])), ('bias', tensor([0.3171]))]) \n",
            "\n",
            "Epoch: 29450 | Loss: 0.008145574480295181 | Test loss: 0.019042974337935448\n",
            "OrderedDict([('weights', tensor([0.6595])), ('bias', tensor([0.3170]))]) \n",
            "\n",
            "Epoch: 29460 | Loss: 0.00812839437276125 | Test loss: 0.019001763314008713\n",
            "OrderedDict([('weights', tensor([0.6596])), ('bias', tensor([0.3170]))]) \n",
            "\n",
            "Epoch: 29470 | Loss: 0.008111252449452877 | Test loss: 0.01896224543452263\n",
            "OrderedDict([('weights', tensor([0.6597])), ('bias', tensor([0.3169]))]) \n",
            "\n",
            "Epoch: 29480 | Loss: 0.008094069547951221 | Test loss: 0.01892104744911194\n",
            "OrderedDict([('weights', tensor([0.6597])), ('bias', tensor([0.3169]))]) \n",
            "\n",
            "Epoch: 29490 | Loss: 0.008076927624642849 | Test loss: 0.01888151839375496\n",
            "OrderedDict([('weights', tensor([0.6598])), ('bias', tensor([0.3169]))]) \n",
            "\n",
            "Epoch: 29500 | Loss: 0.00805976428091526 | Test loss: 0.01884372904896736\n",
            "OrderedDict([('weights', tensor([0.6599])), ('bias', tensor([0.3168]))]) \n",
            "\n",
            "Epoch: 29510 | Loss: 0.008042598143219948 | Test loss: 0.018800754100084305\n",
            "OrderedDict([('weights', tensor([0.6600])), ('bias', tensor([0.3168]))]) \n",
            "\n",
            "Epoch: 29520 | Loss: 0.008025458082556725 | Test loss: 0.018762975931167603\n",
            "OrderedDict([('weights', tensor([0.6601])), ('bias', tensor([0.3168]))]) \n",
            "\n",
            "Epoch: 29530 | Loss: 0.00800828356295824 | Test loss: 0.018723469227552414\n",
            "OrderedDict([('weights', tensor([0.6602])), ('bias', tensor([0.3167]))]) \n",
            "\n",
            "Epoch: 29540 | Loss: 0.00799115002155304 | Test loss: 0.018682235851883888\n",
            "OrderedDict([('weights', tensor([0.6603])), ('bias', tensor([0.3167]))]) \n",
            "\n",
            "Epoch: 29550 | Loss: 0.007973981089890003 | Test loss: 0.018642742186784744\n",
            "OrderedDict([('weights', tensor([0.6603])), ('bias', tensor([0.3167]))]) \n",
            "\n",
            "Epoch: 29560 | Loss: 0.007956822402775288 | Test loss: 0.01860150694847107\n",
            "OrderedDict([('weights', tensor([0.6604])), ('bias', tensor([0.3166]))]) \n",
            "\n",
            "Epoch: 29570 | Loss: 0.007939668372273445 | Test loss: 0.01856200024485588\n",
            "OrderedDict([('weights', tensor([0.6605])), ('bias', tensor([0.3166]))]) \n",
            "\n",
            "Epoch: 29580 | Loss: 0.00792250968515873 | Test loss: 0.018520742654800415\n",
            "OrderedDict([('weights', tensor([0.6606])), ('bias', tensor([0.3166]))]) \n",
            "\n",
            "Epoch: 29590 | Loss: 0.007905355654656887 | Test loss: 0.01848124898970127\n",
            "OrderedDict([('weights', tensor([0.6607])), ('bias', tensor([0.3165]))]) \n",
            "\n",
            "Epoch: 29600 | Loss: 0.007888173684477806 | Test loss: 0.018440013751387596\n",
            "OrderedDict([('weights', tensor([0.6608])), ('bias', tensor([0.3165]))]) \n",
            "\n",
            "Epoch: 29610 | Loss: 0.00787102710455656 | Test loss: 0.018400520086288452\n",
            "OrderedDict([('weights', tensor([0.6608])), ('bias', tensor([0.3164]))]) \n",
            "\n",
            "Epoch: 29620 | Loss: 0.007853841409087181 | Test loss: 0.018361013382673264\n",
            "OrderedDict([('weights', tensor([0.6609])), ('bias', tensor([0.3164]))]) \n",
            "\n",
            "Epoch: 29630 | Loss: 0.007836706936359406 | Test loss: 0.018319766968488693\n",
            "OrderedDict([('weights', tensor([0.6610])), ('bias', tensor([0.3164]))]) \n",
            "\n",
            "Epoch: 29640 | Loss: 0.007819544523954391 | Test loss: 0.018282026052474976\n",
            "OrderedDict([('weights', tensor([0.6611])), ('bias', tensor([0.3163]))]) \n",
            "\n",
            "Epoch: 29650 | Loss: 0.007802376989275217 | Test loss: 0.01823902688920498\n",
            "OrderedDict([('weights', tensor([0.6612])), ('bias', tensor([0.3163]))]) \n",
            "\n",
            "Epoch: 29660 | Loss: 0.007785235997289419 | Test loss: 0.01820123754441738\n",
            "OrderedDict([('weights', tensor([0.6613])), ('bias', tensor([0.3163]))]) \n",
            "\n",
            "Epoch: 29670 | Loss: 0.007768063805997372 | Test loss: 0.018161732703447342\n",
            "OrderedDict([('weights', tensor([0.6614])), ('bias', tensor([0.3162]))]) \n",
            "\n",
            "Epoch: 29680 | Loss: 0.007750902324914932 | Test loss: 0.018118780106306076\n",
            "OrderedDict([('weights', tensor([0.6614])), ('bias', tensor([0.3162]))]) \n",
            "\n",
            "Epoch: 29690 | Loss: 0.0077337645925581455 | Test loss: 0.018081003800034523\n",
            "OrderedDict([('weights', tensor([0.6615])), ('bias', tensor([0.3162]))]) \n",
            "\n",
            "Epoch: 29700 | Loss: 0.00771661102771759 | Test loss: 0.018039792776107788\n",
            "OrderedDict([('weights', tensor([0.6616])), ('bias', tensor([0.3161]))]) \n",
            "\n",
            "Epoch: 29710 | Loss: 0.007699464913457632 | Test loss: 0.01800026372075081\n",
            "OrderedDict([('weights', tensor([0.6617])), ('bias', tensor([0.3161]))]) \n",
            "\n",
            "Epoch: 29720 | Loss: 0.007682283874601126 | Test loss: 0.017959004268050194\n",
            "OrderedDict([('weights', tensor([0.6618])), ('bias', tensor([0.3160]))]) \n",
            "\n",
            "Epoch: 29730 | Loss: 0.007665135897696018 | Test loss: 0.017919521778821945\n",
            "OrderedDict([('weights', tensor([0.6619])), ('bias', tensor([0.3160]))]) \n",
            "\n",
            "Epoch: 29740 | Loss: 0.007647974882274866 | Test loss: 0.01788000389933586\n",
            "OrderedDict([('weights', tensor([0.6620])), ('bias', tensor([0.3160]))]) \n",
            "\n",
            "Epoch: 29750 | Loss: 0.007630813866853714 | Test loss: 0.01783878169953823\n",
            "OrderedDict([('weights', tensor([0.6620])), ('bias', tensor([0.3159]))]) \n",
            "\n",
            "Epoch: 29760 | Loss: 0.007613630499690771 | Test loss: 0.017799263820052147\n",
            "OrderedDict([('weights', tensor([0.6621])), ('bias', tensor([0.3159]))]) \n",
            "\n",
            "Epoch: 29770 | Loss: 0.007596484385430813 | Test loss: 0.017758041620254517\n",
            "OrderedDict([('weights', tensor([0.6622])), ('bias', tensor([0.3159]))]) \n",
            "\n",
            "Epoch: 29780 | Loss: 0.0075793215073645115 | Test loss: 0.01772025227546692\n",
            "OrderedDict([('weights', tensor([0.6623])), ('bias', tensor([0.3158]))]) \n",
            "\n",
            "Epoch: 29790 | Loss: 0.007562158163636923 | Test loss: 0.017677301540970802\n",
            "OrderedDict([('weights', tensor([0.6624])), ('bias', tensor([0.3158]))]) \n",
            "\n",
            "Epoch: 29800 | Loss: 0.007545008324086666 | Test loss: 0.01763778366148472\n",
            "OrderedDict([('weights', tensor([0.6625])), ('bias', tensor([0.3158]))]) \n",
            "\n",
            "Epoch: 29810 | Loss: 0.007527848239988089 | Test loss: 0.017600005492568016\n",
            "OrderedDict([('weights', tensor([0.6626])), ('bias', tensor([0.3157]))]) \n",
            "\n",
            "Epoch: 29820 | Loss: 0.007510683033615351 | Test loss: 0.01755703054368496\n",
            "OrderedDict([('weights', tensor([0.6626])), ('bias', tensor([0.3157]))]) \n",
            "\n",
            "Epoch: 29830 | Loss: 0.007493535988032818 | Test loss: 0.017519265413284302\n",
            "OrderedDict([('weights', tensor([0.6627])), ('bias', tensor([0.3157]))]) \n",
            "\n",
            "Epoch: 29840 | Loss: 0.007476392202079296 | Test loss: 0.01747801899909973\n",
            "OrderedDict([('weights', tensor([0.6628])), ('bias', tensor([0.3156]))]) \n",
            "\n",
            "Epoch: 29850 | Loss: 0.007459236774593592 | Test loss: 0.017438512295484543\n",
            "OrderedDict([('weights', tensor([0.6629])), ('bias', tensor([0.3156]))]) \n",
            "\n",
            "Epoch: 29860 | Loss: 0.007442062254995108 | Test loss: 0.017399007454514503\n",
            "OrderedDict([('weights', tensor([0.6630])), ('bias', tensor([0.3155]))]) \n",
            "\n",
            "Epoch: 29870 | Loss: 0.007424929179251194 | Test loss: 0.01735777221620083\n",
            "OrderedDict([('weights', tensor([0.6631])), ('bias', tensor([0.3155]))]) \n",
            "\n",
            "Epoch: 29880 | Loss: 0.007407752331346273 | Test loss: 0.017318254336714745\n",
            "OrderedDict([('weights', tensor([0.6632])), ('bias', tensor([0.3155]))]) \n",
            "\n",
            "Epoch: 29890 | Loss: 0.007390589453279972 | Test loss: 0.017277032136917114\n",
            "OrderedDict([('weights', tensor([0.6632])), ('bias', tensor([0.3154]))]) \n",
            "\n",
            "Epoch: 29900 | Loss: 0.007373420055955648 | Test loss: 0.017237525433301926\n",
            "OrderedDict([('weights', tensor([0.6633])), ('bias', tensor([0.3154]))]) \n",
            "\n",
            "Epoch: 29910 | Loss: 0.007356265094131231 | Test loss: 0.0171962920576334\n",
            "OrderedDict([('weights', tensor([0.6634])), ('bias', tensor([0.3154]))]) \n",
            "\n",
            "Epoch: 29920 | Loss: 0.007339117582887411 | Test loss: 0.017156774178147316\n",
            "OrderedDict([('weights', tensor([0.6635])), ('bias', tensor([0.3153]))]) \n",
            "\n",
            "Epoch: 29930 | Loss: 0.007321940269321203 | Test loss: 0.017115551978349686\n",
            "OrderedDict([('weights', tensor([0.6636])), ('bias', tensor([0.3153]))]) \n",
            "\n",
            "Epoch: 29940 | Loss: 0.007304788567125797 | Test loss: 0.017076021060347557\n",
            "OrderedDict([('weights', tensor([0.6637])), ('bias', tensor([0.3153]))]) \n",
            "\n",
            "Epoch: 29950 | Loss: 0.0072876280173659325 | Test loss: 0.01703828014433384\n",
            "OrderedDict([('weights', tensor([0.6638])), ('bias', tensor([0.3152]))]) \n",
            "\n",
            "Epoch: 29960 | Loss: 0.007270466536283493 | Test loss: 0.016995292156934738\n",
            "OrderedDict([('weights', tensor([0.6638])), ('bias', tensor([0.3152]))]) \n",
            "\n",
            "Epoch: 29970 | Loss: 0.007253317628055811 | Test loss: 0.01695752702653408\n",
            "OrderedDict([('weights', tensor([0.6639])), ('bias', tensor([0.3152]))]) \n",
            "\n",
            "Epoch: 29980 | Loss: 0.007236149162054062 | Test loss: 0.016918009147047997\n",
            "OrderedDict([('weights', tensor([0.6640])), ('bias', tensor([0.3151]))]) \n",
            "\n",
            "Epoch: 29990 | Loss: 0.007219006307423115 | Test loss: 0.01687679812312126\n",
            "OrderedDict([('weights', tensor([0.6641])), ('bias', tensor([0.3151]))]) \n",
            "\n",
            "Epoch: 30000 | Loss: 0.00720184063538909 | Test loss: 0.016837269067764282\n",
            "OrderedDict([('weights', tensor([0.6642])), ('bias', tensor([0.3150]))]) \n",
            "\n",
            "Epoch: 30010 | Loss: 0.0071846977807581425 | Test loss: 0.016796071082353592\n",
            "OrderedDict([('weights', tensor([0.6643])), ('bias', tensor([0.3150]))]) \n",
            "\n",
            "Epoch: 30020 | Loss: 0.0071675339713692665 | Test loss: 0.016756528988480568\n",
            "OrderedDict([('weights', tensor([0.6643])), ('bias', tensor([0.3150]))]) \n",
            "\n",
            "Epoch: 30030 | Loss: 0.007150369230657816 | Test loss: 0.016715293750166893\n",
            "OrderedDict([('weights', tensor([0.6644])), ('bias', tensor([0.3149]))]) \n",
            "\n",
            "Epoch: 30040 | Loss: 0.007133219391107559 | Test loss: 0.01667577587068081\n",
            "OrderedDict([('weights', tensor([0.6645])), ('bias', tensor([0.3149]))]) \n",
            "\n",
            "Epoch: 30050 | Loss: 0.007116040680557489 | Test loss: 0.016634564846754074\n",
            "OrderedDict([('weights', tensor([0.6646])), ('bias', tensor([0.3149]))]) \n",
            "\n",
            "Epoch: 30060 | Loss: 0.007098897360265255 | Test loss: 0.01659504696726799\n",
            "OrderedDict([('weights', tensor([0.6647])), ('bias', tensor([0.3148]))]) \n",
            "\n",
            "Epoch: 30070 | Loss: 0.007081714458763599 | Test loss: 0.0165538489818573\n",
            "OrderedDict([('weights', tensor([0.6648])), ('bias', tensor([0.3148]))]) \n",
            "\n",
            "Epoch: 30080 | Loss: 0.007064572535455227 | Test loss: 0.01651431992650032\n",
            "OrderedDict([('weights', tensor([0.6649])), ('bias', tensor([0.3148]))]) \n",
            "\n",
            "Epoch: 30090 | Loss: 0.007047408726066351 | Test loss: 0.016476530581712723\n",
            "OrderedDict([('weights', tensor([0.6649])), ('bias', tensor([0.3147]))]) \n",
            "\n",
            "Epoch: 30100 | Loss: 0.007030243519693613 | Test loss: 0.016433555632829666\n",
            "OrderedDict([('weights', tensor([0.6650])), ('bias', tensor([0.3147]))]) \n",
            "\n",
            "Epoch: 30110 | Loss: 0.00701310345903039 | Test loss: 0.016395777463912964\n",
            "OrderedDict([('weights', tensor([0.6651])), ('bias', tensor([0.3146]))]) \n",
            "\n",
            "Epoch: 30120 | Loss: 0.0069959284737706184 | Test loss: 0.016356270760297775\n",
            "OrderedDict([('weights', tensor([0.6652])), ('bias', tensor([0.3146]))]) \n",
            "\n",
            "Epoch: 30130 | Loss: 0.0069787949323654175 | Test loss: 0.01631503738462925\n",
            "OrderedDict([('weights', tensor([0.6653])), ('bias', tensor([0.3146]))]) \n",
            "\n",
            "Epoch: 30140 | Loss: 0.006961626000702381 | Test loss: 0.016275543719530106\n",
            "OrderedDict([('weights', tensor([0.6654])), ('bias', tensor([0.3145]))]) \n",
            "\n",
            "Epoch: 30150 | Loss: 0.0069444673135876656 | Test loss: 0.01623430848121643\n",
            "OrderedDict([('weights', tensor([0.6655])), ('bias', tensor([0.3145]))]) \n",
            "\n",
            "Epoch: 30160 | Loss: 0.00692731374874711 | Test loss: 0.016194801777601242\n",
            "OrderedDict([('weights', tensor([0.6655])), ('bias', tensor([0.3145]))]) \n",
            "\n",
            "Epoch: 30170 | Loss: 0.00691015413030982 | Test loss: 0.016153544187545776\n",
            "OrderedDict([('weights', tensor([0.6656])), ('bias', tensor([0.3144]))]) \n",
            "\n",
            "Epoch: 30180 | Loss: 0.006893000565469265 | Test loss: 0.016114050522446632\n",
            "OrderedDict([('weights', tensor([0.6657])), ('bias', tensor([0.3144]))]) \n",
            "\n",
            "Epoch: 30190 | Loss: 0.006875819060951471 | Test loss: 0.016072815284132957\n",
            "OrderedDict([('weights', tensor([0.6658])), ('bias', tensor([0.3144]))]) \n",
            "\n",
            "Epoch: 30200 | Loss: 0.0068586720153689384 | Test loss: 0.016033321619033813\n",
            "OrderedDict([('weights', tensor([0.6659])), ('bias', tensor([0.3143]))]) \n",
            "\n",
            "Epoch: 30210 | Loss: 0.006841486785560846 | Test loss: 0.015993814915418625\n",
            "OrderedDict([('weights', tensor([0.6660])), ('bias', tensor([0.3143]))]) \n",
            "\n",
            "Epoch: 30220 | Loss: 0.0068243518471717834 | Test loss: 0.015952568501234055\n",
            "OrderedDict([('weights', tensor([0.6661])), ('bias', tensor([0.3143]))]) \n",
            "\n",
            "Epoch: 30230 | Loss: 0.006807189434766769 | Test loss: 0.015914827585220337\n",
            "OrderedDict([('weights', tensor([0.6661])), ('bias', tensor([0.3142]))]) \n",
            "\n",
            "Epoch: 30240 | Loss: 0.006790021900087595 | Test loss: 0.01587182842195034\n",
            "OrderedDict([('weights', tensor([0.6662])), ('bias', tensor([0.3142]))]) \n",
            "\n",
            "Epoch: 30250 | Loss: 0.006772880908101797 | Test loss: 0.015834039077162743\n",
            "OrderedDict([('weights', tensor([0.6663])), ('bias', tensor([0.3141]))]) \n",
            "\n",
            "Epoch: 30260 | Loss: 0.00675570871680975 | Test loss: 0.015794534236192703\n",
            "OrderedDict([('weights', tensor([0.6664])), ('bias', tensor([0.3141]))]) \n",
            "\n",
            "Epoch: 30270 | Loss: 0.00673854723572731 | Test loss: 0.015751581639051437\n",
            "OrderedDict([('weights', tensor([0.6665])), ('bias', tensor([0.3141]))]) \n",
            "\n",
            "Epoch: 30280 | Loss: 0.0067214095033705235 | Test loss: 0.015713805332779884\n",
            "OrderedDict([('weights', tensor([0.6666])), ('bias', tensor([0.3140]))]) \n",
            "\n",
            "Epoch: 30290 | Loss: 0.006704255938529968 | Test loss: 0.01567259430885315\n",
            "OrderedDict([('weights', tensor([0.6667])), ('bias', tensor([0.3140]))]) \n",
            "\n",
            "Epoch: 30300 | Loss: 0.00668710982427001 | Test loss: 0.01563306525349617\n",
            "OrderedDict([('weights', tensor([0.6667])), ('bias', tensor([0.3140]))]) \n",
            "\n",
            "Epoch: 30310 | Loss: 0.006669928785413504 | Test loss: 0.015591805800795555\n",
            "OrderedDict([('weights', tensor([0.6668])), ('bias', tensor([0.3139]))]) \n",
            "\n",
            "Epoch: 30320 | Loss: 0.006652780808508396 | Test loss: 0.015552324242889881\n",
            "OrderedDict([('weights', tensor([0.6669])), ('bias', tensor([0.3139]))]) \n",
            "\n",
            "Epoch: 30330 | Loss: 0.006635619793087244 | Test loss: 0.015512806363403797\n",
            "OrderedDict([('weights', tensor([0.6670])), ('bias', tensor([0.3139]))]) \n",
            "\n",
            "Epoch: 30340 | Loss: 0.006618458777666092 | Test loss: 0.015471583232283592\n",
            "OrderedDict([('weights', tensor([0.6671])), ('bias', tensor([0.3138]))]) \n",
            "\n",
            "Epoch: 30350 | Loss: 0.006601275410503149 | Test loss: 0.015432065352797508\n",
            "OrderedDict([('weights', tensor([0.6672])), ('bias', tensor([0.3138]))]) \n",
            "\n",
            "Epoch: 30360 | Loss: 0.006584129296243191 | Test loss: 0.015390843152999878\n",
            "OrderedDict([('weights', tensor([0.6673])), ('bias', tensor([0.3138]))]) \n",
            "\n",
            "Epoch: 30370 | Loss: 0.006566966418176889 | Test loss: 0.01535305380821228\n",
            "OrderedDict([('weights', tensor([0.6673])), ('bias', tensor([0.3137]))]) \n",
            "\n",
            "Epoch: 30380 | Loss: 0.006549803074449301 | Test loss: 0.015310103073716164\n",
            "OrderedDict([('weights', tensor([0.6674])), ('bias', tensor([0.3137]))]) \n",
            "\n",
            "Epoch: 30390 | Loss: 0.006532653234899044 | Test loss: 0.01527058519423008\n",
            "OrderedDict([('weights', tensor([0.6675])), ('bias', tensor([0.3136]))]) \n",
            "\n",
            "Epoch: 30400 | Loss: 0.0065154931508004665 | Test loss: 0.015232807025313377\n",
            "OrderedDict([('weights', tensor([0.6676])), ('bias', tensor([0.3136]))]) \n",
            "\n",
            "Epoch: 30410 | Loss: 0.006498327944427729 | Test loss: 0.01518983207643032\n",
            "OrderedDict([('weights', tensor([0.6677])), ('bias', tensor([0.3136]))]) \n",
            "\n",
            "Epoch: 30420 | Loss: 0.006481180898845196 | Test loss: 0.015152066946029663\n",
            "OrderedDict([('weights', tensor([0.6678])), ('bias', tensor([0.3135]))]) \n",
            "\n",
            "Epoch: 30430 | Loss: 0.006464037112891674 | Test loss: 0.015110820531845093\n",
            "OrderedDict([('weights', tensor([0.6678])), ('bias', tensor([0.3135]))]) \n",
            "\n",
            "Epoch: 30440 | Loss: 0.00644688168540597 | Test loss: 0.015071314759552479\n",
            "OrderedDict([('weights', tensor([0.6679])), ('bias', tensor([0.3135]))]) \n",
            "\n",
            "Epoch: 30450 | Loss: 0.006429707165807486 | Test loss: 0.015031808987259865\n",
            "OrderedDict([('weights', tensor([0.6680])), ('bias', tensor([0.3134]))]) \n",
            "\n",
            "Epoch: 30460 | Loss: 0.006412574090063572 | Test loss: 0.01499057374894619\n",
            "OrderedDict([('weights', tensor([0.6681])), ('bias', tensor([0.3134]))]) \n",
            "\n",
            "Epoch: 30470 | Loss: 0.006395397242158651 | Test loss: 0.014951055869460106\n",
            "OrderedDict([('weights', tensor([0.6682])), ('bias', tensor([0.3134]))]) \n",
            "\n",
            "Epoch: 30480 | Loss: 0.00637823436409235 | Test loss: 0.014909833669662476\n",
            "OrderedDict([('weights', tensor([0.6683])), ('bias', tensor([0.3133]))]) \n",
            "\n",
            "Epoch: 30490 | Loss: 0.006361064966768026 | Test loss: 0.014870327897369862\n",
            "OrderedDict([('weights', tensor([0.6684])), ('bias', tensor([0.3133]))]) \n",
            "\n",
            "Epoch: 30500 | Loss: 0.006343910004943609 | Test loss: 0.014829093590378761\n",
            "OrderedDict([('weights', tensor([0.6684])), ('bias', tensor([0.3133]))]) \n",
            "\n",
            "Epoch: 30510 | Loss: 0.006326762493699789 | Test loss: 0.014789575710892677\n",
            "OrderedDict([('weights', tensor([0.6685])), ('bias', tensor([0.3132]))]) \n",
            "\n",
            "Epoch: 30520 | Loss: 0.006309585180133581 | Test loss: 0.014748352579772472\n",
            "OrderedDict([('weights', tensor([0.6686])), ('bias', tensor([0.3132]))]) \n",
            "\n",
            "Epoch: 30530 | Loss: 0.006292433477938175 | Test loss: 0.014708822593092918\n",
            "OrderedDict([('weights', tensor([0.6687])), ('bias', tensor([0.3131]))]) \n",
            "\n",
            "Epoch: 30540 | Loss: 0.00627527292817831 | Test loss: 0.0146710816770792\n",
            "OrderedDict([('weights', tensor([0.6688])), ('bias', tensor([0.3131]))]) \n",
            "\n",
            "Epoch: 30550 | Loss: 0.006258111447095871 | Test loss: 0.014628094621002674\n",
            "OrderedDict([('weights', tensor([0.6689])), ('bias', tensor([0.3131]))]) \n",
            "\n",
            "Epoch: 30560 | Loss: 0.006240962538868189 | Test loss: 0.014590328559279442\n",
            "OrderedDict([('weights', tensor([0.6690])), ('bias', tensor([0.3130]))]) \n",
            "\n",
            "Epoch: 30570 | Loss: 0.00622379407286644 | Test loss: 0.014550810679793358\n",
            "OrderedDict([('weights', tensor([0.6690])), ('bias', tensor([0.3130]))]) \n",
            "\n",
            "Epoch: 30580 | Loss: 0.006206651218235493 | Test loss: 0.014509600587189198\n",
            "OrderedDict([('weights', tensor([0.6691])), ('bias', tensor([0.3130]))]) \n",
            "\n",
            "Epoch: 30590 | Loss: 0.0061894855462014675 | Test loss: 0.014470070600509644\n",
            "OrderedDict([('weights', tensor([0.6692])), ('bias', tensor([0.3129]))]) \n",
            "\n",
            "Epoch: 30600 | Loss: 0.00617234269157052 | Test loss: 0.014428859576582909\n",
            "OrderedDict([('weights', tensor([0.6693])), ('bias', tensor([0.3129]))]) \n",
            "\n",
            "Epoch: 30610 | Loss: 0.0061551788821816444 | Test loss: 0.01438933052122593\n",
            "OrderedDict([('weights', tensor([0.6694])), ('bias', tensor([0.3129]))]) \n",
            "\n",
            "Epoch: 30620 | Loss: 0.006138014141470194 | Test loss: 0.014348095282912254\n",
            "OrderedDict([('weights', tensor([0.6695])), ('bias', tensor([0.3128]))]) \n",
            "\n",
            "Epoch: 30630 | Loss: 0.006120864301919937 | Test loss: 0.01430857740342617\n",
            "OrderedDict([('weights', tensor([0.6696])), ('bias', tensor([0.3128]))]) \n",
            "\n",
            "Epoch: 30640 | Loss: 0.006103685591369867 | Test loss: 0.01426736731082201\n",
            "OrderedDict([('weights', tensor([0.6696])), ('bias', tensor([0.3128]))]) \n",
            "\n",
            "Epoch: 30650 | Loss: 0.006086542271077633 | Test loss: 0.014227849431335926\n",
            "OrderedDict([('weights', tensor([0.6697])), ('bias', tensor([0.3127]))]) \n",
            "\n",
            "Epoch: 30660 | Loss: 0.006069359369575977 | Test loss: 0.014186650514602661\n",
            "OrderedDict([('weights', tensor([0.6698])), ('bias', tensor([0.3127]))]) \n",
            "\n",
            "Epoch: 30670 | Loss: 0.006052217446267605 | Test loss: 0.014147120527923107\n",
            "OrderedDict([('weights', tensor([0.6699])), ('bias', tensor([0.3126]))]) \n",
            "\n",
            "Epoch: 30680 | Loss: 0.006035053636878729 | Test loss: 0.01410933118313551\n",
            "OrderedDict([('weights', tensor([0.6700])), ('bias', tensor([0.3126]))]) \n",
            "\n",
            "Epoch: 30690 | Loss: 0.006017888430505991 | Test loss: 0.014066356234252453\n",
            "OrderedDict([('weights', tensor([0.6701])), ('bias', tensor([0.3126]))]) \n",
            "\n",
            "Epoch: 30700 | Loss: 0.006000748369842768 | Test loss: 0.014028578996658325\n",
            "OrderedDict([('weights', tensor([0.6702])), ('bias', tensor([0.3125]))]) \n",
            "\n",
            "Epoch: 30710 | Loss: 0.005983573384582996 | Test loss: 0.013989073224365711\n",
            "OrderedDict([('weights', tensor([0.6702])), ('bias', tensor([0.3125]))]) \n",
            "\n",
            "Epoch: 30720 | Loss: 0.005966439843177795 | Test loss: 0.013947838917374611\n",
            "OrderedDict([('weights', tensor([0.6703])), ('bias', tensor([0.3125]))]) \n",
            "\n",
            "Epoch: 30730 | Loss: 0.005949270911514759 | Test loss: 0.013908344320952892\n",
            "OrderedDict([('weights', tensor([0.6704])), ('bias', tensor([0.3124]))]) \n",
            "\n",
            "Epoch: 30740 | Loss: 0.0059321122244000435 | Test loss: 0.013867110013961792\n",
            "OrderedDict([('weights', tensor([0.6705])), ('bias', tensor([0.3124]))]) \n",
            "\n",
            "Epoch: 30750 | Loss: 0.005914958659559488 | Test loss: 0.013827592134475708\n",
            "OrderedDict([('weights', tensor([0.6706])), ('bias', tensor([0.3124]))]) \n",
            "\n",
            "Epoch: 30760 | Loss: 0.005897799041122198 | Test loss: 0.013786345720291138\n",
            "OrderedDict([('weights', tensor([0.6707])), ('bias', tensor([0.3123]))]) \n",
            "\n",
            "Epoch: 30770 | Loss: 0.005880645476281643 | Test loss: 0.013746852055191994\n",
            "OrderedDict([('weights', tensor([0.6708])), ('bias', tensor([0.3123]))]) \n",
            "\n",
            "Epoch: 30780 | Loss: 0.005863463971763849 | Test loss: 0.013705616816878319\n",
            "OrderedDict([('weights', tensor([0.6708])), ('bias', tensor([0.3122]))]) \n",
            "\n",
            "Epoch: 30790 | Loss: 0.005846316926181316 | Test loss: 0.013666123151779175\n",
            "OrderedDict([('weights', tensor([0.6709])), ('bias', tensor([0.3122]))]) \n",
            "\n",
            "Epoch: 30800 | Loss: 0.005829131696373224 | Test loss: 0.01362661737948656\n",
            "OrderedDict([('weights', tensor([0.6710])), ('bias', tensor([0.3122]))]) \n",
            "\n",
            "Epoch: 30810 | Loss: 0.005811996757984161 | Test loss: 0.01358537096530199\n",
            "OrderedDict([('weights', tensor([0.6711])), ('bias', tensor([0.3121]))]) \n",
            "\n",
            "Epoch: 30820 | Loss: 0.005794834345579147 | Test loss: 0.013547629117965698\n",
            "OrderedDict([('weights', tensor([0.6712])), ('bias', tensor([0.3121]))]) \n",
            "\n",
            "Epoch: 30830 | Loss: 0.005777666810899973 | Test loss: 0.013504629954695702\n",
            "OrderedDict([('weights', tensor([0.6713])), ('bias', tensor([0.3121]))]) \n",
            "\n",
            "Epoch: 30840 | Loss: 0.005760525818914175 | Test loss: 0.013466840609908104\n",
            "OrderedDict([('weights', tensor([0.6713])), ('bias', tensor([0.3120]))]) \n",
            "\n",
            "Epoch: 30850 | Loss: 0.0057433536276221275 | Test loss: 0.01342733483761549\n",
            "OrderedDict([('weights', tensor([0.6714])), ('bias', tensor([0.3120]))]) \n",
            "\n",
            "Epoch: 30860 | Loss: 0.005726192146539688 | Test loss: 0.013384384103119373\n",
            "OrderedDict([('weights', tensor([0.6715])), ('bias', tensor([0.3120]))]) \n",
            "\n",
            "Epoch: 30870 | Loss: 0.005709054414182901 | Test loss: 0.013346606865525246\n",
            "OrderedDict([('weights', tensor([0.6716])), ('bias', tensor([0.3119]))]) \n",
            "\n",
            "Epoch: 30880 | Loss: 0.005691899918019772 | Test loss: 0.01330539584159851\n",
            "OrderedDict([('weights', tensor([0.6717])), ('bias', tensor([0.3119]))]) \n",
            "\n",
            "Epoch: 30890 | Loss: 0.005674754735082388 | Test loss: 0.013265865854918957\n",
            "OrderedDict([('weights', tensor([0.6718])), ('bias', tensor([0.3119]))]) \n",
            "\n",
            "Epoch: 30900 | Loss: 0.005657573696225882 | Test loss: 0.013224607333540916\n",
            "OrderedDict([('weights', tensor([0.6719])), ('bias', tensor([0.3118]))]) \n",
            "\n",
            "Epoch: 30910 | Loss: 0.005640426184982061 | Test loss: 0.013185125775635242\n",
            "OrderedDict([('weights', tensor([0.6719])), ('bias', tensor([0.3118]))]) \n",
            "\n",
            "Epoch: 30920 | Loss: 0.005623265169560909 | Test loss: 0.013145607896149158\n",
            "OrderedDict([('weights', tensor([0.6720])), ('bias', tensor([0.3117]))]) \n",
            "\n",
            "Epoch: 30930 | Loss: 0.00560610368847847 | Test loss: 0.013104384765028954\n",
            "OrderedDict([('weights', tensor([0.6721])), ('bias', tensor([0.3117]))]) \n",
            "\n",
            "Epoch: 30940 | Loss: 0.005588920321315527 | Test loss: 0.01306486688554287\n",
            "OrderedDict([('weights', tensor([0.6722])), ('bias', tensor([0.3117]))]) \n",
            "\n",
            "Epoch: 30950 | Loss: 0.005571774207055569 | Test loss: 0.01302364468574524\n",
            "OrderedDict([('weights', tensor([0.6723])), ('bias', tensor([0.3116]))]) \n",
            "\n",
            "Epoch: 30960 | Loss: 0.005554611794650555 | Test loss: 0.012985855340957642\n",
            "OrderedDict([('weights', tensor([0.6724])), ('bias', tensor([0.3116]))]) \n",
            "\n",
            "Epoch: 30970 | Loss: 0.005537447985261679 | Test loss: 0.012942904606461525\n",
            "OrderedDict([('weights', tensor([0.6725])), ('bias', tensor([0.3116]))]) \n",
            "\n",
            "Epoch: 30980 | Loss: 0.005520298145711422 | Test loss: 0.012903386726975441\n",
            "OrderedDict([('weights', tensor([0.6725])), ('bias', tensor([0.3115]))]) \n",
            "\n",
            "Epoch: 30990 | Loss: 0.005503137595951557 | Test loss: 0.012865608558058739\n",
            "OrderedDict([('weights', tensor([0.6726])), ('bias', tensor([0.3115]))]) \n",
            "\n",
            "Epoch: 31000 | Loss: 0.005485973320901394 | Test loss: 0.012822633609175682\n",
            "OrderedDict([('weights', tensor([0.6727])), ('bias', tensor([0.3115]))]) \n",
            "\n",
            "Epoch: 31010 | Loss: 0.005468825809657574 | Test loss: 0.012784868478775024\n",
            "OrderedDict([('weights', tensor([0.6728])), ('bias', tensor([0.3114]))]) \n",
            "\n",
            "Epoch: 31020 | Loss: 0.005451682023704052 | Test loss: 0.012743622064590454\n",
            "OrderedDict([('weights', tensor([0.6729])), ('bias', tensor([0.3114]))]) \n",
            "\n",
            "Epoch: 31030 | Loss: 0.0054345265962183475 | Test loss: 0.01270411629229784\n",
            "OrderedDict([('weights', tensor([0.6730])), ('bias', tensor([0.3114]))]) \n",
            "\n",
            "Epoch: 31040 | Loss: 0.0054173520766198635 | Test loss: 0.012664610520005226\n",
            "OrderedDict([('weights', tensor([0.6731])), ('bias', tensor([0.3113]))]) \n",
            "\n",
            "Epoch: 31050 | Loss: 0.00540021900087595 | Test loss: 0.012623375281691551\n",
            "OrderedDict([('weights', tensor([0.6731])), ('bias', tensor([0.3113]))]) \n",
            "\n",
            "Epoch: 31060 | Loss: 0.005383042152971029 | Test loss: 0.012583857402205467\n",
            "OrderedDict([('weights', tensor([0.6732])), ('bias', tensor([0.3112]))]) \n",
            "\n",
            "Epoch: 31070 | Loss: 0.005365878343582153 | Test loss: 0.012542635202407837\n",
            "OrderedDict([('weights', tensor([0.6733])), ('bias', tensor([0.3112]))]) \n",
            "\n",
            "Epoch: 31080 | Loss: 0.005348709877580404 | Test loss: 0.012503129430115223\n",
            "OrderedDict([('weights', tensor([0.6734])), ('bias', tensor([0.3112]))]) \n",
            "\n",
            "Epoch: 31090 | Loss: 0.005331554915755987 | Test loss: 0.012461895123124123\n",
            "OrderedDict([('weights', tensor([0.6735])), ('bias', tensor([0.3111]))]) \n",
            "\n",
            "Epoch: 31100 | Loss: 0.005314407404512167 | Test loss: 0.012422377243638039\n",
            "OrderedDict([('weights', tensor([0.6736])), ('bias', tensor([0.3111]))]) \n",
            "\n",
            "Epoch: 31110 | Loss: 0.005297230090945959 | Test loss: 0.012381154112517834\n",
            "OrderedDict([('weights', tensor([0.6737])), ('bias', tensor([0.3111]))]) \n",
            "\n",
            "Epoch: 31120 | Loss: 0.005280078388750553 | Test loss: 0.01234162412583828\n",
            "OrderedDict([('weights', tensor([0.6737])), ('bias', tensor([0.3110]))]) \n",
            "\n",
            "Epoch: 31130 | Loss: 0.005262917838990688 | Test loss: 0.012303883209824562\n",
            "OrderedDict([('weights', tensor([0.6738])), ('bias', tensor([0.3110]))]) \n",
            "\n",
            "Epoch: 31140 | Loss: 0.005245756357908249 | Test loss: 0.012260896153748035\n",
            "OrderedDict([('weights', tensor([0.6739])), ('bias', tensor([0.3110]))]) \n",
            "\n",
            "Epoch: 31150 | Loss: 0.005228607915341854 | Test loss: 0.012223130092024803\n",
            "OrderedDict([('weights', tensor([0.6740])), ('bias', tensor([0.3109]))]) \n",
            "\n",
            "Epoch: 31160 | Loss: 0.005211438052356243 | Test loss: 0.01218361221253872\n",
            "OrderedDict([('weights', tensor([0.6741])), ('bias', tensor([0.3109]))]) \n",
            "\n",
            "Epoch: 31170 | Loss: 0.005194296129047871 | Test loss: 0.012142402119934559\n",
            "OrderedDict([('weights', tensor([0.6742])), ('bias', tensor([0.3108]))]) \n",
            "\n",
            "Epoch: 31180 | Loss: 0.0051771304570138454 | Test loss: 0.012102872133255005\n",
            "OrderedDict([('weights', tensor([0.6743])), ('bias', tensor([0.3108]))]) \n",
            "\n",
            "Epoch: 31190 | Loss: 0.005159987602382898 | Test loss: 0.01206166110932827\n",
            "OrderedDict([('weights', tensor([0.6743])), ('bias', tensor([0.3108]))]) \n",
            "\n",
            "Epoch: 31200 | Loss: 0.005142823792994022 | Test loss: 0.01202213205397129\n",
            "OrderedDict([('weights', tensor([0.6744])), ('bias', tensor([0.3107]))]) \n",
            "\n",
            "Epoch: 31210 | Loss: 0.005125659052282572 | Test loss: 0.011980896815657616\n",
            "OrderedDict([('weights', tensor([0.6745])), ('bias', tensor([0.3107]))]) \n",
            "\n",
            "Epoch: 31220 | Loss: 0.005108509212732315 | Test loss: 0.011941378936171532\n",
            "OrderedDict([('weights', tensor([0.6746])), ('bias', tensor([0.3107]))]) \n",
            "\n",
            "Epoch: 31230 | Loss: 0.0050913309678435326 | Test loss: 0.011900168843567371\n",
            "OrderedDict([('weights', tensor([0.6747])), ('bias', tensor([0.3106]))]) \n",
            "\n",
            "Epoch: 31240 | Loss: 0.0050741867162287235 | Test loss: 0.011860650964081287\n",
            "OrderedDict([('weights', tensor([0.6748])), ('bias', tensor([0.3106]))]) \n",
            "\n",
            "Epoch: 31250 | Loss: 0.005057004280388355 | Test loss: 0.011819452047348022\n",
            "OrderedDict([('weights', tensor([0.6748])), ('bias', tensor([0.3106]))]) \n",
            "\n",
            "Epoch: 31260 | Loss: 0.005039862357079983 | Test loss: 0.011779922060668468\n",
            "OrderedDict([('weights', tensor([0.6749])), ('bias', tensor([0.3105]))]) \n",
            "\n",
            "Epoch: 31270 | Loss: 0.005022698547691107 | Test loss: 0.01174213271588087\n",
            "OrderedDict([('weights', tensor([0.6750])), ('bias', tensor([0.3105]))]) \n",
            "\n",
            "Epoch: 31280 | Loss: 0.005005533341318369 | Test loss: 0.011699157766997814\n",
            "OrderedDict([('weights', tensor([0.6751])), ('bias', tensor([0.3105]))]) \n",
            "\n",
            "Epoch: 31290 | Loss: 0.004988393280655146 | Test loss: 0.011661380529403687\n",
            "OrderedDict([('weights', tensor([0.6752])), ('bias', tensor([0.3104]))]) \n",
            "\n",
            "Epoch: 31300 | Loss: 0.004971218295395374 | Test loss: 0.011621874757111073\n",
            "OrderedDict([('weights', tensor([0.6753])), ('bias', tensor([0.3104]))]) \n",
            "\n",
            "Epoch: 31310 | Loss: 0.004954083822667599 | Test loss: 0.011580640450119972\n",
            "OrderedDict([('weights', tensor([0.6754])), ('bias', tensor([0.3103]))]) \n",
            "\n",
            "Epoch: 31320 | Loss: 0.004936915822327137 | Test loss: 0.011541145853698254\n",
            "OrderedDict([('weights', tensor([0.6754])), ('bias', tensor([0.3103]))]) \n",
            "\n",
            "Epoch: 31330 | Loss: 0.004919757135212421 | Test loss: 0.011499911546707153\n",
            "OrderedDict([('weights', tensor([0.6755])), ('bias', tensor([0.3103]))]) \n",
            "\n",
            "Epoch: 31340 | Loss: 0.0049026040360331535 | Test loss: 0.01146039366722107\n",
            "OrderedDict([('weights', tensor([0.6756])), ('bias', tensor([0.3102]))]) \n",
            "\n",
            "Epoch: 31350 | Loss: 0.004885443951934576 | Test loss: 0.011419147253036499\n",
            "OrderedDict([('weights', tensor([0.6757])), ('bias', tensor([0.3102]))]) \n",
            "\n",
            "Epoch: 31360 | Loss: 0.00486829224973917 | Test loss: 0.011379653587937355\n",
            "OrderedDict([('weights', tensor([0.6758])), ('bias', tensor([0.3102]))]) \n",
            "\n",
            "Epoch: 31370 | Loss: 0.004851107485592365 | Test loss: 0.01133841834962368\n",
            "OrderedDict([('weights', tensor([0.6759])), ('bias', tensor([0.3101]))]) \n",
            "\n",
            "Epoch: 31380 | Loss: 0.004833961836993694 | Test loss: 0.011298924684524536\n",
            "OrderedDict([('weights', tensor([0.6760])), ('bias', tensor([0.3101]))]) \n",
            "\n",
            "Epoch: 31390 | Loss: 0.004816775675863028 | Test loss: 0.011259418912231922\n",
            "OrderedDict([('weights', tensor([0.6760])), ('bias', tensor([0.3101]))]) \n",
            "\n",
            "Epoch: 31400 | Loss: 0.004799641668796539 | Test loss: 0.011218172498047352\n",
            "OrderedDict([('weights', tensor([0.6761])), ('bias', tensor([0.3100]))]) \n",
            "\n",
            "Epoch: 31410 | Loss: 0.004782479256391525 | Test loss: 0.01118043065071106\n",
            "OrderedDict([('weights', tensor([0.6762])), ('bias', tensor([0.3100]))]) \n",
            "\n",
            "Epoch: 31420 | Loss: 0.004765312187373638 | Test loss: 0.011137431487441063\n",
            "OrderedDict([('weights', tensor([0.6763])), ('bias', tensor([0.3100]))]) \n",
            "\n",
            "Epoch: 31430 | Loss: 0.004748172126710415 | Test loss: 0.011099642142653465\n",
            "OrderedDict([('weights', tensor([0.6764])), ('bias', tensor([0.3099]))]) \n",
            "\n",
            "Epoch: 31440 | Loss: 0.0047309971414506435 | Test loss: 0.011060136370360851\n",
            "OrderedDict([('weights', tensor([0.6765])), ('bias', tensor([0.3099]))]) \n",
            "\n",
            "Epoch: 31450 | Loss: 0.004713838454335928 | Test loss: 0.011017185635864735\n",
            "OrderedDict([('weights', tensor([0.6766])), ('bias', tensor([0.3098]))]) \n",
            "\n",
            "Epoch: 31460 | Loss: 0.004696700721979141 | Test loss: 0.010979408398270607\n",
            "OrderedDict([('weights', tensor([0.6766])), ('bias', tensor([0.3098]))]) \n",
            "\n",
            "Epoch: 31470 | Loss: 0.0046795448288321495 | Test loss: 0.010938197374343872\n",
            "OrderedDict([('weights', tensor([0.6767])), ('bias', tensor([0.3098]))]) \n",
            "\n",
            "Epoch: 31480 | Loss: 0.004662399645894766 | Test loss: 0.010898667387664318\n",
            "OrderedDict([('weights', tensor([0.6768])), ('bias', tensor([0.3097]))]) \n",
            "\n",
            "Epoch: 31490 | Loss: 0.0046452186070382595 | Test loss: 0.010857408866286278\n",
            "OrderedDict([('weights', tensor([0.6769])), ('bias', tensor([0.3097]))]) \n",
            "\n",
            "Epoch: 31500 | Loss: 0.004628071095794439 | Test loss: 0.010817927308380604\n",
            "OrderedDict([('weights', tensor([0.6770])), ('bias', tensor([0.3097]))]) \n",
            "\n",
            "Epoch: 31510 | Loss: 0.004610910080373287 | Test loss: 0.01077840942889452\n",
            "OrderedDict([('weights', tensor([0.6771])), ('bias', tensor([0.3096]))]) \n",
            "\n",
            "Epoch: 31520 | Loss: 0.004593748599290848 | Test loss: 0.010737186297774315\n",
            "OrderedDict([('weights', tensor([0.6772])), ('bias', tensor([0.3096]))]) \n",
            "\n",
            "Epoch: 31530 | Loss: 0.004576565232127905 | Test loss: 0.010697668418288231\n",
            "OrderedDict([('weights', tensor([0.6772])), ('bias', tensor([0.3096]))]) \n",
            "\n",
            "Epoch: 31540 | Loss: 0.004559422377496958 | Test loss: 0.0106564462184906\n",
            "OrderedDict([('weights', tensor([0.6773])), ('bias', tensor([0.3095]))]) \n",
            "\n",
            "Epoch: 31550 | Loss: 0.004542258568108082 | Test loss: 0.010618656873703003\n",
            "OrderedDict([('weights', tensor([0.6774])), ('bias', tensor([0.3095]))]) \n",
            "\n",
            "Epoch: 31560 | Loss: 0.004525092896074057 | Test loss: 0.010575706139206886\n",
            "OrderedDict([('weights', tensor([0.6775])), ('bias', tensor([0.3095]))]) \n",
            "\n",
            "Epoch: 31570 | Loss: 0.0045079430565238 | Test loss: 0.010536188259720802\n",
            "OrderedDict([('weights', tensor([0.6776])), ('bias', tensor([0.3094]))]) \n",
            "\n",
            "Epoch: 31580 | Loss: 0.004490782506763935 | Test loss: 0.0104984100908041\n",
            "OrderedDict([('weights', tensor([0.6777])), ('bias', tensor([0.3094]))]) \n",
            "\n",
            "Epoch: 31590 | Loss: 0.004473618231713772 | Test loss: 0.010455435141921043\n",
            "OrderedDict([('weights', tensor([0.6778])), ('bias', tensor([0.3093]))]) \n",
            "\n",
            "Epoch: 31600 | Loss: 0.004456470720469952 | Test loss: 0.010417670011520386\n",
            "OrderedDict([('weights', tensor([0.6778])), ('bias', tensor([0.3093]))]) \n",
            "\n",
            "Epoch: 31610 | Loss: 0.00443932693451643 | Test loss: 0.010376423597335815\n",
            "OrderedDict([('weights', tensor([0.6779])), ('bias', tensor([0.3093]))]) \n",
            "\n",
            "Epoch: 31620 | Loss: 0.0044221701100468636 | Test loss: 0.010336917825043201\n",
            "OrderedDict([('weights', tensor([0.6780])), ('bias', tensor([0.3092]))]) \n",
            "\n",
            "Epoch: 31630 | Loss: 0.0044049969874322414 | Test loss: 0.010297412052750587\n",
            "OrderedDict([('weights', tensor([0.6781])), ('bias', tensor([0.3092]))]) \n",
            "\n",
            "Epoch: 31640 | Loss: 0.004387863911688328 | Test loss: 0.010256176814436913\n",
            "OrderedDict([('weights', tensor([0.6782])), ('bias', tensor([0.3092]))]) \n",
            "\n",
            "Epoch: 31650 | Loss: 0.004370687063783407 | Test loss: 0.010216658934950829\n",
            "OrderedDict([('weights', tensor([0.6783])), ('bias', tensor([0.3091]))]) \n",
            "\n",
            "Epoch: 31660 | Loss: 0.004353524651378393 | Test loss: 0.010175436735153198\n",
            "OrderedDict([('weights', tensor([0.6783])), ('bias', tensor([0.3091]))]) \n",
            "\n",
            "Epoch: 31670 | Loss: 0.00433635339140892 | Test loss: 0.010135930962860584\n",
            "OrderedDict([('weights', tensor([0.6784])), ('bias', tensor([0.3091]))]) \n",
            "\n",
            "Epoch: 31680 | Loss: 0.004319199826568365 | Test loss: 0.010094696655869484\n",
            "OrderedDict([('weights', tensor([0.6785])), ('bias', tensor([0.3090]))]) \n",
            "\n",
            "Epoch: 31690 | Loss: 0.004302052315324545 | Test loss: 0.0100551787763834\n",
            "OrderedDict([('weights', tensor([0.6786])), ('bias', tensor([0.3090]))]) \n",
            "\n",
            "Epoch: 31700 | Loss: 0.004284875001758337 | Test loss: 0.010013955645263195\n",
            "OrderedDict([('weights', tensor([0.6787])), ('bias', tensor([0.3090]))]) \n",
            "\n",
            "Epoch: 31710 | Loss: 0.004267723299562931 | Test loss: 0.009974425658583641\n",
            "OrderedDict([('weights', tensor([0.6788])), ('bias', tensor([0.3089]))]) \n",
            "\n",
            "Epoch: 31720 | Loss: 0.004250562749803066 | Test loss: 0.009936684742569923\n",
            "OrderedDict([('weights', tensor([0.6789])), ('bias', tensor([0.3089]))]) \n",
            "\n",
            "Epoch: 31730 | Loss: 0.004233399871736765 | Test loss: 0.009893697686493397\n",
            "OrderedDict([('weights', tensor([0.6789])), ('bias', tensor([0.3088]))]) \n",
            "\n",
            "Epoch: 31740 | Loss: 0.004216252826154232 | Test loss: 0.009855931624770164\n",
            "OrderedDict([('weights', tensor([0.6790])), ('bias', tensor([0.3088]))]) \n",
            "\n",
            "Epoch: 31750 | Loss: 0.004199082963168621 | Test loss: 0.00981641374528408\n",
            "OrderedDict([('weights', tensor([0.6791])), ('bias', tensor([0.3088]))]) \n",
            "\n",
            "Epoch: 31760 | Loss: 0.0041819410398602486 | Test loss: 0.00977520365267992\n",
            "OrderedDict([('weights', tensor([0.6792])), ('bias', tensor([0.3087]))]) \n",
            "\n",
            "Epoch: 31770 | Loss: 0.004164775367826223 | Test loss: 0.009735673666000366\n",
            "OrderedDict([('weights', tensor([0.6793])), ('bias', tensor([0.3087]))]) \n",
            "\n",
            "Epoch: 31780 | Loss: 0.004147631116211414 | Test loss: 0.009694462642073631\n",
            "OrderedDict([('weights', tensor([0.6794])), ('bias', tensor([0.3087]))]) \n",
            "\n",
            "Epoch: 31790 | Loss: 0.004130470100790262 | Test loss: 0.009654933586716652\n",
            "OrderedDict([('weights', tensor([0.6795])), ('bias', tensor([0.3086]))]) \n",
            "\n",
            "Epoch: 31800 | Loss: 0.00411330396309495 | Test loss: 0.009613698348402977\n",
            "OrderedDict([('weights', tensor([0.6795])), ('bias', tensor([0.3086]))]) \n",
            "\n",
            "Epoch: 31810 | Loss: 0.004096154123544693 | Test loss: 0.009574180468916893\n",
            "OrderedDict([('weights', tensor([0.6796])), ('bias', tensor([0.3086]))]) \n",
            "\n",
            "Epoch: 31820 | Loss: 0.0040789758786559105 | Test loss: 0.009532970376312733\n",
            "OrderedDict([('weights', tensor([0.6797])), ('bias', tensor([0.3085]))]) \n",
            "\n",
            "Epoch: 31830 | Loss: 0.0040618316270411015 | Test loss: 0.009493452496826649\n",
            "OrderedDict([('weights', tensor([0.6798])), ('bias', tensor([0.3085]))]) \n",
            "\n",
            "Epoch: 31840 | Loss: 0.004044650588184595 | Test loss: 0.009452253580093384\n",
            "OrderedDict([('weights', tensor([0.6799])), ('bias', tensor([0.3084]))]) \n",
            "\n",
            "Epoch: 31850 | Loss: 0.004027507267892361 | Test loss: 0.00941272359341383\n",
            "OrderedDict([('weights', tensor([0.6800])), ('bias', tensor([0.3084]))]) \n",
            "\n",
            "Epoch: 31860 | Loss: 0.004010343458503485 | Test loss: 0.009374934248626232\n",
            "OrderedDict([('weights', tensor([0.6801])), ('bias', tensor([0.3084]))]) \n",
            "\n",
            "Epoch: 31870 | Loss: 0.003993178252130747 | Test loss: 0.009331959299743176\n",
            "OrderedDict([('weights', tensor([0.6801])), ('bias', tensor([0.3083]))]) \n",
            "\n",
            "Epoch: 31880 | Loss: 0.003976038191467524 | Test loss: 0.009294182062149048\n",
            "OrderedDict([('weights', tensor([0.6802])), ('bias', tensor([0.3083]))]) \n",
            "\n",
            "Epoch: 31890 | Loss: 0.003958863206207752 | Test loss: 0.009254676289856434\n",
            "OrderedDict([('weights', tensor([0.6803])), ('bias', tensor([0.3083]))]) \n",
            "\n",
            "Epoch: 31900 | Loss: 0.003941728733479977 | Test loss: 0.009213441982865334\n",
            "OrderedDict([('weights', tensor([0.6804])), ('bias', tensor([0.3082]))]) \n",
            "\n",
            "Epoch: 31910 | Loss: 0.003924558870494366 | Test loss: 0.009173947386443615\n",
            "OrderedDict([('weights', tensor([0.6805])), ('bias', tensor([0.3082]))]) \n",
            "\n",
            "Epoch: 31920 | Loss: 0.003907402046024799 | Test loss: 0.009132713079452515\n",
            "OrderedDict([('weights', tensor([0.6806])), ('bias', tensor([0.3082]))]) \n",
            "\n",
            "Epoch: 31930 | Loss: 0.003890249179676175 | Test loss: 0.00909319519996643\n",
            "OrderedDict([('weights', tensor([0.6807])), ('bias', tensor([0.3081]))]) \n",
            "\n",
            "Epoch: 31940 | Loss: 0.003873088862746954 | Test loss: 0.00905194878578186\n",
            "OrderedDict([('weights', tensor([0.6807])), ('bias', tensor([0.3081]))]) \n",
            "\n",
            "Epoch: 31950 | Loss: 0.0038559369277209044 | Test loss: 0.009012455120682716\n",
            "OrderedDict([('weights', tensor([0.6808])), ('bias', tensor([0.3081]))]) \n",
            "\n",
            "Epoch: 31960 | Loss: 0.0038387521635740995 | Test loss: 0.008971219882369041\n",
            "OrderedDict([('weights', tensor([0.6809])), ('bias', tensor([0.3080]))]) \n",
            "\n",
            "Epoch: 31970 | Loss: 0.003821606980636716 | Test loss: 0.008931726217269897\n",
            "OrderedDict([('weights', tensor([0.6810])), ('bias', tensor([0.3080]))]) \n",
            "\n",
            "Epoch: 31980 | Loss: 0.0038044205866754055 | Test loss: 0.008892220444977283\n",
            "OrderedDict([('weights', tensor([0.6811])), ('bias', tensor([0.3079]))]) \n",
            "\n",
            "Epoch: 31990 | Loss: 0.0037872865796089172 | Test loss: 0.008850974030792713\n",
            "OrderedDict([('weights', tensor([0.6812])), ('bias', tensor([0.3079]))]) \n",
            "\n",
            "Epoch: 32000 | Loss: 0.003770124167203903 | Test loss: 0.008813232183456421\n",
            "OrderedDict([('weights', tensor([0.6813])), ('bias', tensor([0.3079]))]) \n",
            "\n",
            "Epoch: 32010 | Loss: 0.0037529573310166597 | Test loss: 0.008770233020186424\n",
            "OrderedDict([('weights', tensor([0.6813])), ('bias', tensor([0.3078]))]) \n",
            "\n",
            "Epoch: 32020 | Loss: 0.0037358172703534365 | Test loss: 0.008732443675398827\n",
            "OrderedDict([('weights', tensor([0.6814])), ('bias', tensor([0.3078]))]) \n",
            "\n",
            "Epoch: 32030 | Loss: 0.0037186420522630215 | Test loss: 0.008692937903106213\n",
            "OrderedDict([('weights', tensor([0.6815])), ('bias', tensor([0.3078]))]) \n",
            "\n",
            "Epoch: 32040 | Loss: 0.003701483365148306 | Test loss: 0.008649987168610096\n",
            "OrderedDict([('weights', tensor([0.6816])), ('bias', tensor([0.3077]))]) \n",
            "\n",
            "Epoch: 32050 | Loss: 0.003684345632791519 | Test loss: 0.008612209931015968\n",
            "OrderedDict([('weights', tensor([0.6817])), ('bias', tensor([0.3077]))]) \n",
            "\n",
            "Epoch: 32060 | Loss: 0.003667189972475171 | Test loss: 0.008570998907089233\n",
            "OrderedDict([('weights', tensor([0.6818])), ('bias', tensor([0.3077]))]) \n",
            "\n",
            "Epoch: 32070 | Loss: 0.003650044556707144 | Test loss: 0.00853146892040968\n",
            "OrderedDict([('weights', tensor([0.6818])), ('bias', tensor([0.3076]))]) \n",
            "\n",
            "Epoch: 32080 | Loss: 0.0036328635178506374 | Test loss: 0.008490210399031639\n",
            "OrderedDict([('weights', tensor([0.6819])), ('bias', tensor([0.3076]))]) \n",
            "\n",
            "Epoch: 32090 | Loss: 0.0036157160066068172 | Test loss: 0.008450728841125965\n",
            "OrderedDict([('weights', tensor([0.6820])), ('bias', tensor([0.3076]))]) \n",
            "\n",
            "Epoch: 32100 | Loss: 0.003598555224016309 | Test loss: 0.008411210961639881\n",
            "OrderedDict([('weights', tensor([0.6821])), ('bias', tensor([0.3075]))]) \n",
            "\n",
            "Epoch: 32110 | Loss: 0.0035813935101032257 | Test loss: 0.008369987830519676\n",
            "OrderedDict([('weights', tensor([0.6822])), ('bias', tensor([0.3075]))]) \n",
            "\n",
            "Epoch: 32120 | Loss: 0.003564210142940283 | Test loss: 0.008330469951033592\n",
            "OrderedDict([('weights', tensor([0.6823])), ('bias', tensor([0.3074]))]) \n",
            "\n",
            "Epoch: 32130 | Loss: 0.0035470672883093357 | Test loss: 0.008289247751235962\n",
            "OrderedDict([('weights', tensor([0.6824])), ('bias', tensor([0.3074]))]) \n",
            "\n",
            "Epoch: 32140 | Loss: 0.003529903246089816 | Test loss: 0.008251458406448364\n",
            "OrderedDict([('weights', tensor([0.6824])), ('bias', tensor([0.3074]))]) \n",
            "\n",
            "Epoch: 32150 | Loss: 0.0035127378068864346 | Test loss: 0.008208507671952248\n",
            "OrderedDict([('weights', tensor([0.6825])), ('bias', tensor([0.3073]))]) \n",
            "\n",
            "Epoch: 32160 | Loss: 0.0034955882001668215 | Test loss: 0.008168989792466164\n",
            "OrderedDict([('weights', tensor([0.6826])), ('bias', tensor([0.3073]))]) \n",
            "\n",
            "Epoch: 32170 | Loss: 0.0034784271847456694 | Test loss: 0.008131211623549461\n",
            "OrderedDict([('weights', tensor([0.6827])), ('bias', tensor([0.3073]))]) \n",
            "\n",
            "Epoch: 32180 | Loss: 0.0034612647723406553 | Test loss: 0.008088236674666405\n",
            "OrderedDict([('weights', tensor([0.6828])), ('bias', tensor([0.3072]))]) \n",
            "\n",
            "Epoch: 32190 | Loss: 0.003444115864112973 | Test loss: 0.008050471544265747\n",
            "OrderedDict([('weights', tensor([0.6829])), ('bias', tensor([0.3072]))]) \n",
            "\n",
            "Epoch: 32200 | Loss: 0.0034269720781594515 | Test loss: 0.008009225130081177\n",
            "OrderedDict([('weights', tensor([0.6830])), ('bias', tensor([0.3072]))]) \n",
            "\n",
            "Epoch: 32210 | Loss: 0.003409814788028598 | Test loss: 0.007969719357788563\n",
            "OrderedDict([('weights', tensor([0.6830])), ('bias', tensor([0.3071]))]) \n",
            "\n",
            "Epoch: 32220 | Loss: 0.0033926418982446194 | Test loss: 0.007930213585495949\n",
            "OrderedDict([('weights', tensor([0.6831])), ('bias', tensor([0.3071]))]) \n",
            "\n",
            "Epoch: 32230 | Loss: 0.003375508589670062 | Test loss: 0.007888978347182274\n",
            "OrderedDict([('weights', tensor([0.6832])), ('bias', tensor([0.3070]))]) \n",
            "\n",
            "Epoch: 32240 | Loss: 0.003358331974595785 | Test loss: 0.00784946046769619\n",
            "OrderedDict([('weights', tensor([0.6833])), ('bias', tensor([0.3070]))]) \n",
            "\n",
            "Epoch: 32250 | Loss: 0.003341169562190771 | Test loss: 0.00780823826789856\n",
            "OrderedDict([('weights', tensor([0.6834])), ('bias', tensor([0.3070]))]) \n",
            "\n",
            "Epoch: 32260 | Loss: 0.0033239983022212982 | Test loss: 0.007768732495605946\n",
            "OrderedDict([('weights', tensor([0.6835])), ('bias', tensor([0.3069]))]) \n",
            "\n",
            "Epoch: 32270 | Loss: 0.003306844737380743 | Test loss: 0.007727497722953558\n",
            "OrderedDict([('weights', tensor([0.6836])), ('bias', tensor([0.3069]))]) \n",
            "\n",
            "Epoch: 32280 | Loss: 0.003289697226136923 | Test loss: 0.007687979843467474\n",
            "OrderedDict([('weights', tensor([0.6836])), ('bias', tensor([0.3069]))]) \n",
            "\n",
            "Epoch: 32290 | Loss: 0.003272519912570715 | Test loss: 0.007646757178008556\n",
            "OrderedDict([('weights', tensor([0.6837])), ('bias', tensor([0.3068]))]) \n",
            "\n",
            "Epoch: 32300 | Loss: 0.0032553679775446653 | Test loss: 0.00760722765699029\n",
            "OrderedDict([('weights', tensor([0.6838])), ('bias', tensor([0.3068]))]) \n",
            "\n",
            "Epoch: 32310 | Loss: 0.003238207893446088 | Test loss: 0.007569485809653997\n",
            "OrderedDict([('weights', tensor([0.6839])), ('bias', tensor([0.3068]))]) \n",
            "\n",
            "Epoch: 32320 | Loss: 0.003221044782549143 | Test loss: 0.007526499219238758\n",
            "OrderedDict([('weights', tensor([0.6840])), ('bias', tensor([0.3067]))]) \n",
            "\n",
            "Epoch: 32330 | Loss: 0.0032038979697972536 | Test loss: 0.007488733623176813\n",
            "OrderedDict([('weights', tensor([0.6841])), ('bias', tensor([0.3067]))]) \n",
            "\n",
            "Epoch: 32340 | Loss: 0.0031867281068116426 | Test loss: 0.007449215743690729\n",
            "OrderedDict([('weights', tensor([0.6842])), ('bias', tensor([0.3067]))]) \n",
            "\n",
            "Epoch: 32350 | Loss: 0.003169585717841983 | Test loss: 0.0074080051854252815\n",
            "OrderedDict([('weights', tensor([0.6842])), ('bias', tensor([0.3066]))]) \n",
            "\n",
            "Epoch: 32360 | Loss: 0.0031524202786386013 | Test loss: 0.0073684751987457275\n",
            "OrderedDict([('weights', tensor([0.6843])), ('bias', tensor([0.3066]))]) \n",
            "\n",
            "Epoch: 32370 | Loss: 0.0031352757941931486 | Test loss: 0.00732726464048028\n",
            "OrderedDict([('weights', tensor([0.6844])), ('bias', tensor([0.3065]))]) \n",
            "\n",
            "Epoch: 32380 | Loss: 0.00311811501160264 | Test loss: 0.007287734653800726\n",
            "OrderedDict([('weights', tensor([0.6845])), ('bias', tensor([0.3065]))]) \n",
            "\n",
            "Epoch: 32390 | Loss: 0.0031009488739073277 | Test loss: 0.007246500346809626\n",
            "OrderedDict([('weights', tensor([0.6846])), ('bias', tensor([0.3065]))]) \n",
            "\n",
            "Epoch: 32400 | Loss: 0.003083799034357071 | Test loss: 0.007206982467323542\n",
            "OrderedDict([('weights', tensor([0.6847])), ('bias', tensor([0.3064]))]) \n",
            "\n",
            "Epoch: 32410 | Loss: 0.003066621022298932 | Test loss: 0.007165771909058094\n",
            "OrderedDict([('weights', tensor([0.6848])), ('bias', tensor([0.3064]))]) \n",
            "\n",
            "Epoch: 32420 | Loss: 0.0030494765378534794 | Test loss: 0.00712625402957201\n",
            "OrderedDict([('weights', tensor([0.6848])), ('bias', tensor([0.3064]))]) \n",
            "\n",
            "Epoch: 32430 | Loss: 0.003032295498996973 | Test loss: 0.007085055112838745\n",
            "OrderedDict([('weights', tensor([0.6849])), ('bias', tensor([0.3063]))]) \n",
            "\n",
            "Epoch: 32440 | Loss: 0.0030151524115353823 | Test loss: 0.007045525126159191\n",
            "OrderedDict([('weights', tensor([0.6850])), ('bias', tensor([0.3063]))]) \n",
            "\n",
            "Epoch: 32450 | Loss: 0.0029979883693158627 | Test loss: 0.0070077357813715935\n",
            "OrderedDict([('weights', tensor([0.6851])), ('bias', tensor([0.3063]))]) \n",
            "\n",
            "Epoch: 32460 | Loss: 0.0029808245599269867 | Test loss: 0.006964760832488537\n",
            "OrderedDict([('weights', tensor([0.6852])), ('bias', tensor([0.3062]))]) \n",
            "\n",
            "Epoch: 32470 | Loss: 0.0029636831022799015 | Test loss: 0.006926983594894409\n",
            "OrderedDict([('weights', tensor([0.6853])), ('bias', tensor([0.3062]))]) \n",
            "\n",
            "Epoch: 32480 | Loss: 0.0029465078841894865 | Test loss: 0.006887477822601795\n",
            "OrderedDict([('weights', tensor([0.6853])), ('bias', tensor([0.3062]))]) \n",
            "\n",
            "Epoch: 32490 | Loss: 0.0029293738771229982 | Test loss: 0.006846243049949408\n",
            "OrderedDict([('weights', tensor([0.6854])), ('bias', tensor([0.3061]))]) \n",
            "\n",
            "Epoch: 32500 | Loss: 0.0029122040141373873 | Test loss: 0.006806748919188976\n",
            "OrderedDict([('weights', tensor([0.6855])), ('bias', tensor([0.3061]))]) \n",
            "\n",
            "Epoch: 32510 | Loss: 0.0028950467240065336 | Test loss: 0.006765514612197876\n",
            "OrderedDict([('weights', tensor([0.6856])), ('bias', tensor([0.3060]))]) \n",
            "\n",
            "Epoch: 32520 | Loss: 0.002877894090488553 | Test loss: 0.006725996732711792\n",
            "OrderedDict([('weights', tensor([0.6857])), ('bias', tensor([0.3060]))]) \n",
            "\n",
            "Epoch: 32530 | Loss: 0.002860733773559332 | Test loss: 0.006684750318527222\n",
            "OrderedDict([('weights', tensor([0.6858])), ('bias', tensor([0.3060]))]) \n",
            "\n",
            "Epoch: 32540 | Loss: 0.0028435818385332823 | Test loss: 0.00664525618776679\n",
            "OrderedDict([('weights', tensor([0.6859])), ('bias', tensor([0.3059]))]) \n",
            "\n",
            "Epoch: 32550 | Loss: 0.0028263970743864775 | Test loss: 0.00660402188077569\n",
            "OrderedDict([('weights', tensor([0.6859])), ('bias', tensor([0.3059]))]) \n",
            "\n",
            "Epoch: 32560 | Loss: 0.002809251891449094 | Test loss: 0.006564527750015259\n",
            "OrderedDict([('weights', tensor([0.6860])), ('bias', tensor([0.3059]))]) \n",
            "\n",
            "Epoch: 32570 | Loss: 0.0027920654974877834 | Test loss: 0.006525021977722645\n",
            "OrderedDict([('weights', tensor([0.6861])), ('bias', tensor([0.3058]))]) \n",
            "\n",
            "Epoch: 32580 | Loss: 0.002774931490421295 | Test loss: 0.0064837755635380745\n",
            "OrderedDict([('weights', tensor([0.6862])), ('bias', tensor([0.3058]))]) \n",
            "\n",
            "Epoch: 32590 | Loss: 0.002757769078016281 | Test loss: 0.006446033716201782\n",
            "OrderedDict([('weights', tensor([0.6863])), ('bias', tensor([0.3058]))]) \n",
            "\n",
            "Epoch: 32600 | Loss: 0.0027406022418290377 | Test loss: 0.006403035018593073\n",
            "OrderedDict([('weights', tensor([0.6864])), ('bias', tensor([0.3057]))]) \n",
            "\n",
            "Epoch: 32610 | Loss: 0.0027234621811658144 | Test loss: 0.006365245673805475\n",
            "OrderedDict([('weights', tensor([0.6865])), ('bias', tensor([0.3057]))]) \n",
            "\n",
            "Epoch: 32620 | Loss: 0.0027062869630753994 | Test loss: 0.006325739435851574\n",
            "OrderedDict([('weights', tensor([0.6865])), ('bias', tensor([0.3057]))]) \n",
            "\n",
            "Epoch: 32630 | Loss: 0.002689128275960684 | Test loss: 0.006282788701355457\n",
            "OrderedDict([('weights', tensor([0.6866])), ('bias', tensor([0.3056]))]) \n",
            "\n",
            "Epoch: 32640 | Loss: 0.002671990543603897 | Test loss: 0.006245010998100042\n",
            "OrderedDict([('weights', tensor([0.6867])), ('bias', tensor([0.3056]))]) \n",
            "\n",
            "Epoch: 32650 | Loss: 0.002654834883287549 | Test loss: 0.006203800439834595\n",
            "OrderedDict([('weights', tensor([0.6868])), ('bias', tensor([0.3055]))]) \n",
            "\n",
            "Epoch: 32660 | Loss: 0.0026376894675195217 | Test loss: 0.006164270453155041\n",
            "OrderedDict([('weights', tensor([0.6869])), ('bias', tensor([0.3055]))]) \n",
            "\n",
            "Epoch: 32670 | Loss: 0.0026205084286630154 | Test loss: 0.006123012397438288\n",
            "OrderedDict([('weights', tensor([0.6870])), ('bias', tensor([0.3055]))]) \n",
            "\n",
            "Epoch: 32680 | Loss: 0.002603360917419195 | Test loss: 0.0060835303738713264\n",
            "OrderedDict([('weights', tensor([0.6871])), ('bias', tensor([0.3054]))]) \n",
            "\n",
            "Epoch: 32690 | Loss: 0.0025862001348286867 | Test loss: 0.0060440124943852425\n",
            "OrderedDict([('weights', tensor([0.6871])), ('bias', tensor([0.3054]))]) \n",
            "\n",
            "Epoch: 32700 | Loss: 0.0025690384209156036 | Test loss: 0.006002789828926325\n",
            "OrderedDict([('weights', tensor([0.6872])), ('bias', tensor([0.3054]))]) \n",
            "\n",
            "Epoch: 32710 | Loss: 0.0025518550537526608 | Test loss: 0.005963271949440241\n",
            "OrderedDict([('weights', tensor([0.6873])), ('bias', tensor([0.3053]))]) \n",
            "\n",
            "Epoch: 32720 | Loss: 0.0025347121991217136 | Test loss: 0.005922049283981323\n",
            "OrderedDict([('weights', tensor([0.6874])), ('bias', tensor([0.3053]))]) \n",
            "\n",
            "Epoch: 32730 | Loss: 0.002517548156902194 | Test loss: 0.005884259939193726\n",
            "OrderedDict([('weights', tensor([0.6875])), ('bias', tensor([0.3053]))]) \n",
            "\n",
            "Epoch: 32740 | Loss: 0.0025003827176988125 | Test loss: 0.005841308739036322\n",
            "OrderedDict([('weights', tensor([0.6876])), ('bias', tensor([0.3052]))]) \n",
            "\n",
            "Epoch: 32750 | Loss: 0.0024832331109791994 | Test loss: 0.005801790859550238\n",
            "OrderedDict([('weights', tensor([0.6877])), ('bias', tensor([0.3052]))]) \n",
            "\n",
            "Epoch: 32760 | Loss: 0.0024660720955580473 | Test loss: 0.00576401362195611\n",
            "OrderedDict([('weights', tensor([0.6877])), ('bias', tensor([0.3051]))]) \n",
            "\n",
            "Epoch: 32770 | Loss: 0.0024489096831530333 | Test loss: 0.005721038673073053\n",
            "OrderedDict([('weights', tensor([0.6878])), ('bias', tensor([0.3051]))]) \n",
            "\n",
            "Epoch: 32780 | Loss: 0.002431760774925351 | Test loss: 0.005683273077011108\n",
            "OrderedDict([('weights', tensor([0.6879])), ('bias', tensor([0.3051]))]) \n",
            "\n",
            "Epoch: 32790 | Loss: 0.0024146169889718294 | Test loss: 0.005642026662826538\n",
            "OrderedDict([('weights', tensor([0.6880])), ('bias', tensor([0.3050]))]) \n",
            "\n",
            "Epoch: 32800 | Loss: 0.0023974596988409758 | Test loss: 0.005602520890533924\n",
            "OrderedDict([('weights', tensor([0.6881])), ('bias', tensor([0.3050]))]) \n",
            "\n",
            "Epoch: 32810 | Loss: 0.0023802868090569973 | Test loss: 0.005563014652580023\n",
            "OrderedDict([('weights', tensor([0.6882])), ('bias', tensor([0.3050]))]) \n",
            "\n",
            "Epoch: 32820 | Loss: 0.00236315350048244 | Test loss: 0.0055217803455889225\n",
            "OrderedDict([('weights', tensor([0.6883])), ('bias', tensor([0.3049]))]) \n",
            "\n",
            "Epoch: 32830 | Loss: 0.002345976885408163 | Test loss: 0.0054822624661028385\n",
            "OrderedDict([('weights', tensor([0.6883])), ('bias', tensor([0.3049]))]) \n",
            "\n",
            "Epoch: 32840 | Loss: 0.002328814473003149 | Test loss: 0.005441039800643921\n",
            "OrderedDict([('weights', tensor([0.6884])), ('bias', tensor([0.3049]))]) \n",
            "\n",
            "Epoch: 32850 | Loss: 0.002311643213033676 | Test loss: 0.005401534028351307\n",
            "OrderedDict([('weights', tensor([0.6885])), ('bias', tensor([0.3048]))]) \n",
            "\n",
            "Epoch: 32860 | Loss: 0.002294489648193121 | Test loss: 0.005360299255698919\n",
            "OrderedDict([('weights', tensor([0.6886])), ('bias', tensor([0.3048]))]) \n",
            "\n",
            "Epoch: 32870 | Loss: 0.0022773421369493008 | Test loss: 0.005320781376212835\n",
            "OrderedDict([('weights', tensor([0.6887])), ('bias', tensor([0.3048]))]) \n",
            "\n",
            "Epoch: 32880 | Loss: 0.002260164823383093 | Test loss: 0.005279558710753918\n",
            "OrderedDict([('weights', tensor([0.6888])), ('bias', tensor([0.3047]))]) \n",
            "\n",
            "Epoch: 32890 | Loss: 0.0022430128883570433 | Test loss: 0.005240029189735651\n",
            "OrderedDict([('weights', tensor([0.6888])), ('bias', tensor([0.3047]))]) \n",
            "\n",
            "Epoch: 32900 | Loss: 0.0022258528042584658 | Test loss: 0.005202287342399359\n",
            "OrderedDict([('weights', tensor([0.6889])), ('bias', tensor([0.3046]))]) \n",
            "\n",
            "Epoch: 32910 | Loss: 0.0022086896933615208 | Test loss: 0.005159300751984119\n",
            "OrderedDict([('weights', tensor([0.6890])), ('bias', tensor([0.3046]))]) \n",
            "\n",
            "Epoch: 32920 | Loss: 0.0021915428806096315 | Test loss: 0.0051215351559221745\n",
            "OrderedDict([('weights', tensor([0.6891])), ('bias', tensor([0.3046]))]) \n",
            "\n",
            "Epoch: 32930 | Loss: 0.0021743730176240206 | Test loss: 0.0050820172764360905\n",
            "OrderedDict([('weights', tensor([0.6892])), ('bias', tensor([0.3045]))]) \n",
            "\n",
            "Epoch: 32940 | Loss: 0.0021572306286543608 | Test loss: 0.005040806718170643\n",
            "OrderedDict([('weights', tensor([0.6893])), ('bias', tensor([0.3045]))]) \n",
            "\n",
            "Epoch: 32950 | Loss: 0.0021400651894509792 | Test loss: 0.005001276731491089\n",
            "OrderedDict([('weights', tensor([0.6894])), ('bias', tensor([0.3045]))]) \n",
            "\n",
            "Epoch: 32960 | Loss: 0.0021229207050055265 | Test loss: 0.004960066173225641\n",
            "OrderedDict([('weights', tensor([0.6894])), ('bias', tensor([0.3044]))]) \n",
            "\n",
            "Epoch: 32970 | Loss: 0.002105759922415018 | Test loss: 0.004920536186546087\n",
            "OrderedDict([('weights', tensor([0.6895])), ('bias', tensor([0.3044]))]) \n",
            "\n",
            "Epoch: 32980 | Loss: 0.0020885937847197056 | Test loss: 0.004879301879554987\n",
            "OrderedDict([('weights', tensor([0.6896])), ('bias', tensor([0.3044]))]) \n",
            "\n",
            "Epoch: 32990 | Loss: 0.002071443945169449 | Test loss: 0.004839784000068903\n",
            "OrderedDict([('weights', tensor([0.6897])), ('bias', tensor([0.3043]))]) \n",
            "\n",
            "Epoch: 33000 | Loss: 0.00205426593311131 | Test loss: 0.004798573441803455\n",
            "OrderedDict([('weights', tensor([0.6898])), ('bias', tensor([0.3043]))]) \n",
            "\n",
            "Epoch: 33010 | Loss: 0.0020371214486658573 | Test loss: 0.004759055562317371\n",
            "OrderedDict([('weights', tensor([0.6899])), ('bias', tensor([0.3043]))]) \n",
            "\n",
            "Epoch: 33020 | Loss: 0.002019940409809351 | Test loss: 0.0047178566455841064\n",
            "OrderedDict([('weights', tensor([0.6900])), ('bias', tensor([0.3042]))]) \n",
            "\n",
            "Epoch: 33030 | Loss: 0.00200279732234776 | Test loss: 0.0046783266589045525\n",
            "OrderedDict([('weights', tensor([0.6900])), ('bias', tensor([0.3042]))]) \n",
            "\n",
            "Epoch: 33040 | Loss: 0.0019856332801282406 | Test loss: 0.004640537314116955\n",
            "OrderedDict([('weights', tensor([0.6901])), ('bias', tensor([0.3041]))]) \n",
            "\n",
            "Epoch: 33050 | Loss: 0.0019684694707393646 | Test loss: 0.004597562365233898\n",
            "OrderedDict([('weights', tensor([0.6902])), ('bias', tensor([0.3041]))]) \n",
            "\n",
            "Epoch: 33060 | Loss: 0.0019513278966769576 | Test loss: 0.0045597851276397705\n",
            "OrderedDict([('weights', tensor([0.6903])), ('bias', tensor([0.3041]))]) \n",
            "\n",
            "Epoch: 33070 | Loss: 0.0019341527950018644 | Test loss: 0.0045202793553471565\n",
            "OrderedDict([('weights', tensor([0.6904])), ('bias', tensor([0.3040]))]) \n",
            "\n",
            "Epoch: 33080 | Loss: 0.0019170187879353762 | Test loss: 0.004479044582694769\n",
            "OrderedDict([('weights', tensor([0.6905])), ('bias', tensor([0.3040]))]) \n",
            "\n",
            "Epoch: 33090 | Loss: 0.0018998489249497652 | Test loss: 0.004439550451934338\n",
            "OrderedDict([('weights', tensor([0.6906])), ('bias', tensor([0.3040]))]) \n",
            "\n",
            "Epoch: 33100 | Loss: 0.0018826916348189116 | Test loss: 0.004398316144943237\n",
            "OrderedDict([('weights', tensor([0.6906])), ('bias', tensor([0.3039]))]) \n",
            "\n",
            "Epoch: 33110 | Loss: 0.001865539001300931 | Test loss: 0.004358798265457153\n",
            "OrderedDict([('weights', tensor([0.6907])), ('bias', tensor([0.3039]))]) \n",
            "\n",
            "Epoch: 33120 | Loss: 0.0018483788007870317 | Test loss: 0.004317551851272583\n",
            "OrderedDict([('weights', tensor([0.6908])), ('bias', tensor([0.3039]))]) \n",
            "\n",
            "Epoch: 33130 | Loss: 0.0018312267493456602 | Test loss: 0.004278057720512152\n",
            "OrderedDict([('weights', tensor([0.6909])), ('bias', tensor([0.3038]))]) \n",
            "\n",
            "Epoch: 33140 | Loss: 0.0018140419851988554 | Test loss: 0.004236823413521051\n",
            "OrderedDict([('weights', tensor([0.6910])), ('bias', tensor([0.3038]))]) \n",
            "\n",
            "Epoch: 33150 | Loss: 0.0017968968022614717 | Test loss: 0.00419732928276062\n",
            "OrderedDict([('weights', tensor([0.6911])), ('bias', tensor([0.3038]))]) \n",
            "\n",
            "Epoch: 33160 | Loss: 0.0017797105247154832 | Test loss: 0.004157823510468006\n",
            "OrderedDict([('weights', tensor([0.6912])), ('bias', tensor([0.3037]))]) \n",
            "\n",
            "Epoch: 33170 | Loss: 0.001762576401233673 | Test loss: 0.004116577096283436\n",
            "OrderedDict([('weights', tensor([0.6912])), ('bias', tensor([0.3037]))]) \n",
            "\n",
            "Epoch: 33180 | Loss: 0.001745413988828659 | Test loss: 0.0040788352489471436\n",
            "OrderedDict([('weights', tensor([0.6913])), ('bias', tensor([0.3036]))]) \n",
            "\n",
            "Epoch: 33190 | Loss: 0.0017282471526414156 | Test loss: 0.004035836551338434\n",
            "OrderedDict([('weights', tensor([0.6914])), ('bias', tensor([0.3036]))]) \n",
            "\n",
            "Epoch: 33200 | Loss: 0.0017111070919781923 | Test loss: 0.0039980472065508366\n",
            "OrderedDict([('weights', tensor([0.6915])), ('bias', tensor([0.3036]))]) \n",
            "\n",
            "Epoch: 33210 | Loss: 0.0016939319903030992 | Test loss: 0.003958540968596935\n",
            "OrderedDict([('weights', tensor([0.6916])), ('bias', tensor([0.3035]))]) \n",
            "\n",
            "Epoch: 33220 | Loss: 0.0016767733031883836 | Test loss: 0.003915590234100819\n",
            "OrderedDict([('weights', tensor([0.6917])), ('bias', tensor([0.3035]))]) \n",
            "\n",
            "Epoch: 33230 | Loss: 0.001659635454416275 | Test loss: 0.0038778125308454037\n",
            "OrderedDict([('weights', tensor([0.6918])), ('bias', tensor([0.3035]))]) \n",
            "\n",
            "Epoch: 33240 | Loss: 0.001642479794099927 | Test loss: 0.003836601972579956\n",
            "OrderedDict([('weights', tensor([0.6918])), ('bias', tensor([0.3034]))]) \n",
            "\n",
            "Epoch: 33250 | Loss: 0.0016253344947472215 | Test loss: 0.0037970722187310457\n",
            "OrderedDict([('weights', tensor([0.6919])), ('bias', tensor([0.3034]))]) \n",
            "\n",
            "Epoch: 33260 | Loss: 0.0016081534558907151 | Test loss: 0.003755813930183649\n",
            "OrderedDict([('weights', tensor([0.6920])), ('bias', tensor([0.3034]))]) \n",
            "\n",
            "Epoch: 33270 | Loss: 0.001591005944646895 | Test loss: 0.003716331673786044\n",
            "OrderedDict([('weights', tensor([0.6921])), ('bias', tensor([0.3033]))]) \n",
            "\n",
            "Epoch: 33280 | Loss: 0.0015738450456410646 | Test loss: 0.00367681379429996\n",
            "OrderedDict([('weights', tensor([0.6922])), ('bias', tensor([0.3033]))]) \n",
            "\n",
            "Epoch: 33290 | Loss: 0.0015566833317279816 | Test loss: 0.003635591361671686\n",
            "OrderedDict([('weights', tensor([0.6923])), ('bias', tensor([0.3032]))]) \n",
            "\n",
            "Epoch: 33300 | Loss: 0.0015395000809803605 | Test loss: 0.003596073482185602\n",
            "OrderedDict([('weights', tensor([0.6923])), ('bias', tensor([0.3032]))]) \n",
            "\n",
            "Epoch: 33310 | Loss: 0.0015223569935187697 | Test loss: 0.0035548508167266846\n",
            "OrderedDict([('weights', tensor([0.6924])), ('bias', tensor([0.3032]))]) \n",
            "\n",
            "Epoch: 33320 | Loss: 0.001505193067714572 | Test loss: 0.003517061471939087\n",
            "OrderedDict([('weights', tensor([0.6925])), ('bias', tensor([0.3031]))]) \n",
            "\n",
            "Epoch: 33330 | Loss: 0.0014880277449265122 | Test loss: 0.003474110271781683\n",
            "OrderedDict([('weights', tensor([0.6926])), ('bias', tensor([0.3031]))]) \n",
            "\n",
            "Epoch: 33340 | Loss: 0.0014708780217915773 | Test loss: 0.003434592392295599\n",
            "OrderedDict([('weights', tensor([0.6927])), ('bias', tensor([0.3031]))]) \n",
            "\n",
            "Epoch: 33350 | Loss: 0.0014537170063704252 | Test loss: 0.0033968151547014713\n",
            "OrderedDict([('weights', tensor([0.6928])), ('bias', tensor([0.3030]))]) \n",
            "\n",
            "Epoch: 33360 | Loss: 0.0014365545939654112 | Test loss: 0.0033538402058184147\n",
            "OrderedDict([('weights', tensor([0.6929])), ('bias', tensor([0.3030]))]) \n",
            "\n",
            "Epoch: 33370 | Loss: 0.001419405685737729 | Test loss: 0.0033160746097564697\n",
            "OrderedDict([('weights', tensor([0.6929])), ('bias', tensor([0.3030]))]) \n",
            "\n",
            "Epoch: 33380 | Loss: 0.0014022618997842073 | Test loss: 0.0032748281955718994\n",
            "OrderedDict([('weights', tensor([0.6930])), ('bias', tensor([0.3029]))]) \n",
            "\n",
            "Epoch: 33390 | Loss: 0.0013851046096533537 | Test loss: 0.0032353221904486418\n",
            "OrderedDict([('weights', tensor([0.6931])), ('bias', tensor([0.3029]))]) \n",
            "\n",
            "Epoch: 33400 | Loss: 0.001367931836284697 | Test loss: 0.003195816185325384\n",
            "OrderedDict([('weights', tensor([0.6932])), ('bias', tensor([0.3029]))]) \n",
            "\n",
            "Epoch: 33410 | Loss: 0.001350798411294818 | Test loss: 0.003154581878334284\n",
            "OrderedDict([('weights', tensor([0.6933])), ('bias', tensor([0.3028]))]) \n",
            "\n",
            "Epoch: 33420 | Loss: 0.0013336219126358628 | Test loss: 0.0031150639988482\n",
            "OrderedDict([('weights', tensor([0.6934])), ('bias', tensor([0.3028]))]) \n",
            "\n",
            "Epoch: 33430 | Loss: 0.0013164595002308488 | Test loss: 0.0030738413333892822\n",
            "OrderedDict([('weights', tensor([0.6935])), ('bias', tensor([0.3027]))]) \n",
            "\n",
            "Epoch: 33440 | Loss: 0.001299288123846054 | Test loss: 0.0030343353282660246\n",
            "OrderedDict([('weights', tensor([0.6935])), ('bias', tensor([0.3027]))]) \n",
            "\n",
            "Epoch: 33450 | Loss: 0.0012821346754208207 | Test loss: 0.0029931007884442806\n",
            "OrderedDict([('weights', tensor([0.6936])), ('bias', tensor([0.3027]))]) \n",
            "\n",
            "Epoch: 33460 | Loss: 0.0012649871641770005 | Test loss: 0.0029535829089581966\n",
            "OrderedDict([('weights', tensor([0.6937])), ('bias', tensor([0.3026]))]) \n",
            "\n",
            "Epoch: 33470 | Loss: 0.0012478098506107926 | Test loss: 0.0029123604763299227\n",
            "OrderedDict([('weights', tensor([0.6938])), ('bias', tensor([0.3026]))]) \n",
            "\n",
            "Epoch: 33480 | Loss: 0.0012306577991694212 | Test loss: 0.0028728307224810123\n",
            "OrderedDict([('weights', tensor([0.6939])), ('bias', tensor([0.3026]))]) \n",
            "\n",
            "Epoch: 33490 | Loss: 0.0012134977150708437 | Test loss: 0.00283508887514472\n",
            "OrderedDict([('weights', tensor([0.6940])), ('bias', tensor([0.3025]))]) \n",
            "\n",
            "Epoch: 33500 | Loss: 0.0011963344877585769 | Test loss: 0.002792102051898837\n",
            "OrderedDict([('weights', tensor([0.6941])), ('bias', tensor([0.3025]))]) \n",
            "\n",
            "Epoch: 33510 | Loss: 0.0011791877914220095 | Test loss: 0.0027543366886675358\n",
            "OrderedDict([('weights', tensor([0.6941])), ('bias', tensor([0.3025]))]) \n",
            "\n",
            "Epoch: 33520 | Loss: 0.0011620179284363985 | Test loss: 0.002714818809181452\n",
            "OrderedDict([('weights', tensor([0.6942])), ('bias', tensor([0.3024]))]) \n",
            "\n",
            "Epoch: 33530 | Loss: 0.0011448755394667387 | Test loss: 0.0026736080180853605\n",
            "OrderedDict([('weights', tensor([0.6943])), ('bias', tensor([0.3024]))]) \n",
            "\n",
            "Epoch: 33540 | Loss: 0.001127710216678679 | Test loss: 0.00263407826423645\n",
            "OrderedDict([('weights', tensor([0.6944])), ('bias', tensor([0.3024]))]) \n",
            "\n",
            "Epoch: 33550 | Loss: 0.0011105656158179045 | Test loss: 0.0025928677059710026\n",
            "OrderedDict([('weights', tensor([0.6945])), ('bias', tensor([0.3023]))]) \n",
            "\n",
            "Epoch: 33560 | Loss: 0.0010934047168120742 | Test loss: 0.0025533377192914486\n",
            "OrderedDict([('weights', tensor([0.6946])), ('bias', tensor([0.3023]))]) \n",
            "\n",
            "Epoch: 33570 | Loss: 0.0010762400925159454 | Test loss: 0.0025121034123003483\n",
            "OrderedDict([('weights', tensor([0.6947])), ('bias', tensor([0.3022]))]) \n",
            "\n",
            "Epoch: 33580 | Loss: 0.0010590895544737577 | Test loss: 0.0024725855328142643\n",
            "OrderedDict([('weights', tensor([0.6947])), ('bias', tensor([0.3022]))]) \n",
            "\n",
            "Epoch: 33590 | Loss: 0.001041910843923688 | Test loss: 0.002431374741718173\n",
            "OrderedDict([('weights', tensor([0.6948])), ('bias', tensor([0.3022]))]) \n",
            "\n",
            "Epoch: 33600 | Loss: 0.0010247662430629134 | Test loss: 0.002391856862232089\n",
            "OrderedDict([('weights', tensor([0.6949])), ('bias', tensor([0.3021]))]) \n",
            "\n",
            "Epoch: 33610 | Loss: 0.001007585204206407 | Test loss: 0.0023506581783294678\n",
            "OrderedDict([('weights', tensor([0.6950])), ('bias', tensor([0.3021]))]) \n",
            "\n",
            "Epoch: 33620 | Loss: 0.0009904422331601381 | Test loss: 0.0023111284244805574\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.3021]))]) \n",
            "\n",
            "Epoch: 33630 | Loss: 0.0009732783073559403 | Test loss: 0.00227333907969296\n",
            "OrderedDict([('weights', tensor([0.6952])), ('bias', tensor([0.3020]))]) \n",
            "\n",
            "Epoch: 33640 | Loss: 0.0009561143815517426 | Test loss: 0.002230364130809903\n",
            "OrderedDict([('weights', tensor([0.6953])), ('bias', tensor([0.3020]))]) \n",
            "\n",
            "Epoch: 33650 | Loss: 0.0009389721089974046 | Test loss: 0.002192586660385132\n",
            "OrderedDict([('weights', tensor([0.6953])), ('bias', tensor([0.3020]))]) \n",
            "\n",
            "Epoch: 33660 | Loss: 0.0009217977640219033 | Test loss: 0.002153080655261874\n",
            "OrderedDict([('weights', tensor([0.6954])), ('bias', tensor([0.3019]))]) \n",
            "\n",
            "Epoch: 33670 | Loss: 0.0009046636405400932 | Test loss: 0.0021118461154401302\n",
            "OrderedDict([('weights', tensor([0.6955])), ('bias', tensor([0.3019]))]) \n",
            "\n",
            "Epoch: 33680 | Loss: 0.0008874930208548903 | Test loss: 0.0020723522175103426\n",
            "OrderedDict([('weights', tensor([0.6956])), ('bias', tensor([0.3018]))]) \n",
            "\n",
            "Epoch: 33690 | Loss: 0.0008703366038389504 | Test loss: 0.0020311176776885986\n",
            "OrderedDict([('weights', tensor([0.6957])), ('bias', tensor([0.3018]))]) \n",
            "\n",
            "Epoch: 33700 | Loss: 0.000853183853905648 | Test loss: 0.0019915997982025146\n",
            "OrderedDict([('weights', tensor([0.6958])), ('bias', tensor([0.3018]))]) \n",
            "\n",
            "Epoch: 33710 | Loss: 0.0008360237115994096 | Test loss: 0.0019503533840179443\n",
            "OrderedDict([('weights', tensor([0.6958])), ('bias', tensor([0.3017]))]) \n",
            "\n",
            "Epoch: 33720 | Loss: 0.000818871718365699 | Test loss: 0.0019108593696728349\n",
            "OrderedDict([('weights', tensor([0.6959])), ('bias', tensor([0.3017]))]) \n",
            "\n",
            "Epoch: 33730 | Loss: 0.0008016861975193024 | Test loss: 0.001869624829851091\n",
            "OrderedDict([('weights', tensor([0.6960])), ('bias', tensor([0.3017]))]) \n",
            "\n",
            "Epoch: 33740 | Loss: 0.0007845416548661888 | Test loss: 0.0018301308155059814\n",
            "OrderedDict([('weights', tensor([0.6961])), ('bias', tensor([0.3016]))]) \n",
            "\n",
            "Epoch: 33750 | Loss: 0.000767356890719384 | Test loss: 0.0017906248103827238\n",
            "OrderedDict([('weights', tensor([0.6962])), ('bias', tensor([0.3016]))]) \n",
            "\n",
            "Epoch: 33760 | Loss: 0.0007502205553464592 | Test loss: 0.0017493783961981535\n",
            "OrderedDict([('weights', tensor([0.6963])), ('bias', tensor([0.3016]))]) \n",
            "\n",
            "Epoch: 33770 | Loss: 0.000733058899641037 | Test loss: 0.0017116367816925049\n",
            "OrderedDict([('weights', tensor([0.6964])), ('bias', tensor([0.3015]))]) \n",
            "\n",
            "Epoch: 33780 | Loss: 0.0007158920052461326 | Test loss: 0.0016686379676684737\n",
            "OrderedDict([('weights', tensor([0.6964])), ('bias', tensor([0.3015]))]) \n",
            "\n",
            "Epoch: 33790 | Loss: 0.0006987519445829093 | Test loss: 0.001630848622880876\n",
            "OrderedDict([('weights', tensor([0.6965])), ('bias', tensor([0.3015]))]) \n",
            "\n",
            "Epoch: 33800 | Loss: 0.0006815769011154771 | Test loss: 0.0015913427341729403\n",
            "OrderedDict([('weights', tensor([0.6966])), ('bias', tensor([0.3014]))]) \n",
            "\n",
            "Epoch: 33810 | Loss: 0.0006644182140007615 | Test loss: 0.0015483915340155363\n",
            "OrderedDict([('weights', tensor([0.6967])), ('bias', tensor([0.3014]))]) \n",
            "\n",
            "Epoch: 33820 | Loss: 0.000647280365228653 | Test loss: 0.0015106141800060868\n",
            "OrderedDict([('weights', tensor([0.6968])), ('bias', tensor([0.3013]))]) \n",
            "\n",
            "Epoch: 33830 | Loss: 0.000630124646704644 | Test loss: 0.0014694035053253174\n",
            "OrderedDict([('weights', tensor([0.6969])), ('bias', tensor([0.3013]))]) \n",
            "\n",
            "Epoch: 33840 | Loss: 0.0006129794055595994 | Test loss: 0.001429873751476407\n",
            "OrderedDict([('weights', tensor([0.6970])), ('bias', tensor([0.3013]))]) \n",
            "\n",
            "Epoch: 33850 | Loss: 0.000595798366703093 | Test loss: 0.0013886153465136886\n",
            "OrderedDict([('weights', tensor([0.6970])), ('bias', tensor([0.3012]))]) \n",
            "\n",
            "Epoch: 33860 | Loss: 0.0005786508554592729 | Test loss: 0.0013491332065314054\n",
            "OrderedDict([('weights', tensor([0.6971])), ('bias', tensor([0.3012]))]) \n",
            "\n",
            "Epoch: 33870 | Loss: 0.0005614884430542588 | Test loss: 0.0013096153270453215\n",
            "OrderedDict([('weights', tensor([0.6972])), ('bias', tensor([0.3012]))]) \n",
            "\n",
            "Epoch: 33880 | Loss: 0.0005443282425403595 | Test loss: 0.0012683927780017257\n",
            "OrderedDict([('weights', tensor([0.6973])), ('bias', tensor([0.3011]))]) \n",
            "\n",
            "Epoch: 33890 | Loss: 0.0005271449917927384 | Test loss: 0.0012288748985156417\n",
            "OrderedDict([('weights', tensor([0.6974])), ('bias', tensor([0.3011]))]) \n",
            "\n",
            "Epoch: 33900 | Loss: 0.0005100019043311477 | Test loss: 0.001187652349472046\n",
            "OrderedDict([('weights', tensor([0.6975])), ('bias', tensor([0.3011]))]) \n",
            "\n",
            "Epoch: 33910 | Loss: 0.0004928387934342027 | Test loss: 0.0011498630046844482\n",
            "OrderedDict([('weights', tensor([0.6976])), ('bias', tensor([0.3010]))]) \n",
            "\n",
            "Epoch: 33920 | Loss: 0.0004756726266350597 | Test loss: 0.0011069119209423661\n",
            "OrderedDict([('weights', tensor([0.6976])), ('bias', tensor([0.3010]))]) \n",
            "\n",
            "Epoch: 33930 | Loss: 0.00045852139010094106 | Test loss: 0.0010673940414562821\n",
            "OrderedDict([('weights', tensor([0.6977])), ('bias', tensor([0.3010]))]) \n",
            "\n",
            "Epoch: 33940 | Loss: 0.0004413604619912803 | Test loss: 0.0010296165710315108\n",
            "OrderedDict([('weights', tensor([0.6978])), ('bias', tensor([0.3009]))]) \n",
            "\n",
            "Epoch: 33950 | Loss: 0.0004241980495862663 | Test loss: 0.0009866416221484542\n",
            "OrderedDict([('weights', tensor([0.6979])), ('bias', tensor([0.3009]))]) \n",
            "\n",
            "Epoch: 33960 | Loss: 0.0004070505383424461 | Test loss: 0.0009488761425018311\n",
            "OrderedDict([('weights', tensor([0.6980])), ('bias', tensor([0.3008]))]) \n",
            "\n",
            "Epoch: 33970 | Loss: 0.00038990675238892436 | Test loss: 0.0009076297283172607\n",
            "OrderedDict([('weights', tensor([0.6981])), ('bias', tensor([0.3008]))]) \n",
            "\n",
            "Epoch: 33980 | Loss: 0.00037274957867339253 | Test loss: 0.000868123781401664\n",
            "OrderedDict([('weights', tensor([0.6982])), ('bias', tensor([0.3008]))]) \n",
            "\n",
            "Epoch: 33990 | Loss: 0.00035557671799324453 | Test loss: 0.0008286178344860673\n",
            "OrderedDict([('weights', tensor([0.6982])), ('bias', tensor([0.3007]))]) \n",
            "\n",
            "Epoch: 34000 | Loss: 0.00033844338031485677 | Test loss: 0.0007873832946643233\n",
            "OrderedDict([('weights', tensor([0.6983])), ('bias', tensor([0.3007]))]) \n",
            "\n",
            "Epoch: 34010 | Loss: 0.0003212675510440022 | Test loss: 0.0007478654151782393\n",
            "OrderedDict([('weights', tensor([0.6984])), ('bias', tensor([0.3007]))]) \n",
            "\n",
            "Epoch: 34020 | Loss: 0.00030410289764404297 | Test loss: 0.0007066428661346436\n",
            "OrderedDict([('weights', tensor([0.6985])), ('bias', tensor([0.3006]))]) \n",
            "\n",
            "Epoch: 34030 | Loss: 0.000286933034658432 | Test loss: 0.0006671369192190468\n",
            "OrderedDict([('weights', tensor([0.6986])), ('bias', tensor([0.3006]))]) \n",
            "\n",
            "Epoch: 34040 | Loss: 0.0002697795571293682 | Test loss: 0.0006259024376049638\n",
            "OrderedDict([('weights', tensor([0.6987])), ('bias', tensor([0.3006]))]) \n",
            "\n",
            "Epoch: 34050 | Loss: 0.000252632045885548 | Test loss: 0.0005863845581188798\n",
            "OrderedDict([('weights', tensor([0.6988])), ('bias', tensor([0.3005]))]) \n",
            "\n",
            "Epoch: 34060 | Loss: 0.0002354547323193401 | Test loss: 0.0005451619508676231\n",
            "OrderedDict([('weights', tensor([0.6988])), ('bias', tensor([0.3005]))]) \n",
            "\n",
            "Epoch: 34070 | Loss: 0.0002183027536375448 | Test loss: 0.0005056321388110518\n",
            "OrderedDict([('weights', tensor([0.6989])), ('bias', tensor([0.3005]))]) \n",
            "\n",
            "Epoch: 34080 | Loss: 0.00020114406652282923 | Test loss: 0.0004678904952015728\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3004]))]) \n",
            "\n",
            "Epoch: 34090 | Loss: 0.0001839801698224619 | Test loss: 0.00042490364285185933\n",
            "OrderedDict([('weights', tensor([0.6991])), ('bias', tensor([0.3004]))]) \n",
            "\n",
            "Epoch: 34100 | Loss: 0.0001668326585786417 | Test loss: 0.00038713813410140574\n",
            "OrderedDict([('weights', tensor([0.6992])), ('bias', tensor([0.3003]))]) \n",
            "\n",
            "Epoch: 34110 | Loss: 0.00014966279559303075 | Test loss: 0.00034762025461532176\n",
            "OrderedDict([('weights', tensor([0.6993])), ('bias', tensor([0.3003]))]) \n",
            "\n",
            "Epoch: 34120 | Loss: 0.00013252049393486232 | Test loss: 0.00030640960903838277\n",
            "OrderedDict([('weights', tensor([0.6993])), ('bias', tensor([0.3003]))]) \n",
            "\n",
            "Epoch: 34130 | Loss: 0.00011535510566318408 | Test loss: 0.0002668797969818115\n",
            "OrderedDict([('weights', tensor([0.6994])), ('bias', tensor([0.3002]))]) \n",
            "\n",
            "Epoch: 34140 | Loss: 9.821057028602809e-05 | Test loss: 0.00022566915140487254\n",
            "OrderedDict([('weights', tensor([0.6995])), ('bias', tensor([0.3002]))]) \n",
            "\n",
            "Epoch: 34150 | Loss: 8.104964945232496e-05 | Test loss: 0.0001861393393483013\n",
            "OrderedDict([('weights', tensor([0.6996])), ('bias', tensor([0.3002]))]) \n",
            "\n",
            "Epoch: 34160 | Loss: 6.388500332832336e-05 | Test loss: 0.00014490485773421824\n",
            "OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3001]))]) \n",
            "\n",
            "Epoch: 34170 | Loss: 4.6734512579860166e-05 | Test loss: 0.00010538697097217664\n",
            "OrderedDict([('weights', tensor([0.6998])), ('bias', tensor([0.3001]))]) \n",
            "\n",
            "Epoch: 34180 | Loss: 2.9555707442341372e-05 | Test loss: 6.417631811928004e-05\n",
            "OrderedDict([('weights', tensor([0.6999])), ('bias', tensor([0.3001]))]) \n",
            "\n",
            "Epoch: 34190 | Loss: 1.2411177522153594e-05 | Test loss: 2.4658442271174863e-05\n",
            "OrderedDict([('weights', tensor([0.6999])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34200 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34210 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34220 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34230 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34240 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34250 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34260 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34270 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34280 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34290 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34300 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34310 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34320 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34330 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34340 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34350 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34360 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34370 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34380 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34390 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34400 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34410 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34420 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34430 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34440 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34450 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34460 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34470 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34480 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34490 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34500 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34510 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34520 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34530 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34540 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34550 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34560 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34570 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34580 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34590 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34600 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34610 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34620 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34630 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34640 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34650 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34660 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34670 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34680 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34690 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34700 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34710 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34720 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34730 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34740 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34750 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34760 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34770 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34780 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34790 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34800 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34810 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34820 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34830 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34840 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34850 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34860 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34870 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34880 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34890 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34900 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34910 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34920 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34930 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34940 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34950 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34960 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34970 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34980 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 34990 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35000 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35010 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35020 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35030 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35040 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35050 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35060 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35070 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35080 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35090 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35100 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35110 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35120 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35130 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35140 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35150 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35160 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35170 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35180 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35190 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35200 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35210 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35220 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35230 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35240 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35250 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35260 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35270 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35280 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35290 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35300 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35310 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35320 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35330 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35340 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35350 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35360 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35370 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35380 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35390 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35400 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35410 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35420 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35430 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35440 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35450 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35460 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35470 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35480 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35490 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35500 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35510 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35520 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35530 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35540 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35550 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35560 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35570 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35580 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35590 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35600 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35610 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35620 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35630 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35640 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35650 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35660 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35670 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35680 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35690 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35700 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35710 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35720 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35730 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35740 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35750 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35760 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35770 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35780 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35790 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35800 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35810 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35820 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35830 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35840 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35850 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35860 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35870 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35880 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35890 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35900 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35910 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35920 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35930 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35940 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35950 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35960 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35970 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35980 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n",
            "Epoch: 35990 | Loss: 2.629011942190118e-05 | Test loss: 2.4956465495051816e-05\n",
            "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\" )\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1YVMAxmjSTGG",
        "outputId": "40550bfd-8b26-407a-887c-18fd363281c3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)"
      ],
      "metadata": {
        "id": "3pSgg8R0F811"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vx1hBJlPhar",
        "outputId": "10264042-4b62-4c4d-e7d6-c1369c787623"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds_new), plot_predictions(predictions=y_preds);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "I_lACF_oJzqK",
        "outputId": "58a291ca-c2c8-4268-88b2-fda7531f3b68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mprBwAQkLH4o"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}